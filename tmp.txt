LecturenotesonAdvancedOperating
Systems
PolitecnicodiMilano
ClaudioMigliorelli(prof. VittorioZaccaria)
April2,2023
Contents
Contents 1
1 Lecture1-IntroductiontoOperatingSystemsI . 2
2 Lecture2-IntroductiontoOperatingSystemsII . 8
3 Lecture3-ConcurrencyI . . . . . . . . . . . . . 21
4 Lecture4-ConcurrencyII . . . . . . . . . . . . . 28
5 Lecture6-ConcurrencyIII . . . . . . . . . . . . 37
6 Lecture7-ConcurrencyIV . . . . . . . . . . . . 48
7 Lecture8-ConcurrencyV . . . . . . . . . . . . . 53
8 Lecture9-ConcurrencyVI . . . . . . . . . . . . 62
9 Lecture10-ConcurrencyVII . . . . . . . . . . . 71
10 Lecture14-LinuxVirtual/PhysicalAddressSpaceI 78
11 Lecture15-LinuxVirtual/PhysicalAddressSpace
II&MemoryModelsI . . . . . . . . . . . . . . . 88
12 Lecture16-MemoryModelsII&VirtualizationI 100
13 Lecture17-VirtualizationII . . . . . . . . . . . . 116
14 Lecture18-I/ODevicesandDriversI . . . . . . 129
15 Lecture23-SeminaronSoftwareVerificationI . 140
16 Lecture24-SeminaronSecureBootI . . . . . . 148
17 Lecture25-I/ODevicesandDriversII . . . . . . 149
11 Lecture1-IntroductiontoOperating
SystemsI
Somequickandintroductoryconcepts
We define a CPUas a logic circuit able to execute instructions.
Aprogram, instead, is a sequence of instructions and definitions
of algorithms, while a processis a program with associated data
which is going to be actually operating on by the program itself
(i.e.,process = program + ongoing data ). Thedifferencebetween
user mode andkernel mode is that in the former we can execute
onlyafractionoftheinstructionsmadeavailablebytheCPU,while
thelatterisa”moreprivileged”modeinwhichwecanexecuteall
instructionsmadeavailable.
Whatisanoperatingsystem
Anoperatingsystemisasoftwareprogramthathasseveralgoals:
•Resource management : provide a single resource to sev-
eral consumers in a way that the latter think they have the
resourceexclusivelyprovidedforthem(e.g.,assignCPUre-
sourcestoprocesses)
–Inotherwords,thepointistoallowprogramstoexe-
cuteastheyweretheonlyonesassignedtotheindivid-
ualresource(e.g.,theirownCPU,thewholememory);
–Another important aspect is that we want to ensure
a fair and parsimonious utilization of the shared re-
sources (i.e., avoid starvation), possibly by implying
somesortofmultiplexingtechniques;
•Isolation and protection : we want to regulate/enforce ac-
cess rights from applications to resources (e.g., memory)
to avoid conflicts or applications clobbering one with each
other
–Theoperatingsystemallowsustodivideandseparate
thephysicalmemoryfromwhatwecallvirtualmem-
ory in order for each application to see its own vir-
tual memory without interfering with data belonging
tootherapplications;
2•Make it easier to port and extend the entire system : the
idea is to hide the complexity of having direct access and
interactionwithperipherals(thatmaybedifferentonewith
each other). The operating system is in charge of dealing
with them, making the complexity transparent to the final
user
–System calls are the most important tool used by the
operatingsystemtoimplementthatbehavior;
–Thefinalresultistoallowthesameapplicationtowork
onsystemsequippedwithdifferentphysicalresources
(e.g.,differentGPUs,networkinterfaces,SSDsorme-
chanicaldisks,etc.).
Basically,thegoalsanoperatingsystemisintendedtoaccom-
plish in that case are strictly related to two famous software pat-
terns:
•Facade: hidingthecomplexityofhardwareaccess/manage-
mentfromapplications(abstractiontoapplications);
•Bridge: hidingthecomplexityassociatedwithvariants,e.g.,
peripheralmodels(abstractiontointernalcomponents).
Techniquesusedtoimplementresourcemanagement
The key idea here is to multiplex the CPU . Multiplexing the CPU
meansthatwehavearesourcewedon’twanttowasteandweare
willingtoallocatethisresourcefairlybetweenprocesses. Theop-
eratingsystemtriesto increasetheCPUutilization andtoreduce
latencybyschedulingapplicationswithoutforcingthemtowaita
lotoftimetobeexecuted.
Thisistypicallydonebyusing interrupts ,tohaveafairmulti-
plexingwhenapplicationswaitforsomethingtohappen(oreven
usingtimerinterruptstogiveresourcestoapplicationsonatime-
based approach). In other words, there are two steps needed in
ordertodothat:
•The kernel programs timersto expire every xms: writing
appropriateI/Oregisterscanbedoneonlyinsupervisormode,
thustheusercan’tre-programtheseintervaltimers;
3Figure1: IncreasingtheCPUutilizationandreducinglatency
•Thekernelsetsinterruptsto vectorbacktokernel : itregains
control1wheneverthisintervaltimersexpiresanditgives,1There is no way for user code to hijack interrupt
handlers, since it must be in supervisor mode to set up
entrypoints.in turn, the control to another process that needs CPU re-
sources.
Asaresult,therearenoprocessesabletomonopolizetheCPU
with infinite loops and, at worst, a single process could get1
Nof
CPUwith NCPU-hungryprocesses.
1.ProcessesandstatesA processisaprogramwithassociated
dataanditsstatearetrackedbytheoperatingsystemusing
a so-called Process control block (PCB). A PCB is a data
structure (i.e., context) allocated for a each processand re-
sidesinkernelspace andmaintains:
•Machineregistersrelatedtothatapplication;
•Machinearchitecturalstate(e.g.,user/kernelmode,vir-
tualmemorymappings);
•Credentials(i.e.,user/groupID),signalmask,control-
lingterminal,priority,accounting,statistics,etc.;
•Openfiles(includingmemorymappedfiles).
Processescanlieinfivedifferentstates:
•NEW:theprocessisnotreadytorunyet;
•READY: ready to be scheduled when the CPU pre-
empttheexecutionofarunningprocess;
4•RUNNING :theprocessisrunninginaCPU-coreuntil
ispreemptedandsenttothereadystate;
•BLOCKED :theprocessiswaitingforaneventtoprogress;
•TERMINATED :theprocessisterminated.
2.ContextswitchesOperatingsystemsthatexploitsinterrupts
togivecontroltoapplicationsbasedontimeframesarecalled
preemptive operatingsystems. Typically,wheninterruptis
senttostoptheexecutionofaprocess P0,theoperatingsys-
temswitchesPCBstogive P1thecapabilitiestoexecute.
Acontext switch is the activity of changing machine regis-
terstorunanotherprocess(bychangingPCBandotherOS-
levelresources). Thechallengehereistoselect whichother
process to execute when performing a context switch (i.e.,
whatprocess P1hastobe). Thisproblemiscalled schedul-
ing.
3.Scheduling Scheduling is an activity used to decide which
processneedstoberunnext. Theimplementedpolicyshould
balancebetween:
•Fairness: do not make processes wait endlessly, mak-
ingthemstarving;
•Throughput : providegoodoverallperformances;
•Efficiency : minimizetheoverheadthescheduleritself
has(takedecisionsintheshortesttimepossible);
•Priority: reflecttherelativeimportanceofprocesses2;2Someprocesses,fortheirownnature,needtohave
moreCPUthanothers. Prioritiesareawaytorepresent
thisandtheyareinterpretedindifferentwaysindifferent
operatingsystems.•Deadlines : makeapplicationsexecuteforthetimeframe
theyaresupposedtoexecute3.
3Thismakesusdifferentiatebetweenoperatingsys-
temsasgeneralpurposeandreal-time. 54.Differencesbetweengeneralpurposeandreal-timeOSesWhen
wehavea generalpurpose operatingsystem,generallyitem-
ploysfairness,decidingwhichprocessneedstobeexecuted
basedontimeintervalsandpriorities,inafairway.
Figure2: Howgeneral-purposeoperatingsystemshandleschedul-
ing
We have intervals in which the operating system decides
whatthenextrunningprocessmustbeandwheneveratime
slice finishes (and whenever the operating system decides
thecurrentprocesstoreleasetheCPU)wesaythatthecur-
rentprocessispreempted. Ageneralpurposeoperatingsys-
tem,asitmayseemclearlookingatthepictureabove,tries
to pursue fairness, even with respect to lower priority pro-
cesses and does not interrupt the current process until it
reachestheendofitstimeslice.
Real-time operatingsystemstrytobealwayspredictablein
termsofCPUallocation: highpriorityprocessesalwayshave
advantageonlowestpriorityones.
HigherprioritythreadsarealwaysgivenaccesstotheCPU
inthatscenarioandtheunderlyingassumptionisthatthey
usually do things for a limited time and then go to sleep
(theideaisthatwestillhavetimetoexecutelowerpriority
6Figure3: Howreal-timeoperatingsystemshandlescheduling
threads). Real-time operating systems typically have more
priorities to choose from with respect to general purpose
operatingsystems.
Memorymanagement
Wheneverthereisaprocess,wealsohaveits virtualaddressspace ,
whichisconstitutedbyallmemorylocationsaprogramcanname.
Thesememorylocationsarebuiltupfrom virtualmemoryareas .
Some of these memory areas are taken from the on-disk rep-
resentation of the program (e.g., text,rodata,data,bss) while
othersarebuiltupdynamically(e.g.,stack,heap,memorymapped
segmentsand vdso). Therealsoalsoothermemorylocationswhich
arenotaccessible,e.g.,kernelspace.
Wecan’thoweverallocatethememoryasitisinphysicalmem-
ory, since we want to avoid other processes to read areas not in-
tended for them. For this reason, tables used for the virtual-to-
memory mapping shouldn’t allow pages related to different pro-
cessestorefertothesamephysicallocation,unlesstheyarespeci-
fiedtodoso. Thisisthecorefunctionalityofakeyconceptcalled
isolation.
7Figure4: Processaddressspace
2 Lecture2-IntroductiontoOperating
SystemsII
Introductiontotasks
Tasksare similar to programs but they are something more: they
haveadditionaldataassignedtothem(e.g.,programcounter,stack).
Inotherwords,theyareamoregeneralconceptandinLinuxthere
isacleardistinctionbetween:
•Tasks;
•Processes;
•Threads.
8Figure5: Taskvs. processvs. thread
Threads are basically tasks that share the same memory (i.e.,
address space), while processes are tasks not sharing the address
spacewithothers. Wecouldseeataskasa”super-class”thatem-
bodiesprocessesandthreads(aswesaid,itisaverygeneralcon-
cept).
Whenthetaskisinuserorkernelspaceonbehalfofthepro-
cess(e.g.,executingasystemcall),wesaythatthekernelisin pro-
cesscontext . Thekernelitselfcancreatethreadswhichlivealways
inkernelmode.
Kernelthreads
Therearealso kernelthreads : theyrunwithkernelprivileges(i.e.,
theyseekernel’smemory)andareroutinesandbackgroundwork
performed by the kernel. The addressspace of thatthreads is the
entire kernel’s address space. Note that these are schedulable and
preemptable , which is the same for normal processes, and they
arecreatedbythekernelforspecifiedpurposesaschildrenofthe
kthreadd kernelprocess.
Thetask_struct
Thedatastructurethekernelholdstomanagetasksis task_struct
(also called Task Control Block), which forms a hierarchy within
kernelmemory(throughthe parentfieldinthedatastructureit-
self)4. In such a data structure, the kernel holds a description of4Theonlytaskthatdoesnothaveaparentisthefirst
task(init). the virtual memory address space, current and root directories,
openedfiles,etc.
9Figure6: The task_struct andthread_info structures
Whenever the kernel wants to manipulate the structure as-
sociated to a task, this should be done right away and in an effi-
cientway. Insomearchitectures(e.g.,RISC-V)thepointertotask
structures is stored in a register always available to the kernel. In
x86, instead, there is an additional structure called thread_info
keptinthekernel-levelstack,whichisusedbythekerneltoreach
thetask_struct by computing its address. A very crucial field
inthethread_info structureis preempt_count ,usedbytheLinux
kerneltounderstandwhether,whentransitioningtokernel-mode
during exceptions or interrupts, it can do something. This flag
prevents the kernel from messing up with interrupt nesting. The
thread_struct field,instead,isusedonlyduringcontextswitchto
save callee-saved registers and make the switch_to() invocation
likea”normal”function5.5However, this is not a normal function: it won’t
return immediately but after the task is going to be
rescheduledtorunagain.Thereisamacroexportedbythekernel,whichiscalled current,
that takes care of getting the reference to the task_struct of the
currentprocessunderexecution.
10TaskstatesinLinux
A task can be in three main and general states (the Linux kernel
usesmorethanthese,aswewillsee):
•Running;
•Ready;
•Blocked.
For some historical reasons Linux uses the same label (i.e.,
running)bothforataskreadybutnotyetrunningandataskcur-
rently running6. Whenever our process terminates, the task is6The kernel differentiates a task already running
fromareadyonefromthekeptTaskControlBlock. put in a temporary ”terminated” state: this is because its parent
taskwantstohavealookatthefinalstateofthetask(e.g.,signals,
errors). Theblockedstatecomesintwodifferentflavors:
•TASK_INTERRUPTIBLE ;
•TASK_UNINTERRUPTIBLE .
These are basically the same state (i.e., the task is waiting for
somethingtohappen),butinthefirstcase,ifsomeprocesssignals
theblockedtask,thenthelattercanbewakenup,evenbeforethe
eventhadoccurred. Whenthetaskisuninterruptible,instead,no
signal(apartfromtheeventoccurrence)canwakeuptheblocked
thread. Anexamplecouldbea killfromcommandlinetowards
ablockedthread: ifitisuninterruptible,therewouldbenowayto
tellthatprocesstodosometaskbeforebeingkilled.
Finally,wecouldsummarizetaskstatesinLinuxasfollows:
•TASK_RUNNING : the process is runnable and it is either cur-
rentlyrunningorinarun-queuewaitingtorun;
•TASK_INTERRUPTIBLE :theprocessissleeping(i.e.,itisblocked),
waiting for some condition to exist. It wakes up and be-
comesrunnablewhenreceivingasignal;
•TASK_UNINTERRUPTIBLE :theprocessissleeping(i.e.,itisblocked),
butitdoesn’twakeupwhenreceivingasignal. Thisstateis
lessoftenusedthan interruptible (onlywhentheeventisex-
pectedtoarriverapidly);
11•TASK_DEAD :theprocessisterminatedandputinthistempo-
rarystate. Wheninthisstate,itwillnolongerbeexecuted,
whileitsmetadataarekeptinmemoryuntilitsparentthread
collectsthem(e.g.,inspectingthereturnvalue). Thesepro-
cessesarecalled zombies.
Waitqueues
Linuxmanageseventsbyusingso-called waitqueues : structures
that maintain tasks in a wait state for a specific event . Tasks are
addedwheneveradriver/moduleinvokesfunctionscalled wait_event()
orwait_event_interruptible() . Thoseareusedbythekernelto
putcurrenttasksinspecifiedqueuestowaitforspecificevents.
However, wait queues have a problem: whenever the event
happens there would be something invoking wake_up() , waking
upalltaskswaitingforthatevent(i.e.,tasksinsidethatwaitqueue).
The point is that, in the majority of the cases, only the first task
couldconsumethatevent(i.e.,theone”winning”therace),while
the others would remain inside the wait queue. This problem is
calledthunderingherd .
Forsolvingthisproblem,thekerneldefinestwokindsofsleep-
ingprocesses:
•Exclusive: always put at the end of the queue. When the
wakeupreachesthem,itstops;
•Non-exclusive : alwayswokenupbythekernel.
Theideaistowakeupthreadsinanexclusiveway: thekernel
uses an additional part of the list to wake up the first task exclu-
sivelyinsuchanadditionallist. Asaresult,allthreadswithoutthe
WG_FLAG_EXCLUSIVE will be waken up, and only one of the tasks
havingthatflagwillwakeupfrombeingblocked. Thisflagisspec-
ifiedwhencalling wait_event APIs.
Taskcreation
TaskcreationinLinuxgoesbycloning: anycallto fork()creates
anewcopyofthecurrent task_struct . Thecopy differsfromthe
parentonlyaccordingtothefollowingaspects:
•PID, which is unique, and PPID, which is the parent’s PID
andit’ssettotheoriginalprocess(i.e.,theoneforking);
12•Certain resources, such as pending signals, which are not
inherited.
Linuxusesa”copy-on-write”wayofmanagingresourceswhen-
ever we do a fork(): whenever the child thread changes some-
thing, it tries to share the original data in read-only. Rather than
duplicatetheprocessaddressspace,parentandchildshareasingle
copy. If the data is written to, a duplicate is made and each pro-
cess receives a unique copy. The copy-on-write is made possible
bysettingupwriteableVMAsasread-only. Inthisway,thekernel
caninterceptonpagefaultanddothecopy.
Thelibc’sfunction fork()invokesthesystemcall sys_clone() ,
whichisgoingtosetupalltheoriginalvirtualmemoryareasfrom
theparentprocessinread-onlymode7.7During this process, the sys_clone() shal-
low copies the parent’s task_struct (and the
thread_struct )bycalling dup_task_struct() .Theinittask
Letusinspectquicklytheinitializationofthekernel: whenitstarts
some routines are executed to bringing it to create the first task
(withPID=1). Inparticular,thekernelcreatesanewkernelthread
thatexecutesthe /bin/init (firsttask)andaroutinecalled invoke_schedule()
createsanotherdummytaskcalled cpu_idle()8.8Thecpu_idle() routine is an always-running ac-
tivitythatisusedforthekernelitselftopulltheCPUin
low-powermodewhenitdoesn’texecuteanyroutine.
The/bin/init is really important because it is used to start
everythingelse(e.g., mountingdisks, startingservices)andthere
are two main approaches to make this process to perform such a
thing:
•System V;
•systemd.
131.Introductionto System VSystem V wasreleasedintheearly
’80sandspecifiestothe initprocessalltheprogramstorun
by collecting them in run levels . These run levels are basi-
callycollectionsoftaskstostartandcorrespondtoaspecific
configurationofthemachine. So,atanytime,thesystemis
inoneoftheserunlevels:
•1: singleuser;
•2: multi-userwithnonet;
•3: multi-user;
•5: X11;
•6: reboot.
Thefile /etc/inittab describeswhichprocessesneedtobe
runforeachrunlevel. Theformatis id:rl:action:command ,
whereactioncan be, e.g., wait,start,respawnand pro-
cesses could be either simple commands or bash script to
initializesubsystems. Thelatterarecalled rc<n>scriptsand
invokesubsystemscriptsin init.dthroughlinks.
Figure7: System V architecture
Themostused System V configurationisthenumber 3,which
isthemulti-userone. Inthiscase,the rc3scriptisrun.
14System V isanimperativeinterface(withacollectionofscripts)
and it is basically single-threaded, everything is done se-
quentially9, which is a huge disadvantage (i.e., the startup9This means that, for the example in figure, K30tcp
issetupfirst,then K40nfsetc. takesalotoftime). Anewandparallelarchitectureis systemd.
2.Introductionto systemd systemd isstructuredby Unitfiles,
which are plain text ini-style files that encode information
about a service, a socket, a device, a mount point, an au-
tomount point. These files have their own semantics and
theyaredeclarative,sayingforeachserviceifthereareother
units to be run before that service. Services are the most
common type of units and are described in .service files.
Whattheydoisencodinginformationaboutaprocesscon-
trolledandsupervisedby systemd. Theycontaintheorder-
ingofrequiredunitstobestartedasdependencies. Targets
arecollectionsofunitsandemulateoldrun-levels(e.g., /lib/systemd/system/multi-
user.target isafilethatcontainslinksto RL3units).
Figure8: systemdarchitecture
Taskscheduling
From its first version in 1991 to the 2.4 kernel series, the Linux
schedulerscaledpoorlyinlightofmanyrunnableprocessesand/or
many processors. With version 2.5, a new scheduler, called O(1),
introduceda constant-timealgorithm forsearchingthehighestpri-
orityprocessinafixed-lengthbitmap. However,O(1)wasidealfor
largeserverworkloadsbutperformedpoorlyoninteractiveappli-
cations. Moreover,itscodewascomplexanderrorproneandthe
15algorithm itself could led to unfairness. In next kernel’s versions,
theCFSalgorithmwasintroducedtogivebetterresponsiveness.
Schedulingclasses
AschedulingclassisanAPIusedinternallybythekerneltospecify
somepolicy-specificwaytopickuptasksfromthe”readyqueue”
(i.e.,select_task_rq )tomakethemrun(i.e., enqueue_task ). De-
pendingonthecontextofuse,wecouldhaveseveralpolicytoen-
codeintheimplementationoftheseAPIs.
Figure9: SchedulingclassAPIsforLinux5.7(subset)
Thereareschedulingclassesassociatedwithnormaltasks,which
doesn’t have many constraints in terms of what they should do
(i.e.,normal scheduling policies ). The other set of policies, used
as an alternative for certain tasks, is the one associated with real-
time processes (i.e., processes that must respect somehow mea-
suresofurgencyanddeadlines). Typicallywesorttheseschedul-
ing classes starting with those having a deadline to be respected,
thosethatneedtobeexecuteduptotheend(i.e.,FIFO),thosethat
arehighprioritybutthatcansharetheprocessorinaround-robin
way(i.e.,RR),andsoon. Thelasttwoclassesare SCHED_BATCH and
SCHED_IDLE : the former is like CFS but has a different and longer
time slice to be used to manage tasks (can be used for tasks not
response-oriented ), while the latter comprises tasks that can be
runwhentheCPUisnotbusy.
16Figure10: Schedulingclasses
Tosummarize:
•SCHED_FIFO :likeRRbutifataskdoesnotreleasetheCPU,it
willrunindefinitelyevenifthereareothertaskshavingthe
samepriority;
•SCHED_RR: tasks will repeatedly go ahead of any other task
havinglowerpriority. Ifmultipletaskshavethesameprior-
ity,theRRpolicywillbeapplied;
•SCHED_OTHER : conventional time-shared approach. In gen-
eral,ithasasoftprioritymechanismoverthe”nice”rangeof
-20 to +19, which decides, according to the priority, which
taskgoesfirstandwhattimesliceitgets;
•SCHED_BATCH :haslongertimeslices(1.5s)therebyallowing
taskstorunlongerandmakebetteruseofcaches,butatthe
costofinteractivity. Thisiswellsuitedforbatchjobs;
•SCHED_IDLE :scheduleonlyiftheCPUis idle. Wheninker-
nelmode,thesebehavelike SCHED_OTHER toavoidsoftlock-
ups(e.g.,notreleasedsemaphores);
•SCHED_DEADLINE :implementationofthe EarliestDeadlineFirst
(EDF)schedulingalgorithm,augmentedwith GreedyRecla-
mationofUnusedBandwidth (GRUB)fromkernel4.13.
However, if multiple policies have a runnable thread, Linux
hasasimplefixed-prioritylisttodeterminetheorder:
deadline -> realtime -> fair -> idle
17Whenathreadisscheduledout,theschedulersubsystemwill
iterate over this list and call the pick_next_task() function of
eachclassuntilathreadisreturned.
The scheduler performs the so-called load balancing : it tries
to migrate threads between cores in order to even the number of
threadsrunningonallcores. Loadbalancingisdoneusinga”work
stealing”approach: oneachcore,thekerneldoesitsownbalancing
andtriestostealthreadsfromthebusiestcoreonthesystem.
CompletelyFairScheduler(CFS)
Completely Fair Scheduler has been introduced in 2007 for non
real-timeprocessestosolvepreviousproblems. Westillhavecom-
pletely separated sets of processes with a certain normal priority
:
•Real-timeprocesses ,2[0;99]: theybelongto SCHED_FIFO
andSCHED_RR schedulingclasses;
•Nonreal-timeprocesses ,100()139: thevalue ()
dependsona nicevalue 2[ 20;+19]:
() = 120 + :
Processesfollowingthisapproachbelongtothe SCHED_NORMAL
schedulingclass.
Figure11: CFSprioritiesandschedulingclasses
18Toinspectprocessesandtheirassociated”nice”value,wecould
usethefollowingcommand:
$ ps ax --format comm,pid,pri_baz,nice,cls
COMMAND PID BAZ NI CLS
systemd 1 120 0 TS
kthreadd 2 120 0 TS
rcu_gp 3 100 -20 TS
rcu_par_gp 4 100 -20 TS
netns 5 100 -20 TS
kworker/0:0H-ev 7 100 -20 TS
mm_percpu_wq 9 100 -20 T
Linuxrunqueues
Runqueuesarecentraldatastructuresusedbythecorescheduler
to manage active processes. Multiple run queues (one per CPU)
areneededtoavoidcontentionovertaskselectionamongmultiple
processors. Practically speaking, each scheduling class has a run
queue that contains runnable tasks. These tasks are grouped in a
general struct rq foreachcore,structuredasfollows:
//*
* This is the main, per-CPU runqueue data structure.
*
* Locking rule: those places that want to lock multiple runqueues
* (such as the load balancing or the thread migration code), lock
* acquire operations must be ordered by ascending &runqueue.
**/
struct rq {
//* runqueue lock: **/
raw_spinlock_t __lock;
//*
* nr_running and cpu_load should be in the same cacheline because
* remote CPUs use both these fields when doing load calculation.
**/
unsigned int nr_running;
/// .....
struct cfs_rq cfs;
struct rt_rq rt;
19struct dl_rq dl;
/// .....
//*
* This is part of a global counter where only the total sum
* over all CPUs matters. A task can increase this counter on
* one CPU and if it got migrated afterwards it may decrease
* it on another CPU. Always updated under the runqueue lock:
**/
unsigned int nr_uninterruptible;
struct task_struct __rcu *curr;
struct task_struct *idle;
struct task_struct *stop;
unsigned long next_balance;
struct mm_struct *prev_mm;
/// .....
}
Thecfs_rqcontains CFS-related statistics and attributes and
itisdefinedasfollows:
//* CFS-related fields in a runqueue **/
struct cfs_rq {
struct load_weight load;
unsigned int nr_running;
unsigned int h_nr_running; //* SCHED_{NORMAL,BATCH,IDLE} **/
unsigned int idle_nr_running; //* SCHED_IDLE **/
/// .....
//*
* 'curr' points to currently running entity on this cfs_rq.
* It is set to NULL otherwise (i.e when none are currently running).
**/
struct sched_entity *curr;
struct sched_entity *next;
struct sched_entity *last;
struct sched_entity *skip;
/// .....
}
20Figure12: Runqueuesstructure
Linuxschedule() function
Themainschedulerfunction(i.e., schedule() )isinvokeddirectly
inmanypointsinthekernel,toallocatetheCPUtoaprocessother
than the currently active one (e.g., after returning from system
calls/interruptsorwhenathreaddoessomeexplicitblocking,with
mutexes/semaphoresorwhenitisputinsideawaitqueue).
3 Lecture3-ConcurrencyI
Recappingsomedefinitions
Wedefineas programasetofinstructionsstoredsomewhere(e.g.,
disk)butthatarenotdoinganythingatthattime(i.e.,instructions
arenotexecuted). Applications ,instead,aresoftwarewhosemain
goal is to interact with the user, typically with a GUI. Finally, a
processlivesinmemoryanditiscurrentlyinexecution. Notethat
anapplicationismoreuser-oriented,whileprocessesaremoreon
theoperatingsystemside.
21Wedefine threadasthesmallestschedulableunitofexecution
inawaythatthelattercan’tbedividedfurther. A taskisthemost
generaltermandhasanospecificdefinition. Itusuallyreferstoa
singleunitofcomputationataconceptuallevel. Inpractice,itcan
bemappedto:
1.Aprocess;
2.Anapplication;
3.Athread.
In Linux, and not in all operating systems, task is a synonym
ofthread.
Processesvs. threads
Definitionsmayvary,but,lookingattheLinuxview,a processcan
bedefinedasaninstanceofaprogram,whichhasitsisolatedmem-
ory address space. Threads, instead, are multiple in the context
ofaprocess,thustheybelongtotheaddressspaceoftheprocess.
Moreover,athreadsharestheaddressspacewithotherthreadsbe-
longingtothesameprocessandtheyrunsequentiallyontheCPU
(withexceptionsrelatedto hardwareparallelism .
Multi-threadedprogramming
Threadscancommunicateonewitheachotherandtheysynchro-
nizethemselveswhenaccessingshareddata(heap,data,etc.). They
canaccessvariablesbelongingtootherthreads,iftheyknowtheir
addresses.
Figure13: Multi-threadedenvironment
22Multi-processprogramming
Given that two different processes have different address spaces,
weneedanintermediatelayer(i.e.,theoperatingsystem)tocom-
municateonewitheachother10. Thisactivityiscalled inter-process10This intermediate layer has the responsibility of
forwardingdatabetweenprocesses. communication (IPC).
Figure14: PerformingIPCtosharedatabetweenprocesses
Forking
Thestartingpointofaprocess,fromaprogrammingperspective,
isgivenbythelibraryfunction fork(),whichisbasedonthesys-
tem call sys_clone() . The idea is to clone the program and to
makethecomputationstartrightafterthe fork()itself(i.e.,start-
ingfromthenextinstructionafterthecall).
Whena fork()iscalled,theunderlyingoperatingsystemcre-
atesanewaddressspaceandallthevariablessharethesamevalue,
exceptthe fork()’sreturnvalue. Onthe”physical”side,the copy-
on-writestrategyisappliedtoallpages.
1.The process tree Every process has exactly one parent and
mayhaveanarbitrarynumberofchildren. Theonlyexcep-
tion is the initprocess, which is the ancestor of all other
processes.
EveryprocesshasanuniqueidentifiercalledPIDandapar-
ent identifier known as PPID. We can get both the current
PIDandPPIDexecuting,respectively, getpid() andgetppid() .
InLinux,thePIDisof pid_ttype(definedin <sys/types.h> ),
whichiscurrentlya32-bitinteger11.11The PID is limited by the special file
/proc/sys/kernel/pid_max . When the pid_max is
reached,nootherprocesscanbecreated. Notethatthis
isasortofDDoSattack.
23Figure15: Theforkingtechnique
ThebootprocessonLinux
ThebootprocessonLinuxworksinthewaydescribedbelow:
1.Poweron: thesystemispoweredon,thefirmware(BIOS/UEFI)
isloadedinmemory;
2.BIOS:thefirmwareperformschecksandlaunchesthe boot-
loader;
3.Bootloader: the bootloader mounts file-systems and loads
thekernelimage(e.g., /boot/vmlinuz-* );
4.Linuxkernel: Thekernelstartsrunning;
5.Low-level initialization: The first code initializes the CPU,
programstheMMU,doesthetransitionto64-bitmode,etc.;
6.Kernel image decompression: the kernel image is decom-
pressed
7.start_kernel() : non-architecturespecificinitialization: in-
terrupt setup, memory configuration, scheduler initializa-
tion,etc.;
248.Startinitprocess: the initprocessisstarted,bydefaultis
searchesfor /sbin/init .
As we just said, initis the first user-space process launched
at the end of kernel boot. This always has PID = 1andPPID = 0
since it is the ancestor of all user-space processes in the system.
Whatinitdoesistostartallenabledservicesduringstartup(e.g.,
DHCP, web server, graphic server, NTP). There are two common
implementationofthe initsystem:
•System V (legacy): loadsallservicesfrom /etc/init.d and
/etc/rc.d ;
•systemd: loadsallservicesaccordingto /etc/systemd .
Executing
Thefork()byitselfisnotusefultohaveacompleteoperatingsys-
tem and set of overlying applications: we need a way to load and
runanotherexecutable. Forthatmatter,wehavethe exec*()fam-
ilyoffunctions: theyloadanewprogramandreplacethecurrent
processimagewithitbycallingthe execve() systemcall.
Thefork()istypicallyusedonlytogeneratethenewaddress
space, while this address space is populated with a new process
imageusing exec*()functions.
Figure16: fork()andexec()mechanism
Allfunctionsinthe exec*()familytaketheexecutablepathas
thefirstargument:
25Eachfunctionhasslightvariationsbasedonarguments:
•-lfunctionsacceptlistof NULL-terminatedparameters;
•-vfunctionsacceptanarrayof NULL-terminatedstrings;
•-pfunctionssearchthe PATHenvironmentvariable;
•-efunctionsallowtospecifynewenvironmentvariables.
Parent-childbasicsynchronization
Whenwe fork()aprocessandweexecutethesamefunctionboth
in parent and child, we have no assurance that they will perform
operations ”in order”. In other words, scheduling order is unpre-
dictable: we need some synchronization mechanisms. The sim-
plestoneforparent-childrelationisthe wait()basedmechanism:
#include <sys/types.h>
#include <sys/wait.h>
pid_t wait(int *status);
pid_t waitpid(pid_t pid, int *status, int options);
These are two functions performing a simple parent-child syn-
chronization:
•Thewait()suspendstheexecutionuntiloneofthechildren
terminates;
•Thewaitpid() suspendstheexecutionuntilaspecificchild
processterminates(orchangesstate).
Theparameter statusisapointertoavariablewheretowrite
thereturnvalue(anditcanbe NULL),pidisthePIDofthechildto
waitand optionsareextra-optionflags.
Howtoavoidzombies
Zombies are dead processes indeed, but they are still there: they
consume memory and resources because a parent process forgot
tousethe wait()function12.12Processesreturntotheparentonlyifthelatterused
await()functionindeed. Whenaprocessterminates,theLinuxkernelchangesitsstate
to ”zombie” and saves the return value. In particular, the kernel
returns the child’s return value to its parent, when the latter calls
wait(), orwaitpid() , on the child process. If the parent termi-
nates before calling wait(), the child is adopted by init, which
26performs wait()onallchildren,freeingthememoryandthePID
number.
Asaruleofthumb,persistentzombieprocessesinthesystem
areasignofaprogrammingerror.
Inter-ProcessCommunication(IPC)
Since different processes have their own address space, we must
haveawaytoexchangeinformationbetweenthem. Thisproblem
is calledInter-Process Communication . In Linux, there aretwo li-
brariesprovidingIPC:
•POSIX,whichisnewerandthread-safe;
•System V, which is basically a legacy software and it is not
thread-safe.
Signals
Signals are unidirectional and their information content is only
the ”signal type”. This means that there is no data transfer being
performed, and, moreover, they are basically asynchronous. Ex-
amplesofsignalscouldbeelapsedtimers,I/Ooperationsuccesses
orfailureevents,exceptions,user-definedevents,etc.
Rememberthatsignalsarecommunicationmethodsbetween
processes, notthreads ,andtheyaresentbytheunderlyingoperat-
ingsystem. Someexamplescouldbe:
•Aterminatingchildprocesssendinga SIGCHLDtoitsparent;
•An user pressing Ctrl+Con the keyboard, which implies a
SIGINTtotheprocess;
•Aprocesstryingtoexecuteanillegalinstruction, implying
aSIGILLfromtheoperatingsystem;
•Asegmentationfault,whichmeansthata SIGSEGVsignalis
sent.
27Figure17: MostcommonPOSIXsignals
4 Lecture4-ConcurrencyII
Moreonsignals
Sendingasignal
Tosendasignalwecanusethe kill()function:
#include <signal.h>
#include <sys/types.h>
int kill(pid_t pid, int sig);
Wehavethat pidisthePIDofthereceiverprocessand sigisthe
signal to send (i.e., a SIG_<something> constant). The kill()re-
turnvalueis 0onsuccessand -1onerror.
Handlingasignal
To receive and handle a signal we can use the sigaction() func-
tion:
#include <signal.h>
int sigaction(int signum, const struct sigaction *act,
struct sigaction *oldact);
Wehavethat signumisthesignaltocatch(i.e.,a SIG_<something>
constant), actisadatastructurecontainingnewsettingstoapply
in order to register a handler function and oldactis an output
variable, used to save the old set settings if not NULL. The return
valuecouldbe 0onsuccessor -1onerror.
28To register a signal handler we must deal with the sigaction
datastructure:
struct sigaction {
void (*sa_handler)(int);
void (*sa_sigaction)(int, siginfo_t *, void *);
sigset_t sa_mask;
int sa_flags;
void (*sa_restorer)(void);
};
Thestructure’sfieldsarethefollowing:
•sa_handler isahandlerfunction(or SIG_IGN);
•sa_sigaction isanalternativehandler;
•sa_maskisamasktobesettoblockcertainsignals;
•sa_flags containsvariousoptions;
•sa_restorer isnotintendedtobeusedbyuserapplications.
POSIXReal-TimeExtension
ThePOSIXreal-timeextension,whichisavailableonanymodern
Linux,introducesthefollowingfunctions:
•sigqueue() tosendaqueuedsignal;
•sigwaitinfo() tosynchronouslywaitasignal;
•sigtimedwait() tosynchronouslywaitasignal(foragiven
time).
The field sa_signaction in thesigaction data structure, al-
lows to specify a handler that accepts an input data. Flags must
contain SA_SIGINFO .
Maskingasignal
Signalscanbemasked(i.e.,blocked)toavoiddisruptingourcode
execution. Themaskingprocessissimilarto SIG_IGN,butinstead
ofbeingdropped,theyareenqueuedandmanagedlaterwhenthe
processunmasksthesignal. Notethat SIGKILLandSIGSTOPcan’t
bemasked.
Wehavethefollowingfunctionprototype:
29int sigprocmask(int how, const struct sigset_t *set,
struct sigset_t *oldset);
Where howcouldbeeither SIG_BLOCK (i.e.,addtothemask), SIG_UNBLOCK
(i.e.,removeasignalfromthemask), SIG_SETMASK (i.e.,replacethe
mask),then setisthesetofsignalsand oldsetistheoutputvalue,
whichistheprevioussetofsignals.
Unnamedpipes
Unnamedpipes areaPOSIX-definedmechanismtoletparentand
childprocessescommunicate. Toletgeneralprocessescommuni-
cate with each other there is another POSIX-defined mechanism
callednamedpipes (FIFO)thatwearegoingtodiscusslateron.
Unnamedpipesarebasedontheproducer/consumerpattern:
oneproducerwritesandoneconsumerreads(i.e.,thecommuni-
cationisunidirectional). Dataiswritten/readinafirst-in-first-out
(FIFO)fashion,asshowninfigure.
Figure18: Howunnamedpipeswork
In Linux, the operating system guarantees that only one pro-
cess at a time can access the pipe, using a so-called implicit syn-
chronization .
Creatingapipe
Tocreateapipewecanusethefollowingfunctions:
#include <unistd.h>
#include <fcntl.h>
int pipe(int pipefd[2]);
int pipe2(int pipefd[2], int flags);
We have that pipefdis an array of two integers to be filled with
twofiledescriptors:
•pipefd[0] isthefiledescriptorofthe readendofthepipe;
30•pipefd[1] isthefiledescriptorofthe writeend ofthepipe.
Theflagsparameter,instead,canbeeither:
•O_CLOEXEC :closethefiledescriptorif exec*()iscalled;
•O_DIRECT:performI/Oin”packetmode”;
•O_NONBLOCK :avoidblockingread/writeincaseofempty/full
pipe.
Usingapipe
Touseapipewecaneitherdoitdirectlywithlow-levelI/Ofunc-
tions,suchas
ssize_t write(int fildes, const void *buf, size_t nbyte);
ssize_t read(int fildes, void *buf, size_t nbyte);
orwecantransformourfiledescriptortoastream,using
#include <stdio.h>
FILE *fdopen(int fildes, const char *mode);
andthenexploitallthe f*functions(e.g., fwrite(),fread(),fprintf() ,
fscanf()).
Namedpipes(FIFO)
Named pipes have basicallythesamebehaviorofunnamed ones:
oneproducerwritesandoneconsumerreads(i.e.,thecommuni-
cation is unidirectional). In other words, data is written/read in
a first-in-first-out (FIFO) fashion (as unnamed pipes indeed), as
showninfigure.
Figure19: Hownamedpipeswork
Named pipes, differently from unnamed ones, are based on
special files created in the file-system and not on file descriptors.
Data is transferred in the same way as reading/writing to a disk
file,butnoactualI/Ooperationisinvolved: theoperatingsystem
passesdatafromoneprocesstoanother.
31CreatingaFIFO
TocreateaFIFO,wecanuse
#include <sys/types.h>
#include <sys/stat.h>
int mkfifo(const char *pathname, mode_t mode);
Where pathname istheusual path + filename ofthefiletobecre-
ated,modeis related to file permissions we want the file to have
(e.g.,S_IWUSRare file permissions for the owner 0200). Then, we
onlyneedtojustuse open(),write()orread()toaccesstheFIFO.
Messagequeues
Message queues are an IPC method suitable for multiple readers
andmultiplewriters. Theyarebasedonapriority-queueandworks
asshowninfigure.
Figure20: Howmessagequeueswork
Thestatusofthemessagequeuecanbeobservableandallspe-
cialfilesrelatedtothequeuesareinasystem-widedirectory,which
is/dev/mqueue . When using message queues we are required to
linkourexecutablestothePOSIXreal-timeextensionlibrary13.13Thismeansthatweshouldcompilewith gccusing
theflags -lrt.
Opening/creatingamessagequeue
Toopen/createamessagequeuewecanuse
#include <mqueue.h>
mqd_t mq_open(const char *name, int oflag, mode_t mode,
struct mq_attr *attr);
wherenameisauniquenameforthemessagequeue(startingwith
/),oflagis an opening flag (e.g., O_RDONLY,O_WRONLY,O_CREAT),
modeisrelatedtofilepermissionstogivetothefile(onlyfor O_CREAT),
andattrareattributes:
32struct mq_attr {
long mq_flags; /// 0 or NON_BLOCK
long mq_maxmsg; /// max nr. messages in the queue
long mq_msgsize; /// max message size in bytes
long mq_curmsg; /// nr. messages currently in the queue
}
There are also other management functions, such as the fol-
lowing:
#include <mqueue.h>
int mq_close(mqd_t mqdes);
int mq_unlink(const char* name);
int mq_getattr(mqd_t mqdes, struct mq_attr *attr);
int mq_setattr(mqd_t mqdes, const struct mq_attr *newattr,
struct mq_attr *oldattr);
Messagequeueinput/output
Tosendmessagesoveramessagequeuewecoulduse:
#include <mqueue.h>
int mq_send(mqd_t mqdes, const char *msg_ptr, size_t msg_len,
unsigned int msg_prio);
We have that mqdesis the message queue descriptor, msg_ptris
thepointertothemessagetobesent, msg_lenisthelengthofthe
message (in bytes) and msg_prio is a non-negative priority value
in the range [0;31]14. The higher msg_prio value is, the higher14Themaximumpriorityvaluecanbelargerinsome
implementations(POSIXrequiresatleast32priorityval-
ues).the priority, while for messages with the same priority the FIFO
approachisapplied.
Toreceivemessagesfromthequeuewecanuse:
#include <mqueue.h>
int mq_receive(mqd_t mqdes, char *msg_ptr, size_t msg_len,
unsigned int *msg_prio);
Wehavethat mqdesisthemessagequeuedescriptor, msg_ptristhe
outputparameter(pointertoabuffertofill), msg_lenisthelength
(inbytes)ofthebufferand msg_prio istheoutputparameter(the
priorityofthemessage).
33Sharedmemory
Shared memory is an IPC mechanism to allow two processes to
shareamemorysegment. InPOSIX,thesharedmemoryisbased
on thememory mapping concept. To use shared memory, we
should link, when compiling, to the POSIX real-time extension
libraryusing gccwithflags -lrt.
Figure21: Thesharedmemory
Like message queues, opening/creating shared memory seg-
ment is referenced by a name. In Linux, a spacial file is created
under/dev/shm/<name> .
Opening/creatingasharedmemory
Toopenasharedmemoryregionwecanuse:
#include <sys/mman.h>
#include <sys/stat.h>
#include <sys/fcntl.h>
int shm_open(const char *name, int oflag, mode_t mode);
Where nameisauniquenameforthesharedmemory(startingwith
/),oflagis the opening flag (e.g., O_RDONLY,O_WRONLY,O_CREAT)
andmodeisrelatedtofilepermissionstogivetothefile. Thisfunc-
tionreturnsafiledescriptor.
Aftercreatingasharedmemoryobject,weshouldspecifythe
sizeofthespecialfiletobecreated:
#include <unistd.h>
#include <sys/types.h>
int ftruncate(int fd, off_t length);
34Wehavethat fdisthefiledescriptortotruncateand lengthisthe
sizeinbytes.
Mappingthememory
We can map a file or a device to the virtual address space of the
callingprocess:
#include <sys/mman.h>
void *mmap(void *addr, size_t length, int prot, int flags,
int fd, off_t offset);
We have that addris the starting virtual address15,lengthis the15When this address is NULLwe leave the kernel to
selectitforus. sizeofthemappedsegment, protisrelatedtomemoryprotection
flags(i.e., PROT_EXEC ,PROT_READ ,PROT_WRITE ,PROT_NONE ),fdisthe
filedescriptor, offsetistheoffsettoskiptostartingfromthebe-
ginning of the file descriptor and flagsis related to the visibility
oftheupdatesw.r.t. otherprocesses16.16Forinstance,wecouldhave:
•MAP_SHARED : updates are visible to other pro-
cesses and carried out through the underlying
file;
•MAP_PRIVATE : enable copy-on-write, which
means that updates are not visible to others and
arenotcarriedoutthroughtheunderlyingfile;
•etc.Cleaningstuff
Tocleanmemoryregionswemapped,wecanusethefollowing:
#include <sys/mman.h>
int munmap(void *addr, size_t length);
int shm_unlink(const char *name);
We have that munmap() deletes the mappings for the specific ad-
dressrange,while shm_unlink() removesthesharedmemoryob-
jectcreatedby shm_open() .
Howtosynchronizeprocesses
Wehaveseenthatitispossibletosynchronizetwoprocessesusing
await()orwaitpid() approach, but this is clearly very limited.
Anyway,synchronizationisneededinamulti-processscenarioto
avoidraceconditionsonsharedresources(sharedmemoryalmost
alwaysrequiressynchronization).
Forthatmatter,POSIXprovidesinter-process semaphores ,which
haveaverysimplegenerallogic:
•semaphore_counter = 0 ,thenWAIT;
•semaphore_counter > 0 ,thenPROCEED.
35When a counter can only be either 0or1, it is called binary
semaphore and behaves similarly to a mutex. We have two main
atomicfunctions:
•wait(): blockuntil counter > 0 ,thendecrementitandpro-
ceed;
•post(): incrementthecounter.
Similarly to pipes, POSIX semaphores can be namedorun-
named. TheyrequirethePOSIXthreadlibrary,whichmeansthat
weneedtousethe -pthread flagwhencompilingwith gcc.
Unnamedsemaphoreinitialization/destruction
Toinitializeasemaphorewecanuse:
#include <semaphore.h>
int sem_init(sem_t *sem, int pshared, unsigned int value);
We have that semis the output parameter (i.e., semaphore data
structuretoinitialize), psharedestablisheswhetherthesemaphore
issharedamongthreads(equalsto 0)ornot(differentfrom 0)and
valueistheinitialvalue. Thefunctionreturns 0onsuccessand -1
onerror.
Todestroyasemaphorewecanuse:
#include <semaphore.h>
int sem_destroy(sem_t *sem);
Namedsemaphoreinitialization/destruction
Toinitializeanamedsemaphorewecanuse:
#include <semaphore.h>
sem_t *sem_open(const char *name, int oflags);
sem_t *sem_open(const char *name, int oflags, mode_t mode,
unsigned int value);
Wehavethat nameisthePOSIXobjectname, oflagsareopening
flags (O_CREAT,O_EXECL),modeis related to file permissions and
valueis the initial value. Those functions return the pointer to
thesemaphoreobjector SEM_FAILED incaseoferrors.
Functions
36#include <semaphore.h>
int sem_close(sem_t *sem);
int sem_unlink(const char *name);
are functions to, respectively, close the named semaphore or re-
movethenamedsemaphoreobject.
Synchronizationfunctions
The following are functions used to synchronize processes based
onPOSIXsemaphores:
#include <semaphore.h>
int sem_wait(sem_t *sem);
int sem_trywait(sem_t *sem);
int sem_timedwait(sem_t *sem, const struct timespec *timeout);
Wehavethat semisthesemaphoreobjectand timeoutisthetime
limittowaitifthesemaphorecounterisequaltozero. The sem_trywait()
isthenon-blockingversionof sem_wait() . Allfunctionsreturn 0
forsuccessor -1incaseoferror.
5 Lecture6-ConcurrencyIII
Terminology
Taskhasnouniquedefinition,butwecanrefertoitasasynonym
ofthread: it represents a computation performed by the proces-
sorinasequentialfashion. The scheduler istheoperatingsystem
component in charge of establishing the execution order of tasks
(calledschedule). Inthatcontext,theorderingalgorithmiscalled
scheduling policy . The activity of dispatching , instead, is about al-
locatingaprocessortoaspecifictask.
Introductiontoscheduling
Typically, we have a set of tasks that at some point will be exe-
cuted. Inordertodothat,theystartthe activation phaseandthey
aremovedtotheoperatingsystem readyqueue . Thescheduler,in
turn,picksataskfromthisreadyqueue,allowingittoaccessitsre-
sourcestobeexecuted. Itislikelythatthistaskwillbepreempted
(because,forsomereason,itwasexecutingfortoolong),thusthe
scheduler de-allocates its resources and picks another task from
37this ready queue to be executed. This preemption is performed
viaacontextswitch . Thecrucialthingtounderstandisthatwhen
a task is preempted it doesn’t mean that it was blocked (i.e., pre-
emptionandblockingaretwodifferentconcepts): ataskcanvol-
untarilysuspenditsexecutiontowaitforI/Odata(e.g.,keyboard
input, file input/output). In that case, the task is put into the I/O
queueandtheCPUwillbecomeavailabletorunothertasks.
Figure22: Schedulingconceptualdiagram
Taskstatesarenotsostraightforward,aswehaveseenduring
the previous lectures, since, in the Linux kernel, there are a lot
morestateswithdifferentpurposes17:17Seealso https://elixir.bootlin.com/linux/v5.
19.12/source/include/linux/sched.h#L83 .
//* Used in tsk->state: **/
#define TASK_RUNNING 0x0000
#define TASK_INTERRUPTIBLE 0x0001
#define TASK_UNINTERRUPTIBLE 0x0002
#define __TASK_STOPPED 0x0004
#define __TASK_TRACED 0x0008
//* Used in tsk->exit_state: **/
#define EXIT_DEAD 0x0010
#define EXIT_ZOMBIE 0x0020
#define EXIT_TRACE (EXIT_ZOMBIE | EXIT_DEAD)
//* Used in tsk->state again: **/
#define TASK_PARKED 0x0040
#define TASK_DEAD 0x0080
#define TASK_WAKEKILL 0x0100
#define TASK_WAKING 0x0200
#define TASK_NOLOAD 0x0400
#define TASK_NEW 0x0800
//* RT specific auxilliary flag to mark RT lock waiters **/
#define TASK_RTLOCK_WAIT 0x1000
#define TASK_STATE_MAX 0x2000
38//* Convenience macros for the sake of set_current_state: **/
#define TASK_KILLABLE (TASK_WAKEKILL | TASK_UNINTERRUPTIBLE)
#define TASK_STOPPED (TASK_WAKEKILL | __TASK_STOPPED)
#define TASK_TRACED __TASK_TRACED
#define TASK_IDLE (TASK_UNINTERRUPTIBLE | TASK_NOLOAD)
Thetaskmodel
Letusdefinethe taskmodel beforetalkingaboutschedulingpoli-
cies. Consider a set of tasks T=f1; 2; : : : ;  ng. Those tasks
haveseveralparameters:
•Thearrival time (orrequest time )ai, which is the time in-
stant at which the task is ready for execution and put into
thereadyqueue;
•Thestarttime si,whichisthetimeinstantatwhichtheex-
ecutionactuallystarts;
•Thewaitingtime Wi,whichisthetimespentwaitinginthe
readyqueue. Inotherwords
Wi=si ai;
•Thefinishingtime (orcompletiontime )fi,whichisthetime
instantatwhichtheexecutionterminates;
•Thecomputation time (orbust time, orexecution time )Ci,
which is the amountof time necessary for the processor to
executethetask withoutinterruptions ;
•Theturnaroundtime Zi,whichisthedifferencebetweenfin-
ishingtimeandarrivaltime,namely
Zi=fi ai:
Note that Ziis not necessarily Wi+Ci, since in case of pre-
emption or suspension, Zicontains also the interferences from
other tasks and the I/O waiting time (which is the time the task
hasbeeninterrupted).
39Figure23: Task’sparameters
Figure24: Task’sparametersandtimeline
Taskboundness
Depending on the type of operations dominating the lifetime of
atask,wemayidentifyits”boundness”18asCPU-bound andI/O18Theboundnesscouldbe,ingeneral,ofthreediffer-
enttypes: I/Oboundness,CPUboundnessandmemory
boundness,whichisamorerecentterm. Inthischapter
wewillconsideronlythefirsttwotypesofboundness.bound. CPU-bound means that the task spends most of its time
executingoperations:
ZiWi+Ci;
notconsideringpreemptions.
Figure25: ACPU-boundtask
I/O-boundmeansthatthetaskspendsmostofitstimewaiting
forI/Ooperations:
ZiWi+Ci;
notconsideringpreemptions.
Platformmodel
Acomputingsystemiscomposedof:
40•mprocessingelements (PE),namelyCPU =fCPU 1; : : : ;CPU mg;
•sadditionalresources ,namely R=fR1; : : : ; R sg.
EachPE,ateachtime t,isassignedtozerooronetask,namely
Ac(CPU k; t) =ior;. A task ican execute at time tonly if
9A(CPU k; t) =i.
Moreover,eachresource,ateachtime t,isassignedtozeroor
more tasks, namely Ar(Rk; t) =f1; 2; : : :gor;. Depending
on the type of the resource, Rkcould be exclusive: in that case,
Ar(Rk; t)can’tcontainmorethatonetask. Atask icanexecute
attime tonlyif i2Ar(Rk; t)8Rkrequiredtorunthetask.
Problemstatement
The problem statement is the following: given a set of ntasks,
T=f1; : : : ;  ng, a set of mPES, CPU =fCPU 1; : : : ;CPU mg
(ifm > 1we have a multi-core ormulti-CPU system), a set of
resources, R=fR1; : : : ; R ng, and an optional set of precedent
relationships and constrains (e.g., 5must execute before 2), we
have to compute an optimalschedule (i.e., tasks order) and allo-
cations(i.e., Ac(Rk; t); Ar(Rk; t)). However,mostoftheseprob-
lems(i.e.,theyreducetothe knapsack problem)areNP-complete.
Schedulingmetrics
The scheduler aims at optimizing one (or more objectives) de-
pendingonthedomaininwhichtheprocessoroperates(e.g.,em-
bedded systems, servers, laptops). There are several metrics to
consider:
•Processorutilization: percentageoftimetheCPUisbusy;
•Throughput: number of tasks completing their execution
pertimeunit;
•Waiting time (average): average time the task spent in the
readyqueue;
•Fairness: whethertaskshaveafairallocationoftheproces-
sor;
•Overhead: amountoftimespentintakingschedulingdeci-
sionsandcontext-switches;
41Figure26: Schedulingmetricsandtradeoffs
•Othermetrics: energy,power,temperature,reliability,etc.
UsuallywewanttomaximizetheCPUutilization,thethrough-
put and the fairness, while we want to minimize the turnaround
time,thewaitingtime,thecompletiontimeandtheoverhead.
Something we definitely don’t want to have is starvation , an
undesirable perpetuated condition in which one (or more) tasks
can’teexecutedduetothelackofresources. Whateveristheobjec-
tiveofascheduler,agoodschedulingalgorithmshouldguarantee
thatalltasksareserved. Forinstance,inafixed-priorityschedul-
ingpolicy,thesituationinwhichastarvationcouldoccuriswhen
wehaveahighprioritytaskkeepingbusytheCPUandnotallow-
ingotherlowerprioritytaskstoexecute.
Classificationofschedulingalgorithms
Now,let’strytoclassifyschedulingalgorithmsbasedontheirchar-
acteristics.
We havepreemptive ones, where running tasks can be inter-
rupted (by the operating system) at any time to allocate the pro-
cessortoanotheractivetask. Thisisnecessaryifweneedarespon-
sive system. Non-preemptive schedulers, instead, are such that,
once started, a task is executed until its completion (i.e., run-to-
completion ). Scheduling decisions can be taken only when a task
terminates: this guarantees minimum overhead, but this is not
goodforaresponsivesystem.
Staticscheduling means that decisions are based on fixed pa-
rameters, whose values are known before task activation. In this
42case, strong assumptions are required. Dynamic schedulers, in-
stead, are such that their decisions are based on parameters that
changes at runtime, during the task execution. They may need
a run-time feedback mechanism to adapt their parameters dur-
ingtheexecution. Moderngeneralpurposeoperatingsystemsare
usually a mix of the two categories: for instance, task priority is
usually known before execution, but the completion time is un-
known.
Goingfurther, offlineschedulersaresuchthattheyexecuteon
a set of known tasks before their activation. Their output is the
sequence of tasks to execute, called schedule. Clearly, they need
to be static (since we need to know all the parameters) thus they
are very limited, but often necessary when we want to provide
some formal guarantees. Onlineschedulers execute at runtime
and can schedule new and previously unknown tasks. Modern
generalpurposeoperatingsystemsaretypicallyonline.
Finally, we have optimalschedulers, which are based on al-
gorithmsoptimizingagivencostfunction,definedoverataskset.
Thealgorithmmybetoocomplex,withanhighoverhead. Heuris-
ticschedulers, instead, are based on heuristic functions and they
tendtooptimalscheduling,butwithoutanyguaranteeaboutachiev-
ingit. Generally,theyaremuchfasterthanoptimalalgorithms.
Schedulingalgorithms
Let’s now see the most famous scheduling algorithms and their
characteristics.
First-in-first-out(FIFO)
FIFO schedulers are such that tasks are scheduled in order of ar-
rival. They are non-preemptive and they are also known as first-
come-first-served (FCFS).Theyareverysimpleanddonotrequire
anyknowledgeoftheprocesses. Asdrawbacks,theyarenotgood
forresponsiveness: longtasksmaymonopolizetheprocessorand
shorttasksarepenalized(andmayevenstarve).
ShortestJobFirst(SJF)
SJF schedulers are such that tasks are executed in ascending or-
der of computation time Ci. They are non-preemptive and also
knownas shortest-job-next (SJN).SJFalgorithmsareoptimalnon-
preemptive ones with respect to the minimization of the average
43Figure27: FIFOexample
time, but we have a risk of starvation for long tasks and we need
toknowtheexecutiontime Ciinadvance,whichisnotcommon
ingeneralpurposeoperatingsystems.
Figure28: SJFexample
ShortestRemainingTimeFirst(SRTF)
SRTFisthepreemptivevariantofSJFandusestheremainingex-
ecution time instead of Cito decide which task to dispatch. For
thisreason,itimprovestheresponsivenessforalltaskscompared
44toSJF.Asdrawbacksthereisariskofstarvationforlongtasksand,
moreover,weneedtoknow Ciinadvance.
Figure29: SRTFexample
HighestResponseRatioNext(HRRN)
HRRNisanon-preemptiveschedulingalgorithmanditworksin
thefollowingway: itselectsthetaskwiththe highestresponseratio :
RRi=Wi+Ci
Ci: (1)
This algorithm prevents starvation with respect to SJF, but again
weneedtoknow Ciinadvance.
1.SJFvs. HRRNLetuscompare,forinstance,SJFandHRRN
with a different task set. When we have small tasks, the
longest one risks starvation in SJF, while in HRRN it in-
creases its response ration, gaining priority over the short
tasks.
RoundRobin(RR)
RRisapreemptive schedulingalgorithmsuchthattasksaresched-
uledforagiventimequantum q(alsocalled timeslice). Whenthe
time quantum expires, the task is preempted and moved back to
thereadyqueue.
45Figure30: HRRNexample
Figure31: SJFvs. HRRNwithanexample
46Insuchasetting,themaximumwaitingtimecanbecomputed
inthefollowingway
Wmax
i= (n 1)q;8i: (2)
Moreover, there is no need to know Ciin advance. RR is good
toachievethefairnessandresponsivenessgoalsandnostarvation
is possible. Asdisadvantage, wehavethattheturnaroundtimeis
worstthanSJF.
Figure32: RRexample
Notethatwehavealotofcontextswitches,thusdependingon
thesystemweareintitcouldpenalizetheexecutiontimeabit.
InLinux,toinspectthequantumsliceallocatedforRRpolicies
wecantypethefollowing:
$ cat /proc/sys/kernel/sched_rr_timeslice_ms
90
1.Choosing the quantum value The activity of choosing the
RR quantum value is critical: choosing a ”long” quantum
will make the scheduler to tend to a FIFO one and will fa-
vorCPU-boundtasks. Thiswillimplyalowoverhead,since
therewillbelesscontextswitches. Choosinga”short”quan-
tum,instead,willreducetheaveragewaitingtime,favoring
I/O-bound tasks. This would be good for responsiveness
and fair scheduling. However, we would have a high over-
head,sincetherewillbemorecontextswitches.
476 Lecture7-ConcurrencyIV
Priority-basedscheduling
Thepriority Piis a task parameter through which we can spec-
ify the importance of a task, and it can be fixed(i.e., known at
design-time)or dynamic (i.e.,changesatrun-time). Thepriority
is usually expressed using an integer value: the lower the integer
value,thehigherthepriority(andviceversa).
Wedefineas multi-queuescheduling aschedulingsystemsuch
that, for each queue, we can specify a different scheduling algo-
rithm(e.g.,RRorFCFS).Thefirsttasktoscheduleispickedfrom
thetopmostnon-emptyqueue,whichalsohasthehighestpriority.
Anothercrucialaspectisthattaskscan’tbemovedfromoneready
queuetoanother. Finally,thequeueschedulingis preemptive .
Figure33: Multi-levelqueueschedulingscenario
Insuchascenario, clearlythereisariskof starvation : whilst
highestpriorityqueuesarepopulatedbynewtasks,thescheduling
ofthosetasksbelongingtolowerpriorityqueuesisdelayed.
Priority-basedwithRoundRobinpolicy
Let us consider a priority-based multi-level queue scheduling as-
signingRRtoeachqueuewithdifferentquantumslices. Suppose
thatthepriorityisselectedontheworkloadtypeasfollows: CPU-
boundtaskshavealowpriority(thereforeahighquantumvalue),
I/O-boundtaskshavehighpriority(thereforealowquantumvalue)
19. Thispriorityschemeguarantees responsiveness ,butstarvation19There are several ways to determine if a task is
CPU-bound or I/O-bound. For instance, we could dis-
tinguish it using information provided both by the user
or by the program itself (using a rum-time feedback
mechanism), or we can use a multi-level feedback queue
scheduling.48isalwaysaconcreterisk,assaidpreviously.
Multi-levelfeedbackqueuescheduling
Thisschedulingmodelworkslikethepreviousmulti-levelRRscheme,
butthepriorityisnow dynamic: thenew/activatedtaskismoved
to the highest priority queue (i.e., lowest quantum value), then if
thequantumoftherunningtaskexpires,thetaskismovedtothe
next queue with lower priority (i.e., higher quantum value). This
means that CPU-bound tasks are progressively moved in queues
withlongertimequantum.
Anyway,alsointhiscasewedidn’tsolvedtheproblemofstar-
vation. Therearebasicallytwowaystosolvestarvationinamulti-
levelschedulingscenario:
•Timeslicing;
•Aging.
1.Multi-level feedback queue scheduling with time slicing In
thisscenario,eachqueuegetsa maximum percentageofthe
available CPU time it can use to schedule the task, which
determines a time quota . If the time quota expires, the re-
maining tasks in the queue are skipped, and the scheduler
startpickingtasksfromthenext(lowerpriority)queue.
Forinstance,wecouldhavethefollowing:
Queue Quota Period
Q1 80ms 100ms
Q2 15ms 100ms
Q3 5ms 100ms
So,Q1has the highest priority, but it can’t schedule tasks
for more than 80ms. The valueP
iquotaican be larger
thantheperiodbutitisguaranteedtohavenostarvationifP
iquotaiperiod. However,wecanstillhavestarvation
duetotheschedulingpolicyofoneofthequeues.
a)Multi-level queue scheduling: the case of the Linux
scheduler The Linux scheduler is a multi-level queue
scheduler withseveralqueueswithaquotaandperiod
definedinthefollowingfiles:
49quota = /proc/sys/kernel/sched_rt_runtime_us
period = /proc/sys/kernel/sched_rt_period_us
Figure34: TheLinuxscheduler
Theschedulingpolicyissetbytheuser/systemadmin-
istrator. Notethatif IDLEischosenforatask,thelatter
maystarve.
2.Multi-levelfeedbackqueuewithagingInthiscase,thepri-
orityofthetaskisincreaseddynamically,aslongasitspends
timeinthereadyqueue(i.e.,itgetsolder). Theideaisthat,
atacertainpoint,thetaskwillbeserved. Theagingtimeis
basicallyadefinedperiodafterwhichataskwillgainprior-
ity and jump into a more prioritized queue. This approach
prevents a task from being indefinitely postponed by new
cominghigherprioritytasks. Inotherwords,itavoidsstar-
vation.
Multi-processorscheduling
Suppose that we have a multi-processor machine and we want to
design a scheduler taking into account the underlying architec-
ture. Thescheduler,indeed,mustchoosebetweenthetasktoexe-
cuteandtheprocessortowhichsuchtaskisassigned.
Multi-processorschedulingishard
Thisscenariointroducessomenewproblems,suchasthefollow-
ing:
•Tasksynchronizationmayoccuracrossparallelexecutions;
50•Difficultiesinachievingahigh-levelofutilizationofthewhole
setofprocessors(orCPUcores);
•Simultaneous(notonlyconcurrent)accesstosharedresources,
whichissometimeshierarchicalandmulti-level(e.g.,cache
memories).
Thisissufficienttoprovethatmulti-processorschedulingisa
veryhard problem. Forinstance,inamodernarchitecture(witha
L1exclusivecacheandaL2/L3sharedcache)therecouldbeprob-
lems related to loading pages from main memory to cache: tasks
may interfere one with each other, thus slowing down their exe-
cution20. Decideonwhichprocessorataskshouldbeexecutedis20Thereasonwhythishappensisthatsomememory
locationsmayendupinthesamecacheline,colliding. crucial to avoid such a scenario: make tasks colliding being exe-
cutedoncoreshavingaL2notsharedbetweenthemiskey.
Designchoices
Therearebasicallytwomaindesignchoices:
•Singlequeuesvs. multiplequeues;
•Singleschedulervs. multipleper-processorschedulers.
1.ChoosingthenumberofqueuesA singlequeue approachis
suchthatallthereadytaskswaitinthesame globalqueue ,
asshowninfigure.
Figure35: Singlequeueapproach
Thisimpliesasimpledesignanditturnsouttobegoodfor
fairness and for managing the CPU utilization. However,
51it has obvious problems of scalability: the scheduler runs
inanyprocessorandrequiresasynchronizedversionofthe
readyqueue(e.g.,usingasemaphore/mutex).
Usingmultiplequeues ,instead,requirestohaveareadyqueue
foreachprocessorandeachofthesehavetwooptions:
a)Tokeep,inturn,severalqueuesoneforeachpriority;
b)Tokeepadatastructuretoefficientlyreordertasksin-
sideasinglequeueandschedulethemaccordingly.
Moreover,foreachqueuewecouldusedifferentscheduling
policies.
Thissolutionssoundslikeamorescalableapproach,butalso
haspotentiallymoreoverhead(i.e.,moredatastructuresto
handle). Usingamultiplequeueapproachitcouldbeeasier
to exploit data locality (i.e., processor affinity) and there is
thepossibilitytoadoptasingleglobalschedulerorper-CPU
schedulers. Finally,thisapproachrequires loadbalancing .
a)LoadbalancingUnbalancedreadyqueueshaveavery
negative impact for several reasons: from a CPUuti-
lizationperspective, processors may be idle (due to
empty queues), while other queues may have a lot of
waiting tasks, from a performance perspective, wait-
ingtimesandresponsetimescanbereducedbymov-
ingtasksinadifferentqueue(e.g.,withalowernum-
ber of tasks). Unbalanced ready queues have a neg-
ative impact also on thermal management : balanc-
ing the ready queue levels the temperature distribu-
tion,andthisimpactspowerconsumption,energyef-
ficiencyandreliability.
Figure36: Ascenarioinwhichloadbalancingisneeded
b)TaskmigrationLoadbalancingistypicallyperformed
viataskmigration: tasksaremovedtoadifferentqueue
52(usuallycontaininglesstasks)andthisasaconsequence
onthecacheoverheadandinterference,aswehaveal-
readyseen. Therearetwopossibleimplementations:
•Pushmodel : adedicatedtaskperiodicallychecks
the queues’ lengths and moves tasks if balancing
isrequired;
•Pullmodel : eachprocessornotifiesanemptyqueue
conditionandpickstasksfromotherqueues.
Forinstance, workstealing isanexampleofpullmodel-
basedapproach: eachper-CPUschedulercan”steal”a
task from other queues in case of an empty one. This
is scalable in theory, but we need to protect the con-
currentaccesstothereadyqueuewithlocks.
c)Hierarchicalqueues Hierarchicalqueues isanapproach
involvingmultipleschedulers. Aglobalqueuedispatches
tasks in local ready queue with a hierarchy of sched-
ulers. In this way, we can have a better control over
the CPU utilization and load balancing, along with a
good scalability. Of course, this model is way more
complextoimplement.
Figure37: Hierarchicalqueuesscheme
7 Lecture8-ConcurrencyV
Introductiontoconcurrency
Concurrency is a situation in which a program composed by ac-
tivities such that one of them canstart before the previous has
finished. In other words, if that happens, the program would be
correctevenifthoseinstructionexecuteinanoverlappedfashion.
Considerthatconcurrencyisa”possibility”. Differentpartor
unitsofaprogramcanbeexecutedinanoverlappedway without
affectingthefinaloutcome ,butensuringtohavedifferentprogram
53counters, stacks and registers for variables. In particular, ”can” is
notequalto”must”: wecanexecuteconcurrentactivitieswithout
overlapping them. However, they will not meet expected dead-
linesorresponsetimesandthiscanbeimpossiblewhentheseac-
tivitiesareinfiniteloops.
Onewayofoverlappingtheseactivitiesisthroughthe thread-
ing model : the operating system allows to stop one activity, save
itsstateandstartfromanotheronebyrestoringitsstate.
Figure38: Threadingmodelasconcurrencyparadigm
Besidesthewell-knownthreadexecutionmodel,wecouldwant
itsbenefitsbutinamorereal-timescenario21,sothereisanother21What we do not typically want is to waste time in
contextswitching. executionmodelfamilycalled lightweightexecutionmodels : we
wantconcurrencybutwealsotoavoidtheoverheadresultingfrom
contextswitches. Lightweightexecutionmodelsaretypicaloflan-
guages supporting co-routines andgenerators . In case we have an
application based on external events (e.g., server), we can use a
subsetoflightweightexecutionmodels: continuationpassing (i.e.,
callbacks - e.g. Nodejs) and languages supporting asynchronous
wait22.22C++recentlyadoptedasynchronouswait,butJava
andRusthaveitforalongtimenow. Historically, operating systems supported through a uniform
interface the thread execution model. Now, it is more and more
common to have support to other mechanisms as well, such as
event-basedI/O.
54Figure39: Concurrencytaxonomy
Hardwareparallelismanditsboundaries
Softwareparallelismiscrucialnowadays,becauseofhardwarepar-
allelism’s limits: the frequency of operations (in MHz) hit a wall,
mainlybecauseofpowerconsumption(whichimpactsthecostof
thechipitself,becauseofcoolingmechanisms). Therefore,single-
threadedperformancereachedaplateau,nonethelesswehavemore
andmoretransistors23.23According to the Moore’s law the number of tran-
sistorsdoubleseverytwoyears. Originally, frequency was used as the main knob to obtain
moreperformance. Increasingfrequencyimpliesalsoanincrease
inpowerconsumptionand,since20years,asshowninpicture,we
reachedapowerthresholdwhichmakesitimpracticaltoincrease
evenmore.
Figure40: Reachingthepowerwall
Micro-architectural techniques allowed for some time to in-
crease the single thread performance by better exploiting avail-
55able transistors while keeping everything within its power enve-
lope. Nevertheless, the more transistor are available the more we
have resources to be exploited by multiple threads the more an
operatingsystembecomesimportant. However,havingaparallel
programmayleadtosomeissues,aswearegoingtosee.
Concurrencyissuesandprevention
Whenwehaveaconcurrentprogram,wecancharacterizeitusing
twoconcepts:
•Safety(i.e.,correctness);
•Liveness(i.e.,progress).
Theideaoflivenessisthat,atsomepoint,ourprogramisgoing
to terminate, reaching a final state (this also means that our pro-
gram never blocks in a state but can always progress). However,
our program canchange states and never blockonly if we do not
havedeadlocks.
Deadlocks are not the only problem, but there are others like
priority inversion (a high priority thread is delayed by a lower
priorityone)whichsurelyneedssomeattention.
Safety-relatedissuescanbecategorizedinseveralways,aswe
aregoingtosee: theyaremainlynon-deadlocksbugsandthema-
jorityofthemare atomicity andorderviolation (i.e.,dataraces ).
Dataraces
Data race isthefirstconditionthatcanimpactonsafety: twoin-
structions of two different threads that access the same variable
should synchronize to avoid conflicts. In other words, when our
program’s substantive behavior depends in an uncontrolled way
fromthememorymodelanthetimingofinvolvedthreads,ifthis
isundesirable,weareinfrontofadata-race-likeproblem. Theac-
tual data race happens whenever we have two instructions, say a
andb(in different threads), where at least one of them is a write
andwhenthereisnothingthatenforceseither a<mborb<ma
24.24We are not sure on the order in which the two in-
structionsaregoingtoexecute.
1.Atomicityviolation Atomicityviolation alsoimpactsonsafety.
Letusconsiderthefollowingblockofcode:
56/// Thread 1:::
if (thd->proc_info) {
fputs(thd->proc_info, .....);
}
.....
/// Thread 2:::
thd->proc_info = NULL;
Intheexampleabove,withoutanymutualexclusion,wemight
have a sequence of instructions being scheduled such that
thenullificationofthepointerhappensbeforetheotherthread
reachesthe ifcondition.
2.OrderviolationLetusconsiderthefollowingexample:
void thread1() {
.....
mThread = PR_CreateThread(mMain, .....);
.....
}
.....
void thread2() {
mState = mThread->State;
}
Orderviolation issuchthat,ifwedon’tensurethat thread1
assignsthevaluebefore thread2accessesit.
Deadlocks
A deadlock is a situation in which a series of threads can’t take
anyactionbecauseofasomesortofcirculardependencybetween
those. Moreprecisely,thesituationissuchthat,notask i2T=
f0; : : : ;  ngcantakeactionbecauseitiswaitingforanothertask
j2Ttotakeaction.
However, in a concurrent program setting, we have a dead-
lock(i.e., theprogramcan’tprogresstowardsitsend)also forthe
followingconditions:
•Mutual exclusion : two threads can’t act on the same re-
sourceatthesametime;
•Hold-and-wait : threadsholdresourcesallocatedwhilewait-
ingforadditionalresources;
57•Nopreemption : resources(e.g., locks) can’t be forcibly re-
movedfromthreadsthatareholdingthem;
•Circularwait : thereexistsacircularchainofwaitingthreads
25.25The simplified definition of deadlock coincides
with a circular wait, but there are also other ways in
whichadeadlockmayoccur.1.MutualexclusionMutualexclusioncanbepreventedusing
certain data structures. In particular, there are data struc-
tures to be used for avoiding the use of locks but without
giveuponmutualexclusion. Letusconsiderthefollowing
example:
void add_atomically(int *value, int amount) {
int old;
do {
old = *value;
} while (_atomic_compare_xchg(value, old, old + amount) === 0);
}
Thisfunctionusesaprocedurecalled compare_and_xchg() ,
which checks in an atomic way a comparison between two
values and updates it when the two compared values are
equal.
We can also use the same approach to insert a new value
intotheheadofalinkedlist:
void insert(int value) {
node_t *n = malloc(sizeof(node_t));
assert(n !!= NULL);
n->value = value;
do {
n->next = head;
} while (_atomic_compare_xchg(&head, n->next, n) === 0);
}
2.Nopreemptionandhold-and-waitBothnopreemptionand
hold-and-waitcanbeprevented: throughappropriateAPIs,
ataskcanvoluntarilyreleasetheresourceiftheacquisition
of further ones fails. Given a programming interface that
allowstowritetasksinthefollowingway:
58/// TASK 1
lock(M1);
if (!try_lock(M2)) {
release(M1);
}
else {
update(R1);
update(R2);
release(M1, M2);
}
/// TASK 2
lock(M2);
if (!try_lock(M1)) {
release(M2);
}
else {
update(R1);
update(R2);
release(M1, M2);
}
WecanuseAPIs(suchas try_lock() )tocheckwhetheralso
other resources canbe locked as well. Thus, threads can
be programmed in such a ”gentle” way to release resources
whenevertheyneedanotherresourcealreadylockedbysome-
oneelse. Thisisawaytoavoidthe nopreemption condition.
a)POSIX pthreads InthePOSIX pthreadlibrary,wehave
thepthread_mutex_trylock() functionwhichdoesex-
actlywhatwesawbefore: eithergrabsthelock(ifavail-
able)andreturnssuccessorreturnsanerrorcodeindi-
catingthattherequestedlockisheldbyanotherthread.
Inparticular,wewouldhave:
top:
pthread_mutex_lock(L1);
if (pthread_mutex_trylock(L2) !!= 0) {
pthread_mutex_unlock(L1);
goto top;
}
However, there is a problem with that scenario: if we
have two threads checking for the other one in the
59similarways,theywouldn’tprogresstowardstheend.
There would be situations when they just attempt to
acquirethesecondlockwithoutsucceedingatall(i.e.,
circularwaitcondition).
3.CircularwaitsLetusintroducearepresentationofthecircu-
larwaitasfollows: assumetherearetwophilosopherssitting
around a table, and assume that they share two forks (sup-
pose that they need all the two to eat). If each philosopher
happenstograbtheforkontheirleftbeforeanyphilosopher
can grab the fork on their right, each will be stuck holding
oneforkandwaitingforanother,forever.
Theproblemcanbesolvedasfollows: introduce orderingso
thatnocyclicalwaitarises26. Whentotallockorderingmay26The example of the dining philosophers can be
solved by establishing an order such that, the first
philosopher takes the left fork first, and the second
philosopher takes the right fork first: T_1: (l, r);
T_2: (r, l) .bedifficulttoachieve(giventhesizeoftheproject), partial
ordering canbeused.
Some operating systems have lock order rules to be com-
pliedwith(e.g., xv6,linux). Linuxhasalsovalidation/debug
features27todetectcircularlocks,whichhavetobeenabled27To better understand how the strat-
egy used by Linux works, see also https:
//lwn.net/Articles/185666/ ,https://www.kernel.
org/doc/html/v4.13/kernel-hacking/locking.html .atcompiletime.
4.PriorityinversionTounderstandhow priorityinversion works,
let us introduce the following example: assume to have a
preemptive scheduler which schedules always the highest
priority task and three tasks having priorities 1>  2>
3,where T1andT3sharearesourcewithacriticalsection.
Figure41: Thepriorityinversionscenario
In such a scenario, we have a lower priority thread, which
isT3, locking a resource and making T1, a higher priority
thread, to miss some deadlines, even if it should be sched-
uledassoonaspossibleduetoitspriority.
60a)SolvingthepriorityinversionTherearethreemaintech-
niquesusedtosolvepriorityinversion:
•HighestLockerPriority (HLP);
•PriorityInheritance (PIP);
•PriorityCeiling (PCP).
Theyareallbasedonchangingthepriorityofthetasks
w.r.t. thenominalone.
Letusconsider R0; : : : ; R msharedresourcesguarded
by semaphores  =fS0; : : : ; S mg,Piandpias, re-
spectively,thenominalandactivepriorityvalueoftask
Ti(lower values indicates higher priority), zi;kas the
criticalsectionintask Tiaccessing Rk,andfinally &i
asasetofsemaphoresusedby Ti.
i.HighestlockerpriorityprotocolTheideaofHLP
is to avoid preemption during the execution of
any critical section by raising the priority of the
taskaccessing Rkto
pi(Rk) =min
ifPijTiusing Rkg:(3)
Figure42: Highestlockerpriorityprotocolexample
ii.Priority inheritance protocol The idea of PIP is
such that, when Tienters zi;kandRkis already
held by Tj, the latter assumes the active priority
ofTi,namely
pj(Rk) =min ifPj; PijTiblockedon Rkg:
(4)
iii.PriorityceilingprotocolA priorityceiling ofasemaphore
Skisthehighestpriorityamongthetasksthatcan
61Figure43: Priorityinheritanceprotocolexample
lockit:
C(Sk) =max
iPijSk2&i:(5)
According to the priority ceiling protocol , a task
Tiis allowed to enter a critical section only if its
priority is higher than all the priority ceilings of
thesemaphorescurrentlylockedbyothertasks.
b)PriorityinversionavoidanceinPOSIXThereareways
todefinewhichapproachtousewithPOSIXmutexes:
•PTHREAD_PRIO_NONE :noprotocol;
•PTHREAD_PRIO_INHERIT :priorityinheritance;
•PTHREAD_PRIO_PROTECT :priorityceiling28.28Wecanuse pthread_mutex_setprioceiling toset
theceilingpriority.Inparticular,usingpriorityinheritance:
int main(.....) {
pthread_mutex_t mutex;
pthread_mutexattr_t mattr;
pthread_mutexattr_setprotocol(&mattr, PTHREAD_PRIO_INHERIT);
pthread_mutex_init(&mutex, &mattr);
return 0;
8 Lecture9-ConcurrencyVI
Introductiontofutexes
Linuxlocksarebasedonaconceptcalled futex(i.e.,fastuserlevel
lock). Theideaistoavoidasmanysystemcallsaspossible29. We29The reason why is better to avoid system calls is
that,doingthis,wealsoavoidstatesavingoverheadand
contextswitching,whicharecostlyingeneral.alsowanttoavoidthunderingherdproblemsinwhichallthreads
arewokenupatthesametime. Notethat,wheneverweusePOSIX
62NPLTorPTHREADlibraries we use this kind of locks (i.e., they are
built-in).
Futexesarchitecture
Theideaisthatontraditionalkernelswealwaysneedtogodirectly
in kernel mode to obtain a lock (and eventually wait in a queue).
Fromafutexperspective,instead,wecouldhaveanuncontended
case(nothreadsareoverlappingintheuseofthelock),andacon-
tended case. In the former, there won’t be any syscall, but every-
thingisresolvedintheruntimeenvironment,inthelatter,instead,
asystemcallinteractionisrequired.
Figure44: Futexesarchitecture
Thelockstructureismovedintotheruntimeitself,asa32bit
integer, divided into 31 bits encoding the number of waiters plus
abitindicatingiftheresourceislockedorunlocked.
Whenataskisredirectintothekernelandthelockrepresenta-
tion’sfirstbitissetto1,itisputinsideaqueueandwakenuplater.
Thekernelmaintainsadatastructurecontainingforeachtaskthe
lockthistaskiswaitingfor.
Lockingwithfutexes
Letusinspectthefunctionusedtolockresourcesusingthefutex
mechanism:
void futex_based_lock(int *mutex) {
int v;
if (atomic_bit_test_set(mutex, 31) === 0) return;
63atomic_increment(mutex);
while (1) {
if (atomic_bit_test_set(mutex, 31) === 0) {
atomic_decrement(mutex);
return;
}
v = *mutex;
if (v >>= 0) continue;
futex(mutex, FUTEX_WAIT_v); //* sleeps only if mutex still has v **/
}
}
Inthisfunction,theLinuxruntimetriesasmuchaspossiblenotto
callthekernel,infactitchecksforabitatomically,andthenchecks
itagaininaloop(seeingifinthemeantimesomethingchanged).
Theif (v >>= 0) controlchecksifthefirstbitoftheintegerisei-
thersetorno(rememberthatthefirstbitisthesigninthebinary
representation).
Theunlockfunction,instead,isstructuredasfollows:
void futex_based_unlock(int *mutex) {
if (atomic_add_zero(mutex, 0x80000000))
return;
futex(mutex, FUTEX_WAIT, 1); /// wake up only one thread
}
Thisapproachisusednotonlyformutexesbutalsoforconditions
variables. Inabroadcastscenario,allthethreadswaitingforacon-
ditionvariableina COND_WAIT state,wouldbewakenup. Withfu-
texes,instead,Linuxtriestoavoidthethunderingherdproblem.
Event-basedconcurrency
Event-baseconcurrencyoccurswhenmultipleactivitieshastheir
progressstrictlyrelatedtoexternalevents. Thisparadigmisheav-
ilyusedinGUI-basedapplicationsandinternetservers(e.g.,Nodejs).
Theideaisthatthereisawaitofsomething(i.e.,an”event”)to
occur (or to be ”posted” by an external entity). When this event
occurs,thereisacheckonwhattypeofeventarrived,identifying
whichactivityitbelongs. Then,theroutinesdothe smallamount
ofworkitisrequired30. Finally,theroutineisputintoa rinseand30This work may include issuing I/O requests, or
othereventsforfuturehandling,etc. repeatstate.
64Differenttypesofconcurrentactivities
In a more traditional event-based concurrency scenario, we have
applicationsexecutinginstructionsandthenblocking(orpolling)
for a certain amount of time. We can use pthreads to develop
applications such that a thread is spawned for each activity that
needstobehandled. However,using pthreads tohandleactivities
in a web server may not be the best idea, since we should avoid
contextswitchesasmuchaspossible.
Therearebasicallytwotechniquestoavoidcontextswitches:
•Eventloops;
•Callbacks.
Eventloopsisatechniqueinvolvingasinglethread,givingthe
controltoafunctionrepeatedlycheckingforexternalevents(i.e.,
theevent loop ). This function then should restore the state of the
activityitselfoncethewaitingisdone(e.g.,Javascripthasthecon-
ceptofclosure). Themodernincarnationofthisbehaviorarecall-
backs,aclosureabletorestorethestateoftheactivity.
Figure45: Event-basedconcurrencytechniques
1.Event loop In an event loop scenario, when a handler pro-
cesses an event, it is the only activity taking place in the
system. Thus, no locking is needed: this task can modify
shareddatawithoutworryingaboutotheractivities. Inthis
way,wedonothavecontextswitchoverhead,exceptforre-
sumingeachactivityfromwhereitstopped.
65Thecodeassociatedtoaneventloopcouldbethefollowing:
while(1) {
events = getEvents();
for (e in events)
processEvent(e);
}
Let’s now focus on events based on network requests. On
UNIX/Linuxwehavethe select() andpoll()APIs,which
checkwhetherthereisanyincomingnetworkI/Othatshould
be attended to. For example, select() examines the first
nfdsI/O descriptor sets checking if there is data ready (to
read), or if the write buffer still has space, or if there is an
exceptionalconditionpending:
int select(int nfds, fd_set *readfds, fd_set *writefds,
fd_set *errorfds, struct timeval *timeout)
Considernowthefollowingusageexample:
void main() {
while(1) {
int wfd[] = {10, 20, 30};
fd_set readFDs;
FD_ZERO(&readFDs);
for (int i = 0; i < 3: i+++)
FD_SET(wfd[i], &readFDs);
int rc = select(3, &readFDs, NULL, NULL, NULL);
for (int i = 0; i < 3; i+++) {
if (FD_ISSET(wfd[i], &readFDs)) processFD(wfd[i]);
}
}
}
Wehavethreestreams(i.e., wfd)fromwhichwearewaiting
for an event, then we create a set of descriptors, specifying
thatinsidethemwewanttoreadthestreams. The select()
will block and returns when there is one or more request
ready on one of the incoming streams specified before. Fi-
nally,foreachofthestreamwecheckwhetherthisstillhas
somethinginside,ifsoweinvokethe processFD() .
66The problem with this approach is that processFD() can’t
block on any activity (e.g., in Javascript callbacks we can’t
have infinite loops). If an event handler issues a call that
blocks,theentireserverwilldojustthat: itblocksuntilthe
callcompletes. Whentheeventloopblocks,thesystemsits
idle, and thus this is a huge potential waste of resource31.31Thismighthappenifthe processFD() functionin-
vokesane.g., fread(). To solve this, we could run blocking file I/O operations in
athreadpoolandmakethe processFD() registeracallback
for when the data is ready ( libuvcreates a nice abstraction
onthis). WecouldalsouseLinux/POSIX AIOlibrary,which
provides native functions for launching asynchronous file
I/Ooperationsandbenotifiedinseveralways.
UsingAIO,onestatemachineiscreateddynamicallyforeach
client,which,inturn,cansendanactionchar (0, ....., 3)
to change a client-specific state (a, ....., d) in the server.
Thestatetransitiontableisthefollowing:
Current 0 1 2 3
a(initialstate) a b c d
b a a b d
c a a c d
d(exitstate) d d d d
Linuxkernelspaceconcurrency
There are basically three main characteristics of the Linux kernel
thatmightintroduceconcurrencywithintheactivitiesperformed:
•Kernelpreemption ;
•Interrupts ;
•Multipleprocessors ;
Kernelpreemptionisaboutmultiplethreadsallowedtoshare
the same resource in the kernel, while interrupts are another as-
pect of concurrent activity. Interrupts can occur asynchronously
at almost any time, interrupting the currently executing code in
kernel mode. If the interrupt and the interrupted task are using
the same resource, then we must regulate access. Code that is
safefromconcurrentaccessfromaninterrupthandlerissaidtobe
interrupt-safe32. Thelastsourceofconcurrencyishavingmulti-32When an interrupt arises, the program flow goes
intoastatecalled interruptcontext ,giventhattheorig-
inalapplicationstartedfrom processcontext andmight
endupin kernelcontext .pleprocessorswithtasksrunningatthesametime.
67Multi-processing
Multi-processing support implies that kernel code must simulta-
neouslyrunontwoormoreprocessors. Codeinthekernel,run-
ning on two different processors, can thus simultaneously access
shareddataatexactlythesametime. Multi-processingisalsocalled,
forthisreason, trueconcurrency .
Codethatissafefromconcurrencyonsymmetricalmulti-processing
machines is SMP-safe. Note that writing code that is SMP-safe is
really tricky, since processors do not have the same view of the
memory.
Kernelpreemption
Remember that, on certain conditions, we can have also nested
interrupts. In preemptive kernels , we can switch to another task
insteadofresumingakernelactivitythatwasexecutingbeforethe
interruptcame. Inotherwords,evenkernelactivitiescanbepre-
empted and we could have context switches also between kernel
tasksbeforethepreemptedonefinished33. Theideaisthat,inpre-33Preemptivekernelsalsorequirespecialcaretokeep
kernel code preempt-safe, without leading it in incos-
titent states. See also https://www.kernel.org/doc/
Documentation/preempt-locking.txt .emptive kernels, context switches may happen in places different
fromtheendofprocesscontext,sotoswitchtoothertasksdiffer-
entfromthepreemptedone(maybebecauseofahigherpriority)
oreventokerneltasks.
Figure46: Preemptivekernelscenario
681.Preemption points From its 2.6 version, the Linux kernel
became preemptive. This comes with the definition of pre-
emptivepoints ,whicharethefollowing:
•Theendofinterrupt/exceptionhandling ,whenTIF_NEED_RESCHED
flaginthethreadcontrolblockhasbeenset(i.e., forced
processswitch );
•When a task in the kernel explicitly blocks (which
results in a call to schedule() - i.e.,planned process
switch)34.34However,itisalwaysassumedthatthecodeexplic-
itlycalling schedule() knowsitissafetoreschedule.
TheTIF_NEED_RESCHED flagisdefinedasfollows:
#define TIF_NEED_RESCHED 1 //* rescheduling necessary **/
Moreover,itisset/unsetinthe task_struct inthefollowing
way:
static inline void set_tsk_need_resched(struct task_struct *tsk)
{
set_tsk_thread_flag(tsk,TIF_NEED_RESCHED);
}
static inline void clear_tsk_need_resched(struct task_struct *tsk)
{
clear_tsk_thread_flag(tsk,TIF_NEED_RESCHED);
}
2.Preemption count In the Linux kernel, the preempt_count
variableisincreasedforeachcominginterrupt. Assoonas
thisvariableisnotequaltozero,thekernelcan’tgivecontrol
tootherthreads. Whenthisvariableiszero,sinceweareas-
sumingtohaveapreemptivekernel,thelattermaygivecon-
troltoanothertaskandnottotheoneexecutingbeforethe
first interrupt arrived. This strategy is typically employed
to allow the kernel to manage nested interrupts correctly,
knowinghowdeepthecurrentchainofinterruptsis.
3.Thereal-timepatch( PREEMPT_RT )Thekeypointofthe PREEMPT_RT
real-time patch is to minimize the amount of kernel code
69Figure47: preempt_count usage
thatisnon-preemptible,whilealsominimizingtheamount
ofcodethatmustbechangedinordertoprovidethisadded
preemptibility. However,Linuxwillneverprovidethelow-
est latencies as possible, since it wasn’t designed with this
in mind. This means that it is not very suitable for safety
criticalapplications.
Figure48: PREEMPT RTstructure
709 Lecture10-ConcurrencyVII
Moreonpreemption
TohaveadditionalresponsivenessinaRTscenario,theLinuxker-
nel has the PREEMPT_RT patch, which maximizes the preemptable
code within the kernel. In this case, critical sections, even if in
kernel mode, can be preempted: a task in kernel mode that has
previouslyacquiredalockonacriticalsectioncanbepreempted,
althoughthelockisnotreleasedyet,andthecontrol,oncethein-
terrupthandlerfinishes,canbegiventoanothertask.
ThePREEMPT_RT mustbemanagedcarefully
This case must be certainly managed carefully, since interrupt-
ing critical sections may be dangerous, depending on what the
newly scheduled task will do (remember that we still have a lock
taken by a preempted task). When the critical section is post-
poned, which means that a new task has been scheduled before
theonethatacquiredthelockreleasedit,thelatterisputintothe
TASK_RUNNING_MUTEX state.
ThreadedIRQs
Whenainterruptcomesinprocesscontext,theinterruptisman-
agedinawaysuchthatsomeworkisscheduledtobedoneinpro-
cess context later on. Thus, each interrupt is assigned to be exe-
cutedinitsownthread.
Figure49: TheIRQmechanism
71Lockingtechniques
Spinlocks
Spinlocks arethemostusedtechniquewhendealingwithmultiple
processes: eachofthemcanbeeither 1or0. Anexampleofcode
usingspinlockscouldbe:
DEFINE_SPINLOCK(mr_lock);
spin_lock(&mr_lock);
//* critical region ..... **/
spin_unlock(&mr_lock);
Thespin_lock() operationisanactiveloop,checkingrepeatedly
if the requested lock becomes free. In the Linux kernel35, spin-35To inspect the source code see also
https://elixir.bootlin.com/linux/latest/source/
tools/include/linux/spinlock.h#L9 .locksaredefinedasmutexesandinitializedaccordingly:
#define spinlock_t pthread_mutex_t
#define DEFINE_SPINLOCK(x) pthread_mutex_t x = PTHREAD_MUTEX_INITIALIZER
Themacro PTHREAD_MUTEX_INITIALIZER isdefinedinthe pthread.h
library. Inparticular, spin_lock() andspin_unlock() aredefined
asfollows36:36These functions are taken from the source code;
see also https://elixir.bootlin.com/linux/latest/
source/tools/include/linux/spinlock.h#L13 . #define spin_lock(x) pthread_mutex_lock(x)
#define spin_unlock(x) pthread_mutex_unlock(x)
Alsointhiscase,both pthread_mutex_lock() andpthread_mutex_unlock()
aredefinedinthe pthread.h library.
Onuni-processormachines,theselocksarediscardedafterthe
compilationandbecomesimplecallsto preempt_disable() .
Wemighthavevariationsoflockacquiringandreleaseopera-
tions,whichare:
spin_lock_irqsave(&mr_lock, flags);
spin_unlock_irqrestore(&mr_lock, flags);
Thesearetypicallyusedwheneverourkernelcodemustsharedata
with an interrupt handler, since they disable local interrupts and
savethepreviousstateinto flags.
1.Basic implementation of a spinlock The basic implementa-
tionofaspinlockwouldboildowntoasortof _atomic_compare_xchg ,
asfollows:
72lock:
..... ; prepare '1' in %edx (new)
..... ; prepare '0' in %eax (expected)
..... ; prepare 'ptr' as &lock
; the actual atomic exchange is called `cmpxchg`
; (%eax F= *ptr) ? {*ptr = %edx, %eax = *ptr} : {%eax = *ptr}
lock cmpxchg %edx, ptr
test %eax, %eax ; is %eax 0 ?
jnz lock
Readwritelocks
Readwritelocks distinguishbetweenreadersandwriters37. When37Rememberthat, ifwehavemultiplereadersin the
criticalsection,withoutanyonewriting,thereisnoprob-
lematall. Somehow,thisiswhatisexploitedinbyread-
writelocks.awriterarrives,thereisacheckwhetherthereisatleastonereader
active. Theselockscomewith irq_save andirq_restore variants,
asseenbefore. Inparticular,theirusecouldbeasfollows:
DEFINE_RWLOCK(mr_rwlock);
read_lock(&mr_rwlock);
//* critical section (read only) ..... **/
read_unlock(&mr_rwlock);
write_lock(&mr_rwlock);
//* critical section (read and write) ..... **/
write_unlock(&mr_lock);
Seqlocks
Wemayalsohavemanyreadersandfewwriters. Forthisreason,
thekernelhasanotherlockingparadigm: seqlocks. Theselockstry
to minimize the effort that readers do to access data, but without
blockingthemandavoidingwriterstobeputaside(i.e.,theymay
starve). Letusconsideranexample:
write_seqlock(&mr_seq_lock); /// increment seq. counter
//* write lock is obtained..... **/
write_sequnlock(&mr_seq_lock); /// increment seq. counter
do {
seq = read_seqbegin(&mr_seq_lock); /// ^
//* read/copy data here | check if seq. counter equal. **/
} while (read_seqretry(&mr_seq_lock, seq)); /// V
73Theread_seqbegin() checkswhetherthecounterisodd,then,
ifso,itspinswaitingforthisstatetochange. The read_seqretry()
checks if some writer appeared in the meanwhile. In this case,
writers are not blocked, readers, instead, are forced to redo their
workifsomenewwriterarrivedinthemeantime.
Read-copyupdate(RCU)
Read-copyupdate (RCU)isascalablehigh-performancesynchro-
nization mechanism implemented in the Linux kernel. The fi-
nal goal RCU tries to achieve is the following: readers shouldn’t
be blocked by anything and writers shouldn’t disrupt the opera-
tionsofreaders. Readers,inparticular,shouldtolerateconcurrent
writes(asinseqlocks),butinthiscasethereisawholeinfrastruc-
ture making readers not repeating their operations. As a result,
readers avoid locks and should tolerate concurrent writes (might
bemultipleconcurrentversions)38,andwriterscreateanewver-38This means also that readers could see an old ver-
sionofagivendatumforalimitedtime. sion(copy)ofthedatastructuretheyareworkingonandtheypub-
lishthenewversionwithasingleatomicinstruction39.39Thismeansthatwritersdotheirworkoffline,com-
mittingonlythefinalvalueattheendoftheiroperation.
Figure50: RCUfunctioning
Inparticular, task P3removesatomicallynode B,thustask P2
will not be aware of this change, until it re-scans this linked list
again. In case of reclamation, P3needs to wait until every reads
arecompleted.
74Foritsverynature,RCUcanbeeffectiveinavoidingdeadlocks
andmakingreadlockacquisitionabreeze. However,forthesame
reason,itmightdelaythecompletionofdestructiveoperations.
MoreontheunderlyingideaofRCU
ThebasicideabehindRCUistosplita destructive operationinto
twoparts:
1.Remove references to data items within a data structure,
runningconcurrentlywithreaders(i.e., removal)40;40Thistakesadvantageofthefactthatwritestosingle
aligned pointers are atomicand must consider memory
ordering. 2.Carryouttheactualdestruction(i.e., reclamation ).
Betweenthesetwosteps,aso-called graceperiod mustelapse,
and this must be long enough so that any reader accessing the
item being deleted has since dropped its references (i.e., dropper
rcu_read_lock() ). Sincethereadsectioncan’tblock,onecanwait
until all CPUs have executed the context switch. This is done by
waitingacontextswitchin call_rcu (orsynchronize_rcu ).
ExamplesofRCUusage
Let us inspect this example of a reader (which scans the process
list)andawriter(whichremovesaprocessfromthelist):
/// READER
void manipulate_task_list(.....) {
rcu_read_lock(); /// inform the reclaimer and disable preemption
/// can't issue any blocking (sleeping) actions that might switch the context
for_each_process(p) {
//* do something with p **/
}
rcu_read_unlock();
}
/// WRITER
void release_task(struct task_struct *p) {
write_lock(&tasklist_lock);
list_del_rcu(&p->tasks); /// removal phase. Must allow concurrent read/write access
write_unlock(&tasklist_lock);
call_rcu(&p->rcu, delayed_put_task_struct); /// update phase
}
75MCSlocks
InSMPsystems, everyattempttoacquirealockrequiresmoving
acachelinecontainingthatlocktothelocalCPU.Forcontended
locks,thiscachelinebouncingcanhurtperformancesignificantly.
In1990,Mellor-CrummeyandScottproposedaCPU-awaretype
oflockwhichtriestoavoidthepingponggamebetweencaches.
Figure51: HowMCSlocksworkinternally
TheideaofMCSlocksisthefollowing: allprocessorswillhave
their particular version of the lock (which it could be either 0or
1). This lock is represented as a mcs_spinlock data structure in
Linux,definedasfollows:
struct mcs_spinlock {
struct mcs_spinlock *next;
int locked; //* 1 if lock acquired **/
}
Startingwithanottakenspinlock(whichmeansthatthelockitself
wouldhaveitsdatastructurewith locked = 0 ),wheneveraCPU1
arrivesandtakesthelock,itallocatesitsown processor-specific data
structureandupdatesatomicallyboththepointerandthe locked
field (setting it equals to 1) of the spinlock data structure. The
situationwillbelikethefollowing:
|----------|- |----------|-
| MCS lock | | CPU 1 |
76|----------|- |----------|-
| ------------------> |
|----------|- |--------- |
| 1 | | 0 |
|----------|- |----------|-
Whenever a second processor CPU 2 arrives, the spinlock
structure (as always) points to the last arrived processor, and the
new one does the exact same things the previous one did: it al-
locates its own version of mcs_spinlock and spins over its local
lockedfield (which is set equals to 1). Moreover, it atomically
changesthepointersofthe nextfieldbothinthespinlockandCPU
1datastructures. Thesituationwouldbeasfollows:
|----------|- |----------|- |----------|-
| MCS lock | | CPU 1 | | CPU 2 |
|----------|- |----------|- |----------|-
| -----------+ | ------------------> <----+
|----------|- | |----------|- |----------|- |
| 1 | | | 0 | | 1 | |
|----------|- | |----------|- |----------|- |
| |
+---------------------------------+
When CPU 1 finally finishes with the lock, it will do a compare-
and-swapoperationonthemainlock,tryingtosetthenextpointer
toNULL(whichwastheoriginalvalueCPU1sawinthebeginning)
ontheassumptionthatthispointerstillpointstoitsownstructure.
If that operation succeeds, the lock was never contended and the
jobisdone. IfsomeotherCPUhaschangedthatpointerasshown
above,though,thecompare-and-swapwillfail. Inthatcase,CPU
1 will not change the main lock at all; instead, it will change the
lockedvalueinCPU2’sstructureandremoveitselffromthesitu-
ation:
|----------|- |----------|-
| MCS lock | | CPU 2 |
|----------|- |----------|-
| -----------+ | <----+
|----------|- | |----------|- |
| 1 | | | 0 | |
|----------|- | |----------|- |
| |
+---------------------+
77InLinux,MCSlocksarecalled queuedspinlocks ,sincethepoint-
ersbetween mcs[1]andmcs[3]infigure,constituteaqueue.
10 Lecture14-LinuxVirtual/PhysicalAddress
SpaceI
Thevirtualaddressspace
Operatingsystemsintroducedaremappingofphysicalpagesinto
a virtualized version of them, which are called virtual pages . The
task_struct , that we already discussed before, contains a field
calledmm,whichisadatastructurecontainingalltheinformation
relatedtotheprocessaddressspace41.41Thisdatastructureisalsocalled memorydescriptor
anditisdefinedunder include/linux/mm_types.h . Virtual memory is used both by kernel code and user code,
withthelatterbeingpositionedatloweraddresses,whiletheLinux
kerneluseshigheraddresses.
Figure 52: Virtual/physical address space mappings and data
structures
Notethat,afterprocessswitch,theuser-spacemappingschange
while kernel ones remain unvaried. Kernel logicalmemory is a
remapping of the physical one and contiguous virtual page allo-
cations end up in contiguous physical pages. The kernel virtual
memory zone corresponds to additional remapping used when-
everitshouldallocatehugememoryareaswhichcan’tbeallocated
contiguouslyinmemory42.42Inotherwords,thosepagesallocatedinthevirtual
memoryzone,willbecontiguousfromavirtualmemory
perspective,butnotinphysicalmemory.
78Thepgdfield(i.e., pagedirectory )insidethe mm_struct isbasi-
callyapointertothe(firstlevel)pagetable. Notethat,thereisalso
aVM base register , which is a machine register that points to the
pgdofthecurrentrunningtask(e.g.,inx86 CR3).
There could be also valid pages in the virtual memory which
are not present in the physical one43. In other words, their en-43Theycouldbepresentbothintheswapspaceorin
thediskitself. triesareinthe pgdbutnotinphysicalmemory(theyweremaybe
swapped out). Furthermore, we could also have pages whose en-
triesarenoteveninsidethe pgd,buttheyareinavalidrange. This
iswhatiscalled demandpaging . Tounderstanditsbehavior,con-
sidertheheapandthe brk()systemcalltoextenditsmemoryarea,
Linux acknowledges that the size of the heap has been increased
andthosenewpages(demanded)aretreateddifferentlyfromthe
others.
Validandnon-validrangesaredefinedusingtheso-calledLinux
VMAs(i.e., Virtual Memory Areas). VMAs are pointed in the
mm_struct : theyarecollectedusingalist,reportingthevalidranges
of the address space. VMAs are represented as vm_area_struct ,
containing startandendof the corresponding address space re-
gion(e.g., .text,.bss)andthoseregionsmightbealsorelatedto
a file (e.g., where the code has been read). In particular, we say
that the structure has a so-called backing store . This is important
because not all pages occupy corresponding frames in the physi-
calmemory(e.g.,notallcode/dataresidesalwaysinmemory),so
theywouldbedirectlyloadablefromtheoriginalfile. VMAshave
flagsfor rwxcapabilities,asusual.
Figure53: VMAsintheLinuxkernel
79There are memory areas not having any backing store (e.g.,
.data, heap) and these are called anonymous virtual memory ar-
eas. These areas will be written in the swap space. Given the ad-
dress space of a process, there could also be implicitly/explicitly
mappedpageswhicharerelatedtootherpartsofthesystem(e.g.,
libraries such as libc). Dynamic libraries may end up in several
addressspaces(ofseveraldifferentprocesses),butattheend,those
pages will map into the same physical memory region. In other
words, some pages may be shared among different processes. To
inspectthosethingsonourcommandline,wecanuse
$ cat /proc/118286/maps
start end prm offset dev inode backing store
55ffded63000-55ffded65000 r--p 00000000 fe:00 16074806 /usr/bin/emacsclient
55ffded65000-55ffded68000 r-xp 00002000 fe:00 16074806 /usr/bin/emacsclient
55ffded68000-55ffded6a000 r--p 00005000 fe:00 16074806 /usr/bin/emacsclient
55ffded6a000-55ffded6b000 r--p 00006000 fe:00 16074806 /usr/bin/emacsclient
55ffded6b000-55ffded6c000 rw-p 00007000 fe:00 16074806 /usr/bin/emacsclient
55ffded6c000-55ffded6d000 rw-p 00000000 00:00 0
55ffe04a4000-55ffe04c5000 rw-p 00000000 00:00 0 [heap]
7f2dd88ba000-7f2dd88bd000 rw-p 00000000 00:00 0
7f2dd88bd000-7f2dd88df000 r--p 00000000 fe:00 15994155 /usr/lib/libc.so.6
7f2dd88df000-7f2dd8a3a000 r-xp 00022000 fe:00 15994155 /usr/lib/libc.so.6
7f2dd8a3a000-7f2dd8a91000 r--p 0017d000 fe:00 15994155 /usr/lib/libc.so.6
7f2dd8a91000-7f2dd8a95000 r--p 001d4000 fe:00 15994155 /usr/lib/libc.so.6
7f2dd8a95000-7f2dd8a97000 rw-p 001d8000 fe:00 15994155 /usr/lib/libc.so.6
7f2dd8a97000-7f2dd8aa4000 rw-p 00000000 00:00 0
7f2dd8ae0000-7f2dd8ae2000 rw-p 00000000 00:00 0
7f2dd8ae2000-7f2dd8ae3000 r--p 00000000 fe:00 15994143 /usr/lib/ld-
linux-x86-64.so.2
7f2dd8ae3000-7f2dd8b09000 r-xp 00001000 fe:00 15994143 /usr/lib/ld-
linux-x86-64.so.2
7f2dd8b09000-7f2dd8b13000 r--p 00027000 fe:00 15994143 /usr/lib/ld-
linux-x86-64.so.2
7f2dd8b13000-7f2dd8b15000 r--p 00031000 fe:00 15994143 /usr/lib/ld-
linux-x86-64.so.2
7f2dd8b15000-7f2dd8b17000 rw-p 00033000 fe:00 15994143 /usr/lib/ld-
linux-x86-64.so.2
7ffdb5b9e000-7ffdb5bc0000 rw-p 00000000 00:00 0 [stack]
7ffdb5bfa000-7ffdb5bfe000 r--p 00000000 00:00 0 [vvar]
7ffdb5bfe000-7ffdb5c00000 r-xp 00000000 00:00 0 [vdso]
ffffffffff600000-ffffffffff601000 --xp 00000000 00:00 0 [vsyscall]
80Pages with inodeequals to 0 correspond to sections that do not
have a backing store (i.e., anonymous pages). Backing store ar-
eascomefromthe PT_LOADsegmentsintheELFfileandtheyare,
initially, code, read-only data and initialized writable data (i.e.,
.data). Writableinitializeddataisputreadonlyatfirst,butcopy-
on-write is then used if written44. Anonymous areas (i.e., heap,44Remember that this is exactly what happens also
forachildofaforkedprocess. stackand .bss)areoriginallymappedintoazeropagemaintained
bytheoperatingsystemandmappedasreadonly. A VMA_GROWSDOWN
area is initialized with a certain number of zero pages and it can
growwhenthelastpageisaccessed: thisareaisusedforthestack.
For other anonymous VMAs, the kernel expects processes to use
brk()orsbrk()explicitly.
Tosummarize,aVMAcanbeclassifiedasfollows:
•Mappedto a file (with backing store ) ornot mapped (i.e.,
anonymouspages-e.g.,stack,heap);
•Sharedorprivate;
•Readable ,writableorexecutable (e.g.,.textsection of a
process is typically mapped with VM_READandVM_EXECbut
notVM_WRITE);
•VM_IOspecifies if that area is a mapping of a device’s I/O
space. Thisfieldistypicallysetbydevicedriverswhen mmap()
iscalledontheirI/Ospace.
Pagefaultmanagement
Considernowaprocessthataccessesapagenotpresentinmem-
ory. The first thing that Linux does is to invoke a function called
find_vma() passinganaddress. ThelatterscansallthelistofVMAs
(alistof vm_area_struct )anditdistinguishesbetweentwocases:
•The page is not found , then the address belongs to a page
relatedtoanon-mappedregion )SIG_SEGV;
•The page is found, then the page could be in two different
states: i) in the page table but not in physical memory; ii)
valid but it doesn’t have any page table entry. In this case,
firstly the permissions are checked (e.g, rwxon pages with
differentcapabilities),ifsomethinggoeswrong,a SIG_SEGV
is raised. Otherwise, Linux tries to resolve the address by
usingthe handle_mm_fault() function45,checkingifsome45Linuxrecognizesthatthispageisina”demandpag-
ingscenario”,soitcreatesanentryinthepagetable.
81page needs to be allocated in the page table, given that the
addressisvalid. Finally,itwillhandlethefaultbyloading,if
needed,thedatafromthediskbyusing handle_pte_fault() .
Theactivityofloadingdataonlywhenthereisaninstruction
readingthatdata(andnotbefore),iscalled demandpaging .
CheckingtheentireVMAslistbythe find_vma() wouldhave
been a costly operation if this list was implemented as a ”simple”
list. VMAs are represented as a red-black tree : a way of arrang-
ing elements of a set by considering, in this case, the ending ad-
dressofthatparticular vm_area_struct . Elementsareorderedso
tohavetheirvaluebeinglessthanthevalueoftheirparent,ifthey
arepresentintheleft-handsubtree,greateriftheylieontheright-
hand subtree. Linux tries to make this tree balanced to reach the
VMAofoffendinginstructionsinlogarithmictime(i.e., O(logn))
insteadoflineartime.
Figure54: The find_vma() primitive
82Demandpaging
Now, going more into the details of demand paging, consider a
program calling brk()to enlarge the heap and suppose that this
processhasapageintheheapwhichisinthepagetablebutnotin
the physical memory, and one mapped in physical memory. The
brk()enlarges the virtual memory area of the process, but new
pageswillbevalidand nonpresent . Inthisway,thephysicalmem-
orywillremainunvaried. Whenevertheprogramhasaload/store
instructioninvolvingoneofthenewmemoryareas,theprovoked
page fault will be handled and Linux, at the end, will allocate a
physical page for the just mapped ones. The example described
aboveisalsodepictedinfigure.
Figure55: Anexampleofdemandpaging
Userspacememorymapping
Inuserspace,virtualmemoryareascanbecreatedexplicitlybya
processusingthe mmap(),whichgoesasfollows:
#include <sys/mman.h>
void *mmap(void *addr, size_t length, int prot, int flags, int fd, off_t offset);
Inorderforprogramstoreadfiles,thesewillhavesome/allofthe
datastoredintophysicalpagesandtypically,wheneveruser-space
83processes want to read that data, there will be data-copying (us-
ing system calls) and data-returning of that specific data. How-
ever, this is not always the best and fastest way to read files. The
alternative way to do it is by using mmap(), which creates and ad-
ditional VMA and mappings between the virtual memory space
oftheprocessandthephysicalpagesthatcontainthedatainker-
nelmemory. Thesepagesaremappeddirectlyfromthe pagecache
andcanaccessthefiledirectly.
Figure56: Thepagecache
Attheendoftheday, mmap()justreturnsa pointertothebe-
ginning of a region of virtual memory where the contents of the
file are located. Actual physical allocation happens only when a
process reads or writes that specific page. The operating system
triestofindspaceforthepageandmakeitaccessiblebyupdating
thepagetableoftheprocessaccordingly(i.e., demandpaging ).
HowLinuxmanagesphysicalpages
Modern systems are structured with non-uniform access mem-
ory,suchthatphysicalthreadsaregroupedintocores(grouped,in
turn,asNUMAnodes)sharingthesameRAM.DifferentNUMA
nodes have different RAM banks, so that access latency to data
may be different based on which RAM (or NUMA node) it be-
longsto.
ForeachNUMAnode,Linuxkeepsa pg_data_t structure(all
structures are contained in the pgdat_list ) and maintains three
typesofinformation:
84Figure57: TheNUMAarchitecture
•ZONE_DMA;
•ZONE_NORMAL ;
•ZONE_HIGHMEMORY .
The RAM is divided in zones and each zone is linked to a
free_area structure, which keeps track of free pages inside the
specificarea. ThisdatastructureisusedbyLinuxtoallocate/deal-
locatepagesfromthephysicalmemoryanditisbasicallyanarray
of lists, pointing to page descriptors (which can be either free or
allocated). Inparticular,the free_area pointstosetofcontiguous
pages (e.g., 1 contiguous page, 2 contiguous pages, 4 contiguous
pages, etc. up to 29) belonging to a list. Furthermore, we have
watermarks thatarevalueskeptbyLinuxtounderstand,giventhe
numberoffreepages,ifitshouldgoaroundandfindotherpagesin
casethenumberoffreeonesisbecominglow. The pg_data_t has
apointertoanotherdatastructurecalled lruvec,usedbythepage
frame reclaim algorithm to keep track of pages belonging to the
arraydescribedbefore(seethepicturebelowforfurtherdetails).
85Figure58: ZonesandtheirdatastructuresinLinux
Pageallocation
Consider now a zone, the number of available pages in that zone
andthe watermarks value. Then, wecouldderiveaplotbasedon
Linuxallocationpolicies,asdepictedinpicture.
Figure59: Pageallocation
Inotherwords, whenthenumberofavailablepagesgoesun-
der a certain threshold, the kernel allocator wakes up a daemon
calledkswapd, which starts to apply the page frame reclaim algo-
rithm, selecting inactive pages and storing them in the backing
storeorintheswapregion. Whenthenumberoffreepagesgoes
underthe lowvalue,theallocator(i.e.,thepagefaulthandler)will
do the kswapdthread’s job. There can be situations in which the
86number of pages might be lower than the lowvalue. The hope is
that, sooner or later, the number of free pages will go back to its
normalstateandthedaemonwillgotosleep.
TheBuddyalgorithm
Thereisawell-knownmemorymanagementproblemcalled exter-
nal fragmentation that the Linux kernel tries to avoid as much as
possible. Theideaisthatfrequentreleasesandrequestsofgroups
ofcontiguouspageframesofdifferentsizesmayleadtohavesmall
blocksoffreepageframebeingscatteredinsideblocksofallocated
pageframes. Havingcontiguouspageframesisreallyimportantin
some circumstances (e.g., buffers for DMA processors), so Linux
uses the well-known buddy algorithm to avoid external fragmen-
tation.
Allpageframesaregroupedinto11listsofblocksthatcontain
groupsof1,2,4,8,16,32,64,128,256,512and1024contiguous
pageframesrespectively. Thelargestrequestof1024pageframes
correspondstoachunkof4MBofcontiguousRAM.
Assume that there is a request for a group of 256 contiguous
pageframes( 2564096 = 1 MB). Thealgorithmchecksifthereis
afreeblockinthe256-page-framelist. Ifthereisnosuchablock,
it looks for the next larger block (i.e., a free block in the 512-list-
frame list). If such blocks exists, the kernel allocates 256 of the
512 page frames to satisfy the request and inserts the remaining
256pageframesintothelistoffree256-page-frameblocks. Note
thatifthereisnosuchfreeblockinthe512-page-framelisteither,
the algorithm checks for it in the 1024-page-frame list, etc. The
reverse operation is the one giving the name to algorithm. The
kernel attempts to merge pair of free buddy blocks of size bto-
getherintoasingleblockofsize 2bifthefollowingconditionsare
met:
•Bothblockshavethesamesize,say b;
•Theyarelocatedincontiguousphysicaladdresses;
•Thephysicaladdressofthefirstpageframeofthefirstblock
isamultipleof 2b212.
8711 Lecture15-LinuxVirtual/PhysicalAddress
SpaceII&MemoryModelsI
Pagecache
Assume we have multiple processes accessing the same file. To
know whether the data requested by some process is already in
memory, Linux maintains a per-file page cache . The page cache
is a set of physical pages that are the result of reads and writes of
regular files lying in the file-system. This set of physical pages is
stored in a structure called address_space . This structure maps
file_descriptor + offset ->- physical_page ,butworksalsoin
areverseway physical_page ->- [VMA]46.46Thereversemappingisusefulwhenwewanttoin-
validate page table entries of shared pages in different
processes.
Sincetheideaofpagecacheistoimplementthe file_descriptor
+ offset ->- physical_page mapping,each address_space struc-
ture has a unique radix tree stored as page_tree47. To search47A radix tree is a type of binary tree and enables
quicksearchingforthedesiredpage,givenonlytheoff-
set.the cache, the kernel goes through the pages associated with the
address_space of a file which contains a mapping for *offset -
> physical_page (through the function find_get_page(addrsp,
offset)). Alsoanonymouspagesaremappedtothe swapper_space
addressspacebeforebeingswappedout,ifnecessary.
88When a page does not exist in the cache and the memory is
full, Linux manages the address space (possibly evicting pages)
throughitsownversionoftheLRUalgorithm.
Pagedescriptor
SomephysicalpagescanbesharedbetweenVMAs(e.g.,file-backed
pageoffilessharedbetweenprocesses,copy-on-writepage-achild’s
page which is copied only when written). For that matter, Linux
keepsa struct page thatcontains:
•Howmanysuchsharingsthereare(i.e., _mapcount );
•How to reach these pages in the case we want to invalidate
them(address_space ,thenintoeach pdgpointedbyVMAs).
PageFrameReclaimAlgorithm
The PFR algorithm is based on the clock algorithm, which is an
approximation of LRU: we flag pages based on the fact that they
hasbeenaccessedrecentlyornot.
There is a variation for which, if a page is dirty, it is skipped
onceif R = 0sincewritingthingsbacktodiskhasanon-minimal
cost. Anonymous pages are contained in two lists belonging to
thelruvecper-CPUdatastructure,whichare INACTIVE_ANON and
89Figure60: Clockalgorithmforevictingpages
ACTIVE_ANON ,withpages,respectively,consideredtoevictionand
still referenced by something else. However, the clock algorithm
has a known problem: we could have pages with R = 1but ac-
cessedonlyonceandnomoresincethen. So,Linuxusesamodi-
fiedversionoftheclockalgorithmandtriestobalance INACTIVE_ANON
andACTIVE_ANON pages. Inthisway,pagereferencedonlyoncewill
besoonerorlaterconsideredforeviction.
Figure61: LinuxmanagementofthetwoLRUs
Inpractice,wheneverthepageisloadedorreferenced,itisput
intothe ACTIVElistwiththereferencebitsetto 0. Whenthispage
is accessed again, it will be moved as a tail and the reference will
90besetto 1. Inthe ACTIVElist,themorepageswillbenearthetail,
themoretheyarefarfrombeingevicted. Aftersometime,active
pages with the reference bit set to 1are reset to a state such that
R = 0. After some time, pages in such a state are moved into the
INACTIVE list. Iftheyarenotaccessedanymore,theyareputatthe
top of the INACTIVE list, where they are more likely to be chosen
foreviction.
In other words, Linux manages the space (possibly evicting
pages)throughitsownversionoftheLRUalgorithm,whichworks
asazonebasis:
•Keeptwolistsofcleanpagesforeachzone,activeandinac-
tive(keptinthe pagefile);
•Victimaretakenfromtheinactivelistandmustbenotdirty;
•Pagesgointothe ACTIVElistonlyaftertwoaccesses;
•Linuxperiodicallymovesthepagesfrom ACTIVEtoINACTIVE,
tryingtokeeplistsbalanced;
•Theheuristic refill_inactive whenthe INACTIVE listissmall.
Objectallocation
Inthekernel,thereisalsoaneedtoallocatememoryregionswhich
are smaller than a page. In general, within the kernel, fixed size
datastructuresareveryoftenallocatedandreleased.
However, the Buddy System we presented before clearly does
not scale: internal fragmentation can rise too much48and the48One page for a single object isan enormous waste
ofresources. Buddy System on each NUMA node is protected by a spinlock.
Even if the object we want to allocate has the size of a page, it is
notalwaysefficienttousetheBuddySystem. Forinstance,alloca-
tion and release of page tables requires a frequent allocation and
de-allocationofthesamefixedsizestructuresthroughthefollow-
ingfunctions:
•pgd_alloc() ,pmd_alloc() andpte_alloc() ;
•pgd_free() ,pmd_free andpte_free() .
Fastallocators
Therearetwofastallocatorsinthekernel:
91•Quicklists : usedonlyforpaging;
•Slaballocator : usedforotherbuffers.
Quicklists are used to implement the page table cache (i.e.,
pages that we need for the data of the page table itself). For the
functions pgd~/~pmd~/~pte_alloc() wehavethreequicklists pgd~/~pmd~/~pte_quicklist
per-CPU.Eacharchitectureimplementsitsownversionofquick-
lists, with the same underlying principles. Quicklists use a LIFO
approach: during the allocation, one page is popped off the list
and,duringthefree,oneisplacedasthenewheadofthelist. This
isdonewhilekeepingacountofhowmanypagesareusedinthe
cache.
TheSlaballocatorhasasitsunderlyingideatohavecachesof
commonly used objects kept in an initialized state, available for
use by the kernel. This allocator consists of a variable number of
caches,linkedtogetherbyadoublelinkedlistcalled cache_chain .
Everycachemanagesobjectsofaparticularkind(e.g., mm_struct )
andmaintainsablockofcontiguouspagesinmemorycalled Slab.
1.MoreontheSlaballocatorTherehavebeendifferentimple-
mentations of the Slab allocator to this day. Nowadays, on
mostdistributions,thedefaultSlaballocatoristheSLUBal-
locator.
Let’s recap what we need to have for such an allocator: we
needobjectcaches. Wecan’tusesimplepageallocationfor
eache.g., structsincetherewillbeaconsiderableinternal
fragmentation49.49If we want a 65-page chunk, we have to ask for
and get a 128-page chunk. Or, if we want to allocate a
task_struct ,whichismuchlessthan4K,weneedtoask
for4K.Aslabis an intermediary structure which consists of one
pageframecontainingbothallocateandinitialized(butfree)
objects. Wecancalltheslabtoobtainnewobjects:
void *kmem_cache_alloc(kmem_cache_t *cachep, int flags);
For instance, when a file is opened, the cachepused is the
filp. TheSlabtriestofindaslotintheactive cpuslab. How-
ever, if this is full, a partial one is taken and switched into
theactiveone. Whenlatertheobjectisfreed,itisleftinan
initializedstatesothatthenextallocationwillbefaster.
Note that even kmalloc() is based on the slab: it allocates
generic size from a set of caches ( malloc_sizes ) that are
searcheddynamically.
92TheSlaballocatorprovidestwomainclassesofcaches:
•Dedicated : these are caches created in the kernel for
commonlyusedobjects(e.g., mm_struct ,vm_area_struct ,
etc.). Structuresallocatedinthiscacheareinitialized,
and, when they are freed, they remain initialized for
thenextallocationtobefaster;
•Generic(size-Nandsize-N(DMA) ): these are general
purpose caches, which, in most of the cases, are of
sizes corresponding to powers of 2. This separation
can be seen in the dedicated file for slab in the proc
file-system.
Figure62: TheSLUBallocator
Linuxmemorysecurity
BufferoverflowsandASLR
Bufferoverflowsarenotsorarewhenprogramminginalow-level
programming language as C. To overcome to this fact, the Linux
kernelcamewithaddressspacelayoutrandomization,whichran-
domizesthestackateveryexecutionofabinary. However,buffer
overflowsmayoccuralsoinkernelspace,soLinuxintroducedker-
nelASLR(KASLR),whichrandomizesateachstartupthekernel’s
.textsection. Thisisdonemainlybecauseoneoftheeasiestway
togetrootprivilegesistoexecutetwosimplefunctions:
commit_creds(prepare_creds(NULL));
93Knowingwheresymbolsofinterestliveinthekernel’saddressspace
mightgivetheattackerachancetochange credentials50.50Provided that this attacker knows how to force
theirexecutionwhengettingintokernelspace. Toknow
more on credentials see also https://www.kernel.org/
doc/Documentation/security/credentials.txt .However,KASLRcurrentlyrandomizesonlywherethekernel
code(i.e., .text)isplacedatboottime. Moreover,theamountof
randomizationthatcanbeappliedtothebaseaddressofthekernel
imageisrathersmall, duetotheaddressspacesizeandhardware
constraintsrelatedtomemorymanagement.
Meltdown
Kernel memory can contain sensitive information from all sorts
of applications running in the system (e.g., passwords). In prin-
ciple, kernel memory is allthe memory. The Meltdown attack
demonstratedthatprocessorspeculationcanleakkernelmemory
intousermodelongenoughforittobecapturedbyaside-channel
cacheattack. Forinstance,considerthefollowingpieceofcode:
char my_userspace_buffer[BUFSIZE]; /// attacker created
/// .....
clear_up_cache();
long_instruction();
char t = my_userspace_buffer[ ((*kernel_address_to_be_analyzed) & 1) << BUFSIZE];
/// measure time to load my_userspace_buffer[0] and my_userspace_buffer[BUFSIZE]
Intheexampleabove:
•clear_up_cache() ensuresnoentryin my_userspace_buffer
iscached;
•long_instruction() forces the CPU to begin out of order
issueandexecutionofsubsequentinstructions(i.e.,itstarts
loading *kernel_address_to_be_analyzed );
•Considering the x86 architecture, the fault associated with
this load is triggered only when retiring from the ROB. In
themeantime, *kernel_address_to_be_analyzed isusedfor
successiveinstructionstoloadspeculativelyfrom my_userspace_buffer ;
•To perform the attack, the cache state is examined (i.e., it
measureshowmuchtimeitgetstoload my_userspace_buffer[0]
andmy_userspace_buffer[BUFSIZE] ).Ifmy_userspace_buffer[0]
isfaster,thenthelowbitof kernel_address_to_be_analyzed
was0.
94Meltdown is known to have been used in any actual attack,
evenifispotentiallydisruptive. ForolderIntelCPUs,KPTIisone
possiblesolution.
KernelPageTableIsolation(KPTI)
OnIntelmachines,the CR3processorpointstoafirst-levelpageta-
ble. Thelatterindeedisahierarchicalstructureworkingasshown
inpicture.
Figure63: 4-levelIntelpagetable
In Linux, when the user code is running, its page table does
notcontainallthemappingsforthekernel,butonlyafractionof
them51. When a context switch happens, Linux switches into a51Thisminimumnumberofpagesistheoneusedto
manage a context switch (to invoke system calls essen-
tially).fullblownkernelmemoryaddressspaceandimplementsspecific
actions around user-space code (i.e., protection against execution
andprotection against invalid references ). In practice, we would
notbeabletorunuser-spacecodewheninkernelcontext.
BeforeKPTI,Linuxkeptapagetablewhichhadbothuserand
kernelmappings,sothatmostcontextswitches-relatedoverheads
(e.g., TLB flush, page-table swapping) could be avoided. KPTI,
instead,usestwoseparateuser-spaceandkernel-spacePGD:
•One PGD includes both kernel-space and user-space ad-
dresses (as it was originally), but it is only used when the
95Figure64: KPTIfunctioning
system is running in kernel mode. Protection against ex-
ecution (SMEP) and access invalid references (SMAP) are
bothinplace;
•The second PGD, for use in user mode, contains a copy of
user-spaceandaminimalsetofkernel-spacemappingspro-
vidingtheinformationneededtoenterorexitfromsystem
calls,interruptsandexceptions.
KPTIcomeswitha measurablerun-timecost ,estimatedatabout
5%. Thekernelcodeneededtodealwithinterruptswillnolonger
exist in the address space. So there must be enough kernel code
mappedinusermodetoswitchbacktothekernelPGDandmake
therestavailable. Allentriestothekernelfromring3musthavea
set of trampolines to switch page tables and jump into the kernel
(i.e.,cpu_entry_area ). Noneofthisisaccessibledirectlyfromring
3,butring3codecanjumpintoitbyusingCPU-mediatedmech-
anismsallowingtochangeprivilegelevels(e.g.,theCPU’s syscall
instruction)52.52For more details on KPTI see also https://lwn.
net/Articles/741878/ .
MemorymodelsonSMPmachines
OnSMPs,differentthreadscouldhaveanon-alignedanddifferent
view of the activity of other threads over the memory. Threads
indeedcouldalsohaveanoncoherentviewwrt. operationsdone
inmemory,comparedtotheoriginalprogramflow.
Thememory model defines the visibility’s behavior (and con-
sistency)ofoperationsdonebyonethread,fromthepointofview
oftheotherthreadsexecutingontheSMPmachine. Duetowrite
buffering, speculation and cache coherency protocols of modern
96Figure65: SMPprogramsandexecutiontraces
processors,theorderofwhichmemoryaccessesareseenbyother
threadsmightbedifferentfromtheorderintheissuingthread.
Forexample,considertheprogram:
/// Thread 1
x = 1;
done = 1;
/// Thread 2
while (done === 0) { //* loop **/ }
print(x);
Oncertainprocessors,thisworksintuitively. Forinstance,on
anIntelx86multi-processor,thiswillalwaysprint1. While,onan
ARMprocessoritcanprint0,ifnomitigationisadopted.
Sequentialconsistency
There are two orders of operations: the one dictated by the pro-
gram and another one for which operations are visible to other
threads. Theorderin whichoperationsarevisibleiscalled mem-
oryorder,whiletheotheroneiscalled programorder .
Toformalize,wedefine <pastheprogramorder oftheinstruc-
tions in a single thread and we define <mas the order in which
these instructions are visible in the shared memory (either order
is also referred to as the ”happens-before” relation), or memory
order.
A multi-processor is called sequentially consistent if and only
if,forallpairsofinstructions (Ip;i; Ip;j),wehavethat
Ip;i<pIp;j)Ip;i<mIp;j: (6)
Inpractice,operationsofeachindividualprocessorappearinthis
sequencewithanorderspecifiedbyitsprogram. Thisisclearlythe
strictestmemorymodel.
97Considerthefollowingexample:
/// Thread 1
x = 1
y = 1
/// Thread 2
r1 = y
r2 = x
Onasequentiallyconsistentprocessor,thisprogramcan’tendwith
r1 = 1, r2 = 0 sinceonlythesixinterleavingsinfigurearevalid.
Figure66: Thesixpossibleinterleavings
However, the are architectures for which this memory model
doesn’t hold anymore. In particular, sequentially consistent pro-
cessorsaretooexpensivetobebuiltandtheyrequireanintrinsic
complexitywhichisnotaffordableatall.
TotalStoreOrder
Intel’sx86processorsareTotalStoreOrderones. Considerashared
memory scenario, so these processors are not directly connected
tothissharedmemory,buttheyinteractwithacomponentinbe-
tween called Store Buffer , as shown in picture. This component
isheretohidememorylatencyandcommitsvaluestotheshared
memoryinanasynchronousway.
98Figure67: TotalStoreOrderphysicalmodel
Sincedataisnotimmediatelywrittenintothesharedmemory,
valuestakesometimetobeseenbyotherthreads. Whenprocessor
T1in the example wants to read something which is in the Store
Buffer,thisdataistakendirectlyfromthebufferandread(andwill
notbetakenfromthesharedmemory). Asingleprocessorcansee
effectsofitsownwritesbeforeothers. Ingeneral,thisisaproblem.
Therearesomeprograms(nottheoneshownpreviously)that
can have different effects based on whether they run on sequen-
tiallyconsistentorTSOprocessors.
Considernowtheprogramalreadyseenbefore:
/// Thread 1
x = 1
y = 1
/// Thread 2
r1 = y
r2 = x
Onsequentiallyconsistentprocessors,thisprogramcan’tendwith
r1 = 0, r2 = 0 ,butonTSOprocessorthismayhappen.
This happens before the two writes are executed but their ef-
fectswillbeseenlateron,sincedataneedstoflowinsidethewrite
buffer.
99Figure68: Readmightbypassearlierstores
12 Lecture16-MemoryModelsII&
VirtualizationI
Moreonmemorymodels
Inthelastlecturewesawtwomemorymodels: sequentiallycon-
sistentmachinesandTotalStoreOrderprocessors(e.g.,Intel’sx86).
Now,thereisonelastmemorymodeltobeanalyzed,whichistyp-
icalofARMprocessors.
PartialStoreOrder
PartialStoreOrderistheARMprocessor’smemorymodelandit
isevenweakerthanTSO.Eachprocessorreadsfromandwritesto
itsowncompletecopyofthesharedmemoryandeachwriteprop-
agatestootherprocessorsindependently,withreorderingallowed
asthewritespropagate.
Hardware threads can perform out-of-order writes, or even
speculatively (i.e., before preceding conditional branches are re-
solved). Any local reordering is allowed, unless otherwise speci-
fied. Notethatthereorderingofwritesbyasingleprocessormeans
thatT1’swritesmaynotbeobservedbyotherthreadsinthesame
order. Moreover,readsmightbedelayedafterwrites.
OnARMarchitectures,withinasinglehardwarethread,there
are(implicit)dependenciestoenforceorderings(i.e.,address,con-
trol and data dependencies) that make programming more intu-
itive. However,thememorysystemdoesnotguaranteethatawrite
becomesvisibletoallotherhardwarethreadssimultaneously(this
behavioriscalled non-multicopy-write-atomicity ).
Considernowtheexamplewealreadysawlasttime:
100Figure69: PartialStoreOrderphysicalmodel
/// Thread 1
x = 1
y = 1
/// Thread 2
r1 = y
r2 = x
On a PSO machine, this program can end with r1 = 1andr2 =
0. Therearelittleprogramsthatcantelluswhetheronesystemis
eithercomplyingwithonememorymodelornot,whicharecalled
litmustests .
Dataraces
Data races may occur, as we already saw before. To reason more
intuitively about the memory behavior of TSO and PSO one can
usesynchronizationinstructions. Incomputerscience, theact of
synchronize means to cause something to happen in a planned
way(i.e.,byenforcingsomeorder).
101Figure70: OnaPSOmachine,writesordercouldbenotrespected
Memorybarriers
Fences(orbarriers) are synchronization instructions that enforce
theprogram order <pintothememory order <m. Theseinstruc-
tionsmightflushwritebufferstomakethememoryuptodate.
Figure71: Memorybarriers
Thereareseveralwaysinwhichwecanusefences,forinstance:
•Enforcesequentialconsistencybyputtingfenceseverywhere,
which is the overly conservative thing we can do. In this
way,itiseasiertoreasonabouttheeffectoffences,butwe’ll
102forceprocessors(andcompilers)toavoidoptimizations,low-
eringtheoverallperformance;
•Identify when this order is actually needed. Programmers
usestructuredprogrammingwhereonethreadmustacquire
theownershipofaresourcebeforeworkingonit. Thisline
ofreasoningcanbeexploitedtoenforcetheorderonlywhen
itisneeded.
Hardwarememorymodels
Ahardware memory model defines the behavior and the visibil-
ity (along with the consistency) of operations of a machine lan-
guage program done by one thread from another thread. In this
process,nocompilerisinvolved. Wealreadydefineddataracesin
somesense,buttheyaresituationssuchthatourprogramsubstan-
tivebehaviordepends(inanuncontrolledway)fromthememory
modelandtimingoftheinvolvedthreads. Whenthisthingisun-
desirable, it is considered to be a bug. In other words, there is a
dataracewheneverwehavetwoinstructions aandb(indifferent
threads) where at least one of them is a write and when there is
nothingtoenforceeither a<mborb<ma.
In this example, we have a read (3) and a write (1) for which
we can’t say that (1) happened before (3). These are concurrent.
Sinceatleastoneofthemisawrite,thisiscalled datarace.
There are two operation’s categories we must deal with when
concurrencyisinvolved:
•Synchronization operations : operations that can be used to
enforcethememoryorderofotheroperations. Theycanbe
oftwotypes:
1031.Ownership release operations : synchronization oper-
ations that, when observed, make the observer con-
cludethatallpreviouswriteshavebeencompleted. This
isgenerallyastorethatensuresthatthenextwritehap-
pensafteranypreviously-executedreadsorwrites;
2.Ownership acquire operation : synchronization opera-
tions that must be used by the observer to recognize
the release operation. This is a load that ensures that
thenextreadhappensbeforeanysubsequentreadsor
writes53;53Most importantly, if an operation Pwith release
semantics synchronizes with an operation Qwith ac-
quire semantics, then operation Phappens before op-
eration Q,eveniftheyhappenindifferentthreads.•Dataoperations : normalreadsandwrites.
In the above example, we have a synchronization release (2)
that ensures all previous writes have been completed. It creates a
new, cross-thread arc (i.e., ”synchronizes-with”), which allows us
to say that (1) happens before (3). In particular, to enforce the
reorderingweshouldhaveareleaseoperation(theoneperformed
byT1in the example), followed by an acquire operation (the one
performedby T2intheaboveexample): thisseriesofinstructions
iskeytoenforcethe”happens-before”relationship.
Incasewedon’thavedataraces,hardwarethread T2willnever
seethereorderingof(1)and(2). Theobservabilityof T1’sopera-
tions is thus limited. The basic tenet of memory consistency the-
ory is that, if a program is data-race-free, then it will appear as if
itwassequentiallyconsistentallalong.
104Figure 72: The happens before relationship has been enforced.
Even having reordered instructions in each thread, the program
willbehaveasasequentiallyconsistentone.
Softwarememorymodels
Compilerscanintroduceadditionalreorderingofinstructionsthat
mightappearasifthemachinehadaweakermemorymodel. This
adds another layer of complexity to hardware memory models.
Higherlevellanguagesmustgivetotheprogrammerawaytoen-
force the ordering of happens-before relations just as it is done
at the ISA level. This is called language memory model . These
mustworkportablyacrossSC/TSO/PSOhardwareplatformsand
account for low level differences. For example, we could write a
TSO program that might run on a PSO machine. When writing
data-race-freeprograms,wewillgetthattheywillbehavelikese-
quentiallyconsistentones,evenexploitinghardwareandsoftware
optimization.
In particular, a software memory model defines the behavior
andthevisibility(alongwiththeconsistency)ofoperationsofhigh-
levellanguageprogramsdonebyonethreadfromanotherthread.
For example, a compiler might reorder writes to unrelated vari-
ables. This is perfectly fine for single-threaded applications but
could make a multi-threaded program to behave like it was run-
ningonaPSOmachine. Compilersmayalsointroduceevenweaker
memorymodels(i.e.,theycanevenbreakthecoherence,making
a thread to read the same variable twice with a different history
54).54For more details, see https://research.swtch.
com/plmm.
105TheLinuxKernelMemoryModel(LKMM)
As we saw before, a memory model is a set of instruments with
whichaprogrammercanenforcehappen-beforerelationships. Linux
has its own memory model, which is basically the least common
denominator of the guarantees of all memory models related to
all CPU families running in the Linux kernel. The LKMM pro-
vides non synchronized (relaxed) access to data, with READ_ONCE
andWRITE_ONCE forcingthecompilerto:
•Preventreorderingofreads(writes);
•Omittingreads(forknownvalues)ordoingtoomany(when
registerspillingisneeded).
Thismemorymodelnaturallyprovidesaccesstosynchronized
data:smp_store_release andsmp_store_acquire aretheAPIsthat
could be used55. Moreover, Linux has the atomic_t (32 bit) and55Both of them could be implemented with
READ_ONCE andWRITE_ONCE plusmemorybarriers.atomic64_t types. Operations on these types are always guaran-
teedtobenotinterruptible. Forinstance:
atomic_t v = ATOMIC_INIT(0);
atomic_set(&v, 4);
atomic_add(2, &v);
atomic_inc(&v);
RMWinstructionson atomic_t areimplementedthroughlock-
less techniques (which might involve loops), and/or instructions
withthe LOCKprefix56. Someofthemhaveacquire-releaseseman-56For more details and to inspect the actual source
code, see https://elixir.bootlin.com/linux/v5.
15-rc1/source/arch/x86/include/asm/atomic64_64.
h#L184.tics.
IntroductiontoVirtualization
To introduce the concept of Virtualization , we should start with
thedefinitiongivenin1974byPopekandGoldberg: avirtualma-
chineis
anefficient,isolateduplicateoftherealmachine,
dedicated to an operating system. This VM is based on a virtual
machinemonitor (orhypervisor )that:
•Creates an environment for an operating system which is
essentiallyidenticalwiththeoriginalmachine(havingonly
minorspeeddecrease);
106•Itisincompletecontrolofsystem’sresources.
There are several reasons why to use a virtual machine. The
firstreasonisthatitallowstoconsolidateandpartitionthehard-
ware57and to react to variable workloads (with a reduced hard-57The idea here is to use one physical machine at
100% instead of two at 50% each. Moreover, in some
cases an entire machine is exaggerated for the specific
usecase.ware and administration costs for data centers, providing hori-
zontal scalability). Having virtual machines also allows to have a
standardizedinfrastructure(e.g.,haveafirewallconfiguredinthe
samewaythevirtualmachineisconfigured),simplifyingsoftware
distribution of complex environments. This standardized infras-
tructurealsoallowstohaveisolatednetworkandstorage. Lastbut
notleast,VMsallowsecuritysandboxingandfaulttolerance(e.g.,
checkpointing androllbacks).
Someterminologyandtheorems
Thefollowingisalistofcommonterminologywhichiscrucialto
haveinmindwhendiscussingvirtualization:
•Host system : the operating system where the virtual ma-
chinesrun;
•Guest system : the operating system that runs on top of the
virtualmachine;
•Virtual machine monitor (VMM) or hypervisor : software
programthattranslates/mediatesaccessestophysicalresources
such as interrupts or sensitive processor state and ensures
isolation;
•Instructiontypes : unprivilegedandprivileged. Thelatterare
thosethattrapinkernelmode;
•Virtualizationidea : runprivilegedinstructionsinade-privileged
mode;
•Instructionsensitivity : aninstructionisvirtualization-sensitive
ifitisbothcontrolsensitiveandbehaviorsensitive58.58Beingcontrol sensitive means that the instruction
modified directly the machine status (e.g., enabling or
disabling interrupts, modifying the interrupt vector ta-
ble) and being behavior sensitive means that these in-
structionsbehavedifferentlywhenusedineitheruseror
supervisormode. Thismightaffectfidelity.Therearetwotypesofhypervisors:
•Type1hypervisors (alsocalled nativehypervisors): theyrun
onbaremetalwithoutanyoperatingsystemabstraction;
•Type2hypervisors : theyruninthecontextofanotheroper-
atingsystem(e.g.,KVMandVirtualBox).
107AccordingtoatheorembyPopekandGoldberg
Foranyconventionalcomputer,avirtualmachinemon-
itormaybebuiltifthesetofsensitiveinstructionsfor
that computer is a subset of the set of privileged in-
structions.
Thisdoesn’tmeanthatthevirtualizationcan’tbeimplementedoth-
erwise. Asamatteroffact,oldx86processors(nonVT-x)didnot
respectthePopekandGoldberg’stheoremoriginally(forthisrea-
sonVMWare’sengineersneededtogetaroundthislimitation).
Hardwarevs. softwarevirtualization
Therearetwodifferenttypesofvirtualization: softwareandhard-
warebased.
The software based one is generally done through deprivileg-
ing:
•All guest software must be run at a privilege level less than
thesupervisor;
•VMMrunsinsupervisormodeasacollectionoffaulthan-
dlers;
•Onx86hosts,theusercanbeintwodifferentprivilegemodes
(i.e.,ring1andring3).
Therearetwokindsofsoftware-basedvirtualization:
•Full system virtualization : we have a real abstraction of the
underlying hardware and VMs run unmodified operating
systems(suchastheonesrunningonrealmachines);
•Operating-system virtualization (”containers”): we have an
abstraction of the underlying operating system (and we do
notabstractthehardware)butonlyinitsuser-spacepart59.59Theunmodifieduser-spacerunsinthecontainer.
Inotherwords,softwarebasedvirtualizationensuresthattheguest
usercoderunsontheprocessor,whilemakingguestprivilegedin-
structionsbeinginterceptedandemulated(i.e., trap-and-emulate )
bythehypervisor. Thisistheclassicaldefinitionof full-systemvir-
tualization (1974). AclassicalVMMexecutesguestoperatingsys-
temsdirectly,butatareducedprivilegelevel60.60For more details, see also https://www.vmware.
com/pdf/asplos235_adams.pdf .
108Figure73: Softwarebasedvirtualization
Hardwarebasedvirtualization,instead,introducesnewmodes
toavoidtheproblemsof deprivileging :
•Introducesanorthogonalguest-modewheretheguest’ssu-
pervisor works as in a traditional supervisor (with no ring
aliasing);
•Maintains a control block where the state of the guest can
beexplicitlyandcomprehensivelysavedandresumed(used
forsomeshadowstructures);
•VMMstillisinvokedontraps(called exits).
Figure74: Hardwarebasedvirtualization
109In other words, there are some processors that provide hard-
ware assistance for CPU virtualization. Hardware assisted virtu-
alization reduces hypervisor intervention to the minimum pos-
sible. Processors provide two additional guest/hypervisor modes
whichareorthogonaltouser/supervisormodes,asshowninpic-
ture. Guest/supervisor mode runs almost at native speeds and
onlyoncertaineventsitentershypervisor/supervisormode(typ-
icallyonpagetablemanipulation).
Hypervisorarchitecture
AlwaysaccordingtoPopekandGoldberg,therearethreerequire-
mentsforvirtualization:
•Fidelity: thebehavioroftheVMmustbereasonablyequiva-
lenttotheoneoftherealmachine(theVMcouldbeslower);
•Safety: theVMdoesn’thavecontrolofthephysicalresources,
but only of the virtualized ones. Virtual resources are as-
signed to the VM by the VMM and this control can’t be
overridden;
•Efficiency : programsshould”showatworstonlyminorde-
creasesinspeed”.
1.Arriving to the hypervisor concept Consider now a sim-
plememorymodelimplementingsegmentationas”relocate
andbound”:
L = lowest accessible address
B = virtual memory size
S = physical memory size
Whenever there is a memory access, the operating system
doesthefollowing:
read(A):
if A + L > B then ERROR
if A > S then ERROR
read from memory address A + L
Now,letaskourselveswhetherthismachineisvirtualizable,
byseeingLandBregistersandsplittingthememoryindif-
ferentareas(andsplittingthemfurther). Consider
110(L0, B0) = memory area assigned to the VM
(L1, B1) = L and B registers of the VM
sousingthismodel,weshouldalsohave
(L01, B01) = L and B register while the VM runs: (L0+L1, min(B1, B0-
L1))
Figure75: TheexampleofasimplememorymodelforVMs
In such a setting, if the VMM can guarantee that the vir-
tualmachinecan’tmodifytheLandBregisterspointingto
anout-of-boundmemoryarea,thenitshouldbeenoughto
havealltherequirements. Rightnow,sincethevirtualma-
chine can write L and B arbitrarily, we can’t virtualize this
machine.
We could consider, instead, two modes of execution: user
modeandsupervisormode. Insuchaway,instructionscan
”trap”tosupervisormode:
trap:
MODE = sup
L = 0
B = S - 1
M[0] = PC
PC = 0
However,thisisnotenoughtomakethemachinebeingvir-
tualizable. The reason why we need user and supervisor
modeisthataresomeinstructionscalled sensitive:
•Control-sensitive instructions affect the availability of
resource (overwriting the register L we could make
memorynotaccessiblebeforeasaccessible);
111•Behavior-sensitive instructions behave differently de-
pendingontheconfigurationofthemachine(reading
the L register will lead the VM to have something it
doesn’texpect).
AnefficientVMMispossibleifallsensitiveinstructionsare
privileged, since control-sensitive instructions affect safety
andbehavior-sensitiveinstructionsaffectfidelity61. Theba-61There are examples of sensitive instructions such
as read/write processor flags (e.g., supervisor bit, dis-
able/enable interrupts), read/write segmentation regis-
ters, MMU root (page tables), read/write interrupt vec-
tors,invalidatecaches,etc.sicmechanismforvirtualizationiscalled trap-and-emulate .
2.Trap-and-emulatemechanismTheideaofthe trap-and-emulate
mechanism is to make the VM run alwaysin user mode
andtomaintainacopyofprivilegedCPUregisters(i.e.,pro-
cessorflagsandsegmentation/pagingregisters). TheVMM
trapsthesensitiveinstructions,emulatesthemandgoesback
tothevirtualmachine62. Inparticular,theexecutionofthe62In particular, the VMM executes privileged in-
structions in hypervisor context and go back to the vir-
tualmachine. Thereisalsothepossibilitytoinjectafake
trapintothevirtualmachine.VMbythehypervisoristhefollowing:
for (;;;) {
if (VM has interrupt) {
setup VM registers for interrupt delivery
}
store hypervisor registers
load VM registers
return to user mode
trap_vector:
store VM registers
load VM registers
act on processor trap
}
Thisisaveryoldtechnique(1965,IBMCP-40)and
”each virtual machine program is actually exe-
cutedinproblemstate(i.e.,usermode). Theef-
fectsofprivilegedinstructionsarereproducedby
CPwithinthevirtualmachines”.
Thistechniqueworksbutitimplieshugecostsanditisrather
slow,notsuitablefortoday’sstandards. Itsufferstotrapam-
plification(i.e.,eachtrapbecomes6/7traps). Moreover,vir-
tualizationofpagingstructuresisquitedifficult.
1123.Movingtomodernapproaches: shadowIDTsSoftware-based
virtualization nowadays implies to use two different tech-
niques:
•De-privileging ;
•Shadowing .
We are going to describe both of them. Let’s firstly inspect
thearchitectureshowninfigurebelow.
Figure76: TheshadowIDT
Inavirtualizedsetting, g.supervisor istranslatedinto h.user,
which is reasonable: the virtual machine (even on its su-
pervisorcounterpart) isexecuted in usermode. Privileged
instructionsormemoryaccessesproducesaninterceptable
trap. Moreover, h.supervisor installsitsown(shadow)struc-
turesinsteadofthosedictatedby g.supervisor . Forexam-
ple,x86usesring1insteadofring0forguest’sring063. Ap-63Thistechniqueiscalled 0/1/3virtualization .
plications(runningatring3)can’talterthestateoftheguest
operatingsystem(runningatring1)andthelattercan’tac-
cess data structures of the host operating system. Finally,
exceptions or interrupts are captured by the VMM (at ring
0) and must be properly handled (e.g., by reflecting them
intoring1tasks).
For instance, on x86 architectures, the VMM can trap the
followinginstructions:
113•hlt,lidt,lgdt,invd,mov %crx,sincetheymodifythe
machinestatus;
•cli,sti,sincetheyenableordisableinterrupts.
TheshadowIDTshowninpicturecontainswrappersinvok-
ingtheVMM,whichinturndecidesif g.supervisor must
be called. System calls, for instance, are managed simply
withatrampolinesetup betweenthetwoIDTs.
4.ShadowpagetablesAnumberofkeydatastructuresusedby
processors need to be shadowed , whichmeans thatthere is
anactualphysicaldatastructure(derivedfromtheoneseen
bytheguest)thatisactuallyusedbythehost. Therearesev-
eral shadow data structures used mainly for virtualization.
Forinstance,whendealingwiththepagetable:
a)The VMM intercepts the guest operating system and
setsthevirtualCR3;
b)TheVMMiteratesovertheguestpagetable,constructs
acorrespondingshadowpagetable;
c)Intheshadowpagetable,everyguestphysicaladdress
is translated into the host physical address (i.e., ma-
chineaddress);
d)Finally, the VMM sets the real CR3 to point to the
shadowpagetable.
Ofcourse,theguestoperatingsystemshouldnotmodifyits
pagetabledirectly, rathertheVMMneedstointerceptthis
attemptandupdatetheshadowpagetableaccordingly. The
underlying idea is to make guest page table pages as read-
only(intheshadowpagetable)andmanagecorresponding
traps. Thistechniqueiscalled memorytracing .
Now, consider the case in which there is a page fault in-
volved. The three actors participating will be g.user, trig-
geringtheactualpagefault, g.supervisor , actingasanin-
termediarybetween g.userandh.supervisor ,andh.supervisor ,
updating the shadow page table. Moreover, on a ”simple”
pagefault,manyprivilegedinstructionsareinvolved:
114Figure77: Shadowpagetablestructure
•SettheMMUroot;
•InvalidatetheTLBentry;
•Modifythepagetable.
Figure78: Anexampleofpagefault
However, a security problem might arise in a scenario like
the one depicted in figure. In such a setting, g.usercould
readg.supervisor memory, since such an action will not
produceatrap. However,wecannoticeatleastachangeof
privilege(i.e., g.user !g.supervisor ),sowecankeeptwo
115shadowpagetables,onefor g.userandonefor g.supervisor
andtheformerwillnothaveallthemappingsfor g.supervisor .
13 Lecture17-VirtualizationII
Problemswithtrap-and-emulate
Trap-and-emulate lets the virtualization setting to work, but has
knownproblems. Thereare,aswepointedout,somearchitectures
having virtualization-sensitive unprivileged instructions. For in-
stance,inIntelx86:
•Instructionsmanipulatingtheinterruptflags, h.supervisor
can’ttrackthestateofinterruptscorrectly;
•Readingandwritingsegmentdescriptorsandregisters. For
instance, g.supervisor canseethatithasbeende-privileged
byreadingthecurrentprivilegelevel(CPL).
On Intel x86 we have 4 kinds of unprivileged virtualization-
sensitiveinstructions64:64For more details, see http://www.cs.columbia.
edu/~cdall/candidacy/pdf/Bugnion2012.pdf .
•pushf,popf,iret: instructions manipulating the interrupt
flag(i.e., %eflags.if )arenopinstructionsifexecutedinuser
mode. Thismeansthattheydonottrap. Theguestoperat-
ing system would think it has disabled interrupts, when it
didn’t;
•lar,verr,verw,lsl: providevisibilityintosegmentdescrip-
tors in the global/local descriptor table. These instructions
would access the VMM’s tables (rather than the one man-
aged by the operating system), thereby confusing the soft-
ware;
•pop <seg> ,push <seg> ,mov <seg> : manipulatesegmentreg-
isters. Thisisproblematicbecausetheprivilegelevelofthe
processorisvisibleinthecodesegmentregister. Forexam-
ple,push %cs copiesthe %cplasthelower2bitsoftheword
pushed onto the stack. Software in a virtual machine that
expectedtorunat %cpl = 0 couldhaveunexpectedbehav-
iorifpush %cs wastobeissueddirectlyontheCPU;
•sgdt,sldt,sidt,smsw: provide read-only access to privi-
leged registers such as %idtr. If executed directly, such in-
structions return the address of the VMM structures, and
116not those specified by the virtual machine’s operating sys-
tem.
Thus,thereareseveralproblemswithpuretrap-and-emulate:
•Ring aliasing : a guest operating system could easily deter-
minethatitisnotrunningatsupervisorprivilegelevel;
•Addressspacecompression : operatingsystemsexpecttohave
accesstotheprocessor’sfullvirtualaddressspace. However,
the VMM must have a minimal amount of pages allocated
intheguestaddressspacetomanagetraps;
•Excessive faulting : on x86, sysenter andsysexitare used
for each system call, but they trap into the VMM any time
theyareexecutedbytheguestoperatingsystem. Whentrap-
ping into the VMM, they will raise interrupts themselves,
yieldingtoexcessivetrapping.
Binarytranslationasasolution
The first idea of virtualization providers was to use a so-called
binary translator , which converts an input binary instruction se-
quenceintoasecondbinaryinstructionsequencethatcanexecute
natively on the target system. When VMWare Workstation first
shipped,thebinarytranslatorconsistedofapproximately27thou-
sandslineofCsourcecode( 45%ofthetotalVMMlinecount).
A dynamic binary translator performs the translation at run-
timebystoringthetargetsequencesintoabuffercalled translation
cache.
Itconsistsinaloopwhereadispatchfunctionisinvoked:
•Thedispatchfunctionlookedupthelocationinthetransla-
tion cache corresponding to the current state of the virtual
CPU;
•Ifnonewasfound,itinvokedthetranslator,whichfirstde-
coded a short instruction sequence (no longer than a ba-
sic block) starting at the current virtual CPU instruction
pointer,generatedacorresponding(buttranslated)instruc-
tionsequenceandstoreditinthetranslationcache;
117Figure79: BinarytranslationinVMWare
•The dispatch function then transferred control to the loca-
tioninthetranslationcache. Thetranslatedcodeconsisted
ofnativex86instructionswithinthetranslationcache,and
couldencodecallstosupportroutines. Thesecalloutstypi-
callyinvokedthedispatcheragain,toclosetheloop.
Inparticular,virtualizationsensitiveinstructionsaretranslated
intospecializedinlinedsequences.
Hardwareassistedvirtualization
Theideabehindhardwareassistedvirtualizationissuchthatsen-
sitive (but not privileged) instructions become privileged, in or-
der for the hypervisor to handle all the corner cases we already
discussed. Let’s first analyze the main goals of hardware assisted
virtualization:
•Avoidproblemsofdeprivileging,whichmeansthat g.supervisor
worksasatraditionalsupervisor(withnoringaliasing),by
addingnewmodes;
•Allowthestateoftheguesttobeexplicitlyandcomprehen-
sivelysavedandresumed(usedinsomeshadowstructure).
Secondary goals for hardware assisted virtualization are the
following:
•Onx86,finallyobeytoPopekandGoldberg’srequirements;
118•Improveperformancebyreducingthenumberoftrapsfrom
systemcallsandinterruptsandbyavoidingtheshadowpag-
ingoverhead.
Inparticular,theyintroducedanewmodeusinghardwarefa-
cilitiestochoosewhichprivilegedinstructionsareactuallysensi-
tive and which, instead, can be managed without an hypervisor
call.
Solutionsproposedbyvendors
Vendorsproposedtheirownwaytoofferhardwareassistedvirtu-
alization. OnARMandPowerPCthehypervisormodehasitsown
rule. Inparticular,thehypervisorlivesinitsownprivilegedmode,
which is different from the supervisor and user one. On ARM
thereisadifferentpagetableformat,whileinPowerPCthereisno
pagingatall. Intel(onVT-x)introducedtwoorthogonalprivilege
modes mirroring the original ones, while RISCV does an hybrid
betweenthetwo(thehypervisorlevelissharedbetween”nonvir-
tualized”and”guest”).
Figure80: Hardwareassistedvirtualizationproposedbydifferent
vendors
Note that ”non root” in x86 is equivalent to ”guest” operating
system. In such a setting, whenever the user code does a system
call, given that levels are explicit now, those system calls can be
119managedwithoutincurringintheVMM.Onx86andRISCV,hy-
pervisormodeisasupersetofregularsupervisormode. Moreover,
in x86 a virtual machine control block holds the state of the en-
tireguest,sothatcontextswitchesareperformedbytheprocessor
withaspecialinstruction. OnARM,PowerPCandRISCV,special
processorregistersholdminimalinformationontheguest.
Comparingwithsoftwareassistedvirtualization
Hardwareandsoftwareassistedvirtualizationshavetheirownstrengths
and drawbacks65. In particular, hardware virtualization has sev-65For mode details, see https://www.vmware.com/
pdf/asplos235_adams.pdf . eraladvantages:
•Whenhavingmanysystemcalls,hardwareprevailsbecause
suchcallsrunwithouttheVMMintervention;
•Recovering the guest state to manage traps is easier with
supportfromhardware;
•Having no binary translation means less overhead and less
memory.
Thesestrengthscomewithcostsanddrawbacks:
•Someinstructionsneedtotrap,befetchedandexecutedby
theVMM,whileinsoftwaretheycanbedirectlytransformed
intoanemulationroutine(e.g.,memorytracing);
•I/OrequiresafullVMM-guestroundtripwhileinsoftware
theycanbeoperatedonavirtualchipset;
•The control path on page faults (which is similar for both
hardware and software) could have a higher overhead in
hardwarewithrespecttosoftware.
Speedingvirtualizationup
Nowlet’sanalyzeallthosetechniquesthathavebeenusedtospeed
uptheperformanceinvirtualization.
120Figure81: OverheadbetweensoftwareandhardwareVMM
Extendedpagetables
Usingthetraditionalwayofmanagingpagetables,wewouldhave
onlyasinglekeyregisterwhichisused: theMMUconsultsjustthe
PGD contained in the host CR3; the guest CR3is just an illusion.
The PGD pointed by CR3thus contains the full translation from
the guest operating system’s virtual pages down to host’s physi-
cal pages. Whenever the guest operating system wants to mod-
ify something in its own page table translation, the VMM traps
thisinteractiontokeeptheentirevirtualmemoryviewconsistent.
Note that this technique also applies to hardware based virtual-
ization. In some sense, this is equivalent, in terms of overhead,
tohaveashadowpagletabletobeconsistentwiththeviewofthe
guestoperatingsystem.
Figure82: Thetraditionalwayofmanagingpagetables
WithhardwarebasedtranslationintroducedbyIntel, thereis
alsoanewwayforavoidingtotrapalwaysintotheVMMwhenever
121dealing with page tables. This new technique is called extended
page table . There will be two actual key registers in the machine
andthehostMMUnowholdstwopointers:
•g.cr3, containing guest-virtual to host-virtual (i.e., guest
physical)mappings;
•h.cr3, containing onlyhost-virtual to host-physical map-
pings.
In such a setting, the guest’s page table pointer has more au-
thority: g.cr3is manipulated directly by the guest, with no in-
terventionfromtheVMM.ThePGDpointedby h.cr3storesthe
translationfromguest’sphysicalpagesdowntohost’sphysicalpages
66. This means that guest’s physical pages don’t need to be pro-66Insuchasetting,host’sphysicalpagesarebasically
treatedashost’svirtualpagesbythehost’sPDGitself. tectedintermsofreadsandwrites.
Figure83: Extendedpagetables
I/Opassthrough
Virtualmachinesoftenmakeuseofdirectdeviceaccess(i.e.,”de-
vice assignment”) when configured for the highest possible I/O
performance. Fromadeviceandhostperspective,thissimplyturns
the VM into a userspace driver, with the benefits of significantly
reduced latency, higher bandwidth, and direct use of bare-metal
devicedrivers.
In particular, to exploit such a functionality, we should have
the root Linux kernel booted with io_mmu = on , detach the spe-
cificdevicefromitstraditionaldriverandbindittoa VFIOdriver.
When launching the ”guest”, the VMM must configure it to use
such ”vfio” interface to connect to the device by setting up the
IOMMU (usingioctl()onsysfs). Interrupts are remapped by
122VFIOto aneventfdobject, which is more or less a socket used
for evented IPC. The VFIO driverexposes direct device access to
userspace, in a secure IOMMU protected environment. In other
words,thisallowssafenon-privileged,userspacedrivers.
Figure84: I/Opassthroughmechanism
ManymodernsystemsnowprovideDMAandinterruptremap-
pingfacilitiestohelpensureI/Odevicesbehavewithinthebound-
aries they are provided with. This includes x86 hardware with
AMD-ViandIntelVT-dandPowerPCsystemswithPartitionable
Endpoints(PEs).
KVM
KVMisaloadablekernelmodulethattakesawaytheproblemof
creatingourownVMM67.Itconsistsofamodulethatprovidesthe67For a practical example, see https://lettieri.
iet.unipi.it/virtualization/2018/kvm.cc . corevirtualizationinfrastructureandaprocessorspecificmodule
(e.g.,kvm-intel.ko ,kvm-amd.ko ). KVM was originally a forked
versionofQEMUandwasprovidedtolaunchguestsanddealwith
hardwareemulationthatisn’thandledbythekernel. Thatsupport
waseventuallymergedintotheupstreamproject.
Paravirtualization
Paravirtualization hasasitsmaingoaltogoevenbeyondvirtual-
izationanddealswithchangingthetargetguestandreplacingthe
123Figure85: TheKVMarchitecture
difficult-to-virtualizeinstructionswithsomethingelse. Rewriting
allthetarget’ssoftwarefromscratchisoutofquestion,butporting
awelldesignedkerneltoanewarchitectureisamatterofreplacing
thesystem-specificroutinesandrecompiletherest(e.g.,insteadof
accessingtheMMU,theparavirtualkernelcouldcalltheVMMfor
writeaccesstopagetables). Thistechniquewasfirstintroducedin
theXENhypervisor,butnowadaysitismostlyusedwithindrivers
intheguest.
VirtIO
VirtIOis a specification for writing device drivers targeting the
guest that access directly the host. We introduce it by looking at
differences between the standard way of emulating a device and
theparavirtualizedcase.
Consider now a Network Interface Controller (NIC) and the
wayinwhichitwouldbetraditionallyhandledinvirtualmachines
as an emulated peripheral. The non-root machine will behave as
arootone, not knowing that there is an underlying host. Given
packet queues handled by the kernel, at some point the kernel
willwriteintosomehardwareregisters, whicharetheringbuffer
head/tailhardwareregisters(i.e., TDT|TDHandRDT|RDH).However,
any read and write to this hardware registers triggers a VM-exit
(to write into the actual hardware registers accessed by the host).
In particular, KVM must read registers, reconstruct packets and
sendthemtothehostnetwork,whichisnotminimalasfarasthe
overheadisconcerned. Thiscaseisdepictedinfigurebelow.
124Figure86: Theemulatedcase
Now, speaking about the VirtIOcase, we have a new driver
calledvirtio-net that communicates to the host through an inter-
facecalled guestvirtio . Inparticular,ithasthisdirectconnection
by writing into a queue (i.e., virtqueue) which is different from
whathasbeendonebefore(writingtoregisters). Thiswriteraises
a trap, to inform the host that a message is coming. The host op-
eratingsystemreadsthatspecificmessageandwriteittothehost
network driver. Doing this, we are minimizing the time of the
vCPUthread waitingforthepackettobesenttothehostperiph-
eral. Thisdescriptionisdepictedinfigurebelow.
Paravirtualizationisamustwhenspeedingupthevirtualma-
chine.
Containerization
Containers are a way to isolate a set of processes and make them
thinktheyaretheonlyonesrunningonthemachine. Themachine
they see may feature only a subset of the resources actually avail-
ableontheentiremachine(e.g.,lessmemory,lessdiskspace,less
CPUs, less network bandwidth). However, keep always in mind
thatcontainersarenotvirtualmachines : processes running in-
sideacontainerarenormalprocessesexecutingonthehostkernel,
125Figure87: Theparavirtualizedcase
thus there is no guest kernel running inside the container. This
also means that we can’t run an arbitrary operating system in a
container, since the kernel is shared with the host (i.e., Linux in
ourcase).
The most important advantage of containers with respect to
virtualmachinesisperformance: thereisnoperformancepenalty
inrunninganapplicationinsideacontainercomparedtorunning
it on the host. Linux containers are implemented using two dis-
tinctkernelfeatures: namespaces andcontrolgroups .
Intermsof security,thereisahugedebatebetweenthevirtual
machinesbeingmoresecurethancontainersandviceversa. Vir-
tual machines are considered (by some) to be more secure than
containers,sincetheyhaveasmaller attacksurface68,whichisthe68Withattack surface we mean the amount of code
andfeaturesthatamaliciousattackermayprobetofind
exploitablebugs.hypervisor (vs. theentirekernel forcontainers). TakingKVM,itis
akernelmoduleandusessomefacilitiesfromtherestoftheLinux
kernel(e.g.,forscheduling,virtualmemoryetc.). However,thisis
stilllessthantheamountoffeaturesandcodeusedtoimplement
containers.
Namespaces
Namespaces provide a means to segregate system resources. In
some sense, this is similar to what the (by now, old) chroot()
syscalldoes:
•For each process, the kernel remembers the inode of the
processrootdirectory ;
126•Thisdirectoryisusedasastartingpointwheneverthepro-
cess passes the kernel a filesystem path that starts with "/"
(e.g.,ina open());
•Wheneverthekernelwalksthroughthecomponentsofany
filesystempathusedbytheprocessandreachestheprocess
root directory, a subsequent "..."path element is ignored
69;69In other words, we are just introducing a bound-
ary that can’t be climbed. This boundary the root from
whereallthepathinspectionofdirectoriesstarts. •Onlyrootcancall chroot();
•Theprocessrootdirectoryisinheritedbyitschildren.
Tosummarize,byusing chroot() wecanmakeasubsetofthe
filesystemlooklikeitwasthefullfilesystemforasetofprocesses.
Chrootenvironments, however, are not full containers. Contrary
topopularbelief,infact, noteverythingisafileinUnix (e.g.,net-
workinterfaces,networkports,usersandprocessesarenotfiles).
Whilewecanhaveasmanyinstancesaswewantof,say, /etc/passwd ,
each different and living in its own chrootenvironment, we can
onlyhaveoneport80throughoutthesystem(thus,onlyoneweb
server), only one process with pid = 1(thus, only one init pro-
cess),anduserandprocessIDswillhavethesamemeaninginall
chrootenvironments.
Now,namespaces have been introduced to create something
similarto chrootenvironmentsforalltheseotheridentifiers. Each
processinLinuxhasitsownnetworknamespace,PIDnamespace,
usernamespaceandothers. Networkinterfacesandportsareonly
defined inside a namespace, and the same port number may be
reused in two different namespaces without any ambiguity. Nor-
mally,allprocessessharethesamenamespaces,butaprocesscan
start a new namespace that will be then inherited by all its chil-
dren, grandchildren, and so on. This is done when the process is
createdusingthe clone()systemcall.
Controlgroups
While namespaces can be used to hide and create private copies
ofallthesystementities,theyarenotsufficientinisolatingsetsof
processessothattheycannotinterferewitheachother. Processes
mayinterferealsobyabusingthesystemresources,e.g.,allocating
127Figure88: Namespacesfunctioning
too much memory, using too much CPU time, or disk and net-
work bandwidth. To properly implement containers, therefore,
we also need to limit the usage of resources by processes living
in the container. Control groups are groups explicitly created by
the administrator, who can later assign processes to them. The
administrator may setup the system so that processes cannot es-
cape their control group. Control groups can be organized in a
tree-shaped hierarchy: each process in the system must belong to
exactlyonecontrolgroupinthehierarchy,andthereforethehier-
archyisapartitionofthesystemprocesses. Whenaprocesscreates
a child process, the child inherits the control group of its parent.
Notethatsomecgroupsmaybeempty. Indeed,itisgoodpractice
to put processes only in the root cgroup and in the leaf cgroups,
leavingallintermediate cgroupsempty70. Oncewehavetheabil-70This procedure has become mandatory in the
newestversionof cgroup,whichis version2. ity to reliably group processes in one or more hierarchy, we can
startcontrollingtheirresourceusage. Tothisaim,hierarchiescan
be linked to so-called subsystems (subsystem controllers would be
a better name). Subsystems are used to control the resources as-
signed to the cgroups in the linked hierarchy. Some examples of
existingsubsystemsare:
•Memory: limits the amount of main memory used by each
cgroup;
•CPU:limitsthemaximumfractionofCPUthateach cgroup
mayuseandmayscheduletheCPUbasedon cgroupsweights;
•CPUacct: thisisnotmuchofacontroller,sinceitonlypro-
vides accounting information about the CPU usage of the
128cgroups;
•CPUset: onmulti-CPUsystems,limitsthesetofCPUsthat
maybeusedbyeach cgroup;
•PIDs: limitsthenumberofprocessesthatcanbecreatedin
acgroup.
Thearealsoothersubsystemsthatcontroldeviceaccess,block
I/Oetc. Tohaveapracticaloverviewofhowtousenamespaces,see
alsohttps://lettieri.iet.unipi.it/virtualization/2018/containers.
pdf.
14 Lecture18-I/ODevicesandDriversI
Introductiontohardwareperipherals
In a more classical view of system device architecture, the CPU
is connected to a shared bus to interact with other devices (e.g.,
memory and peripherals), but this turns out to be not feasible in
practice: the shared bus would introduce several delays for the
CPUtointeractwithexternalperipherals. Whatwehave,instead,
is a more point-to-point approach: the CPU is connected to the
memory using a DDRinterface and to graphics cards with PCIe
connections71. There is also an external hub called I/O chipset71Foritsveryownnature,PCIisaserialbusandhas
severallanestoconnect,e.g.,graphiccardstotheCPU. (connectedtotheCPUwitha DMIinterface)whichmanagesthe
connectiontoalltheotherdevicesboththroughPCIeconnection
(e.g., NVMe SSD, network cards) and through SATA (e.g., SATA
SSDsandHDDs). ThePCIspecificationprovidesawaytotheop-
eratingsystemtolookatthetopologyofthesystemitself,whichis
veryusefulintermsofperipheralsmanagement. TheI/Ochipset
isalsousedforUSBconnection,whichisadifferentstandard,and
serialports(i.e.,RS232).
Intermsofcommunication,theCPUread/writesfrom/tope-
ripherals using their so-called device ports , which can be charac-
terizedbothbyacertainmemoryaddresstowhichtheCPUwrites
orreads(withnormal loadandstoreinstructions)orbyspecific
I/OportsaddressesthataremanipulatedbytheCPUwithspecial-
izedinstructions.
129Figure89: Modernsystemdevicearchitecture
Now,speakingaboutserialports,wehavetwowiresthatcon-
nectthedevicetotheactualmotherboard,butconcerningtheCPU
the device port (UART) is seen as a set of registers and, in turn,
these are seen as memory locations orport locations , as said be-
fore. Apartfromthetransmitandreceiveregisters(i.e., THBand
RBR)thereareseveralconfigurationregisters. Amongthesethere
istheIIRregisterthatsendsaninterrupttotheCPUoncharacter
receivedand/orsent.
Figure90: Exampleofadeviceport(UART)
130Mechanismstointeractwithdevices
There are basically two ways in which the CPU can interact with
externaldevices:
•I/Oports: theyprovideexplicitI/Oinstructions72 72On Intel x86 processors, the inandout(which
areprivileged)instructionscanbeusedtocommunicate
with devices. Each device is assigned to a portnumber
intheI/Oaddressspace,whichnamesthedevice.•Memory-mapped I/O : the hardware makes device registers
available as they were (virtual) memory locations, without
theneedtouseprivilegedinstructionstointeractwiththem.
I/Oinstructions
For example, to read the character received by UART into alwe
coulddo:
in RBR, %al ;;; RBR = 0x2f8
Theportnumberin RBRislimitedtobeenclosedinrange [0;216],
which is quite limited in modern architectures. With memory-
mappedI/Owecanovercomethislimitation.
Memory-mappedI/O
As we said before, in/outinstructions are slow and clunky: the
instructionformatrestrictswhatregisterscanbeusedandonlyal-
lows 216different port numbers. Moreover, per-port access con-
trol turns out not to be useful (any port access allows to disable
all interrupts). Devices can achieve the same effect with physi-
cal addresses: the operating system must map physical to virtual
addresses, ensure non-cachable pages and to assign physical ad-
dresses at boot to avoid conflicts. For instance, we could have an
interactionimplementedasfollows:
volatile int32_t *device_control = (int32_t *) (0xc0100 + PHYS_BASE);
*device control = 0x80;
int32_t status = *device_control;
Inthisway,wearepointingtoadeviceporttowritetoit(bywrit-
ingapointer),andthenwereadthestatusfromit. Thisisallman-
agedusingpointersandnotexploitingprivilegedinstructionsac-
cessingdeviceregistersdirectly.
131DevicetoCPUcommunication
ThedevicecancommunicatedatatotheCPUintwofundamental
ways:
•Polling;
•Interrupts .
Polling
Pollingis basically a loop performed by the CPU (i.e., the CPU
spins)towaitfordataoractiontobefinished. Forinstance,
while((inb(LSR) & (1<<5)) === 0)
/// wait until the UART is ready to send;
outb(c, THR); /// send character
In this case we are waiting for a certain register (i.e., LSR) to con-
tain some bits indicating that the device is ready to accept data.
Whenthedeviceisslow,pollingwastescycles. Ifthedeviceisfast,
instead, it is quite inexpensive: for instance, there is no saving of
registers.
Interrupts
Insteadofpollingthedevicerepeatedly,theoperatingsystemcan
issuearequest,putthecallingprocesstosleep,andcontextswitch
toanothertask. Whenthedeviceisfinallyfinishedwiththeoper-
ation, itwill raise a hardware interrupt , causingthe CPU tojump
intotheoperatingsystematapredetermined interruptservicerou-
tine(ISR),ormoresimply,an interrupthandler .
Interrupt makes sense for slow devices, otherwise the cost of
interrupthandlingmightbemorethanwhatweexpect73. When73Note that an interrupt takes on the order of a mi-
crosecond (we need to save/restore the state, deal with
cachemisses,etc.).there are too many interrupts, the operating system might live-
lock, that is, find itself only processing interrupts and never al-
lowingauser-spaceprocesstorunandactuallyserverequests. In
fact,somedevicesgenerateeventsfasterthanonepermicrosecond
(e.g., a gigabit Ethernet can deliver 1.5 million small packets per
second): anoldapproachwasthateveryeventcausedaninterrupt
(simple hardware, smarter software), but nowadays the hardware
completes lots of work before interrupting. To enable interrupts,
aninterruptcontrolledneedstobeprogrammed. Programanin-
terruptcontrollermeanstosetuphowthesystemshouldinterpret
132signalsfromdevices(edgetriggered,leveltriggered,etc.) andhow
hardware signal numbering should be mapped to interrupt han-
dlers.
DirectyMemoryAccess(DMA)
When using programmed I/O (PIO) to transfer a large chunk of
data to a device, the CPU is overburdened with a rather trivial
taskandmightwastetime. Thisiswhyandadditionaldevicethat
can orchestrate transfers between devices and memory without
CPU intervention has been introduced. This device is called Di-
rect Memory Access (DMA). In figure below, there is the original
interaction between an external device and the CPU. This will be
usefulwhencomparedwiththeDMAapproach.
Figure91: TheoriginalCPU-deviceinteraction
Towrapup,intheoriginalinteractiontheCPUwritesasingle
bytetriggeringthedevicetosendtheactualdata. Inthemeantime
theCPUdoessomethingelse,untilaninterruptarrives,andsoon
andsoforth.
InDMA,instead,wehavetheCPUsendingacommandsuch
as”send xbytesfrommemorylocation Mtobyteregister TXof
UART” to the DMA controller. The entire interaction is now han-
dledbythelatter,sendingsignalstotheCPUon half-transmitcom-
plete(HTC)and transmit-complete (TC)only. PCIallowsanype-
ripheraltohaveaDMAandthisgoesunderthenameof firstparty
DMA.
133Figure92: TheDMAapproach
Linuxinterrupts
Therearebasicallytwodifferenttypesofinterrupts:
•Asynchronousinterrupts (i.e.,I/Ointerrupts),whicharegen-
eratedbyotherhardwaredevicesatarbitrarytimeswithre-
spect to the CPU clock signals. These interrupts could be
maskable andunmaskable :
–Maskable interruptsareallInterruptRequests(IRQs)
issuedbytheI/O.Amaskedinterruptisignoredbythe
controlunitaslongasitremainsmasked;
–Non-maskable interruptsare,instead,alwaysrecognized
bytheCPU;
•Synchronousinterrupts (i.e.,exceptions),whichareproduced
bytheCPU’scontrolunitwhileexecutinginstructions. They
arecalledsynchronousbecausethecontrolunitissuesthem
onlyafterterminatingtheexecutionofaninstruction. These
exceptionscanbedividedin:
–Faultexceptions : theyimplytocorrectandre-execute
thefaultinginstruction;
–Traps: they imply to not re-execute the excepting in-
struction.
Interrupts are issued by interval timers and I/O devices (e.g.,
thearrivalofakeystrokefromausersetsoffaninterrupt). Execep-
tions,ontheotherhand,arecausedeitherbyprogrammingerrors
or by anomalous conditions that must be handled by the kernel.
134Notethatthecodeexecutedbyaninterruptorbyanexceptionis
not a process. Rather, it is a kernel control path that runs at the
expenseofthesameprocessthatwasrunningwhentheinterrupt
occurred(i.e.,itruns onbehalfofaprocess ).
Finally, some examples of maskable interrupts could be non-
recoverablehardwareerrors,aswellasacorruptioninsystemmem-
orysuchasparityandECCerrorsordatacorruptiondetectedon
systemandperipheralbuses. Exceptions,instead,onanIntelx86
machinecouldbedivisionbyzero,debug74,breakpoint(i.e., INT374The address of an instruction or operand may fall
withinarangeofanactivedebugregister. instruction),invalidopcode,protectionfault,pagefault,etc.
Theinterruptflow
On Linux, each interrupt or exception is identified by a number
ranging from 0to255(calledvector). In particular, on Intel’s
x86 machines, each vector 32 + nis calledIRQ nand is asso-
ciated with I/O interrupts. IRQs are external interrupts and con-
stitute a subset of interrupt vectors. They are remapped by the
Programmable Interface Controller (PIC) into a vector number,
as we already said. This vector number has a corresponding en-
tryintoatable,called InterruptDescriptorTable (IDT).Thistable
contains handlers for all vectors and is pointed by the idtrma-
chine register. Each entry identifies a segment selector and offset
(i.e.,entry_ptr = segment_selector + offset )pointingtoaso-
calledInterruptServiceRoutine(ISR),afunctionwhosejobisto
handletheinterrupt. Asalreadysaid,thisserviceroutineiswithin
a segment specified in the GDT. Thus, for each vector Linux reg-
isters a routine called do_irq(n) that invokes all the actions that
devicedrivershaveregisteredtobeexecutedwhenthatspecificin-
terruptrequestcomes. Typically,thefirstpartofthisroutinedis-
ablesallinterruptsandLinuxavoidsnestedinterruptsofthesame
numberbyusingamethodofPICactionscalled ack(). Then,the
handlerisactuallyexecuted,followedbyacallto end()whichre-
enablesinterrupts(i.e.,itistherevertof ack()). Certainly,allthese
actionsareexecutedinkernel-mode.
Note that, on interrupt arrival, the processor switches to su-
pervisor, in the context of the current task’s supervisor stack. In
thenewstack,itsaves:
•Theinterruptvectornumber;
135Figure93: TheLinuxinterruptflow
•Thereturninstructionpointer;
•TheoldCSsegmentselector;
•TheoldvaluesofSSandESP.
Thefollowingpieceofcodeisanexampleofregisteringanac-
tionwithintheIRQsubsystem:
static irqreturn_t handler(int irq, void *mydata)
{
/// .....
/// acquire locks on shared data
/// read/write from peripherals through MMIO
/// defer work
/// release lock
return IRQ_HANDLED;
}
static int __init mydriver_init_module(void)
{
/// allocate space for mydata
ret = request_irq(irqnum, handler, IRQF_SHA, mydata);
/// .....
}
136ProgrammableInterruptController
ThePICisanexternalcircuitforwhichLinuxhasappropriatein-
terfaces to interact with. Legacy PIC had a number of pins that
couldbeusedtoinformitthatthereisadevicewantingtogener-
ateaninterrupttobeexecutedontheCPU.TheCPUwouldreceive
that interrupt through a single signal (single line) and once it re-
ceived the interrupt it used a very specific interrupt bus (directly
connected to the PIC) to read data associated with the interrupt
itself. We could even use multiple PIC of this type in our archi-
tecture at that time. To summarize, legacy PICs were allowed to
use only 1 CPU interrupt pin ( INTR) to manage 8 interrupts and
couldbeusedinachain(master/slave)oftwo,increasingIRQsto
15. Note that, upon a multiple signals arrival through the input
lines, thePICdecided tochoose theonewiththelowerinterrupt
number.
Figure94: LegacyPICarchitecture
Having 8 to 15 IRQs became very soon a limit and has been
surpassedevenbecausewestartedtohavemultipleprocessorsdeal-
ingwithmultipledevices. TheAdvancedProgrammableInterrupt
Controller(APIC)wasintroducedforthatmatter. WithAPIC,we
couldhave24interruptsdividedasfollows:
(
ISA![0; : : : ; 15]
PCIdevices ![16; : : : ; 23]:(7)
137WithxAPICspecification we could even reach 256different
interrupts. These interrupts are structured as follows: each CPU
has its own circuitery for managing interrupts (called Local Pro-
grammableInterruptController -LPIC)connectedtoaAPICbus
sothatwecouldprogramthemainAPICasaroutertomapinter-
ruptrequesttospecificCPUs. Inthiswaywecanalsoprogramthe
APIC to distribute the workload when managing a certain inter-
rupt. Inotherwords,itactsasarouterwithrespecttolocalAPICs
andcanbeprogrammed. Moreover,forlogical/lowpriority+op-
erationsitcandeliverinterruptstomultiplecoresinaroundrobin
fashion. Each CPU could interact with other CPUs through the
generationof inter-processorinterrupts ,enablingasortofmessage
passingbetweenCPUs. Interruptsmayalsoarriveunorderedwith
respecttowritesdonebyadevicethroughDMA75.75Thisbringsasevereconsistenctyproblem.
Figure95: APICarchitecture
The APIC architecture, for some interrupts, has been substi-
tuted by a messaging mechanism through PCIe, whose idea is to
remove physical wires from devices and use PCIe buses to write
messages instead. Each device can produce up to 32 interrupt
types and these are synchronous with respect to data read/write
tomemory.
138Figure96: MSIarchitecture
Deferringwork
Whenexecutinginterrupts,wewanttoavoidasmuchaspossible
to do all the necessary work right after the interrupt had arrived.
Theideaof deferringwork istomovethenon-criticalmangement
of interrupts to a later time. It might also benefits from aggre-
gation, in the sense that we would have many small operations
mergedintoasingleone.
Originally,everyinterruptmanagementwasdividedintotwo
levels:
•Tophalf: executesaminimalamountofworkwhichismanda-
torytolaterfinalizethewholeinterruptmanagement76and76Thisworksina non-interruptible scheme.
schedulessomedeferredwork(i.e., deferredfunctions );
•Bottomhalf : finalizestheworkbydeferredfunctionsfrom
a queue and executes them. Bottom halves are invoked in
particular reconciliationpoints intime.
Therearebasicallythreewaystoperformthedeferringwork:
•SoftIRQs(mainmechanism,rarelyusedalone);
•Tasklets;
•Workqueues.
13915 Lecture23-SeminaronSoftware
VerificationI
IntroductiontoSoftwareVerification
Software verification is a very classical problem: we write a pro-
gram and we want to be sure that it is correct. From the theory
we know that this problem is undecidable (from Rice’s theorem).
However, we actually need to prove correctness in particular sit-
uations (in safety-critical systems), where errors can cost a huge
quantityofmoney,orevenlives. Themostusedtechniquetohave
someguaranteesis testing,butofcourseisverylimited: itcanonly
provethatasystemhaserrors,notitscorrectness.
Operating systems are among the most critical examples of
software and so verification is often used for plenty of aspects of
an operating system. There are two typical properties which are
checked:
•Security: forinstance,wewanttocheckiftheoperatingsys-
temisvulnerabletosomeattacks(e.g.,codeinjection,buffer
overflow);
•Safety: forinstance,wewanttheoperatingsystemtobere-
liableandfreeofcrashes, orthatitisresponsiveenoughin
somespecificreal-timeenvironment(e.g.,acontrolsystem
ofanaircraft).
Mainapproaches
Therearebasicallytwomainapproachestotheproblem:
•Modelchecking : totallyautomatic,buthasnecessarylimita-
tions on the expressivity of used notations (remember that
theproblemisnon-decidable);
•Automatedtheoremproving : itismoregeneral,butkindof
”user-driven”77.77Thesetoolsareoftencalled”proof-checkers”.
1.Model checking This technique was introduced in the ’80s
fora”push-button”verification. Itsbasicideaisthatwehave
amodel Mofthesystemandoneofitsproperties,called 
(usuallywritten Mj=). Ourmodel Misstillanabstrac-
tionoftheoriginalsystemwehave. Traditionally, Miswrit-
teninsomevariant/extensionof finitestateautomata (thus
140verylimited)insometemporallogic,typically lineartempo-
rallogic(LTL).Withtheselimitations,weareworkingwith
regularlanguages ,hencewecouldleverageontheirvarious
niceclosureproperties.
Thehardpartisthelogic: iswritten,forinstance,inLTL,
whichcorrespondstoan aperiodicregularlanguages (orstar-
free languages , i.e., regular expressions without the ” ” op-
eration), which is a subset of regular languages. There are
algorithmstotranslate :inanequivalentautomaton A,
albeit with a (exponential) state blow-up , from going from
LTLtonon-deterministicFSA.HavingtheFSA,theremain-
ingpartiseasier: webuildtheautomaton M\Aandwe
checkwhethertheresultinglanguageisempty:
•Ifyes,thenweprovedthat Mj=;
•If no, this means that 9x2L(M\A)andxis a
counter-example .
This procedure turns out to be PSPACE-complete (polyno-
mial deterministic), which means that it is exponential in
time. Note that, typically we have a very small with re-
specttotheentiremodel M, thustheexponentialgrowing
islimited.
There was a lot of research on these techniques, with two
mainaims:
•Tocovermoreexpressive notations;
•Togetfasterand/oruse lessmemory .
The typical problem was that the resulting automaton was
too big to fit in memory. The main idea was to build up
onlyportionsof it (i.e., on-the-fly ). Another approach was
the so-called bounded model-checking , according to which,
insteadofusingautomata,wecouldtranslateeverythingin
somekindofweakerlogic,byaddingatemporalbound:
•Originally,itwas propositionallogic ,andthenweused
aSAT-solver;
•Morerecently,a satisfiabilitymodulotheory (SMT),then
weuseaSMT-solver(e.g.,Z3).
141Theideatouseautomatahasbeenextendedbyusing push-
downautomata (PDA),whichismoresuitabletorepresent
programs than a FSA, thanks to their stack. The most suc-
cessful regular language is the visibility pushdown (VP): a
subclass of deterministic context-free languages which en-
joymostofthenicepropertiesofregularlanguages. Hence,
theywereproposedformodelcheckingproceduralprograms.
However, there is a lot of theory behind this notations, but
alackofusefultoolstouseit.
Morerecently,therehasbeentheriseofaclassoflanguages
calledoperatorprecedence (OP)thatgeneralizesVP,retain-
ingalltheirproperties. OParemuchmoreexpressivethan
VPandcanmodelcomplexstackbehaviorsuchasthose,for
instance,ofexceptionsandcontinuations,wherepartofthe
stackcanbediscardedbecauseofsomeoperations.
2.AutomatedtheoremprovingTheotherbigfamilyofapproaches
are based on the idea of actually building a general formal
proofthatthesoftwarehasaparticularproperty(asatheo-
rem). Thisisindeedaquitenaturalapproachandtheoffered
logicisveryexpressive,butveryoften undecidable . Forthis
reason,weneed userguidance . Inpractice,itistheuserthat
actuallywritestheproof,butsometoolscanautomatesim-
plerpassagesandcancheckeverystep(i.e., proofchecker ).
There is a connection between writing programs and writ-
ing proofs: many of the recent proof checkers are systems
for functional programming languages (they are based on
thislanguages)andtheyaredependentlytyped. Inthisset-
tings,typesareveryexpressiveandcanbeusedtowrite com-
plex properties : if we write the code of a function fwith a
type expressing some property , then we are assured that
fenjoys 78. Theinterestingconnectionbetweenproving78Note that this is also true for standard typed lan-
guages, but, not surprisingly, the properties we can ex-
pressarequitelimited: forinstance,wecouldusepropo-
sitionallogicforsimpletypes,averybasicpredicatelogic
forparametrictypes.theoremsandwritingprogramsisformalizedbythe Curry-
HowardIsomorphism .
Memorysafety
Memorysafetycharacterizesprogramswhere,inanypossiblesce-
nario, memory allocation/use and de-allocation can never com-
promise the functionality of the program. Memory access is al-
ways well defined. The problem with C++ and Rust is that they
142needtomanagememorydirectly. Inparticular,system-levellan-
guages can’t afford a garbage ollector and thus they are usually
notmemory-safe. However,unlikeC++,Rusthasdefault compile-
timeandrun-timemechanismsforensuringmemorysafety. Both
problems related to temporal memory safety (e.g., use-after-free,
double-free) and to spatial memory safety (e.g., buffer overflow)
areensuredbyRust.
Memory safety bugs can always be seen as ownership prob-
lems. Whenavariablehasapointertoaregionofmemorywesay
thatitownsit. Largeprogramsmightuseseveralvariablesowning
thesameregionofmemoryattheverysametime. Ingeneral,this
isnotabugbutweneedtoensuretodeallocateonlywhenthelast
owner exited. Otherwise, we would get double-free or use-after-
freebugs. Moreover,someprogramsmighthavememoryregions
not owned by a variable. These are called memory leaks because
theycan’tbereclaimed.
Memoryleaks
A memory leak is a pointer to a memory region with no owner.
Essentially,theregionwillneverbede-allocatedbecausethepro-
gramforgotaboutit79. Considernowthefollowingexample:79Of course, one way to solve it is to use the free()
ordeletefunction, respectively in C and C++, to de-
allocatethememoryregion. int vuln(void)
{
char *s1 = (char *) malloc(0x14);
/// .....
}
/// the buffer is never freed
Thebufferisneverfreed,whichmeansthatifcallingthisfunction
multiple times we will end up having a lot of memory areas that
won’tbeeverfreed.
C++ introduced RAII, which stands for Resource Acquisition
IsInitialization anditisaformofmitigationformemoryleaks. In
particular,itisaprogrammingidiomthatties automaticvariables
(i.e.,variablesallocatedonthestack)totheacquisitionandrelease
ofresourcesontheheap. De-allocationistypicallydoneimplicitly
whenthevariablegoesoutofscope. Suchtypeofvariablescanbe
seeninformsofsmartpointers(i.e., shared_ptr andunique_ptr ).
Tosummarize,theideaistolinksomeallocatedobjectstoau-
tomaticvariables,sothatwhenthecodeendstheautomaticvari-
143ableisdeleted,alongwiththeallocatedvariable. Tobetterunder-
standthepoint,letusconsiderthefollowingexample:
int main(void)
{
unique_ptr<Rectangle> P1(new Rectangle(10, 5));
cout << P1->area() << endl; /// This will print 50
return 0; /// here the smart pointer destructor will deallocate the rectangle object
}
Largeprogramsmightneedtocopythesamepointerintoother
variables. Ifthelifetimesofthesevariablesdonotoverlap,wecan
enforcesingleownershipwithoutanyadditionaloverhead. Infact,
even if syntactically we have multiple variables, semantically we
arejustmovingownership fromonetoanother. C++hasspecial
functions for complying with this semantics and exposes a new
constructor (i.e., &&&) to build such copies. For instance, consider
thefollowingpieceofcode:
int main(void)
{
unique_ptr<Rectangle> P1(new Rectangle(10, 5));
cout << P1->area() << endl; /// This will print 50
unique_ptr<Rectangle> P2;
P2 = move(P1); /// P1 becomes invalid here
cout << P2->area() << endl;
return 0; /// only de-allocates the pointer in P2
}
Inthiscase, P1isnottheownerofthe Rectangle objectanymore,
it becomes invalid. Moving owernship is a way to ensure that, at
any point in time, there is a single variable carrying a pointer to
memory. This is opt-in in C++, but it is not in Rust, as we are
goingtosee.
InC++amoveisashallowcopyofanobjectwhichinvalidates
thesourceobject:
string s("Original string");
string d(std:::move(s));
/// uses the following constructor where that === s
string(string&&& that) { /// string&&& is a rvalue reference to a string
data = that.data;
144that.data = nullptr;
}
Sincethatismoved-fromobject,itwillnotbeusedanymoreand
wecanjustusetheoriginalpointer(i.e., data)inournewobject.
Multipleownership(i.e.,aliasing)
Programscouldhavepointerspointingtothesameregionsofmem-
ory, in a legitimate fashion. This is called multiple ownership , or
aliasing. As we said, sometimes aliasing is perfectly fine, for is-
tance:
•We want to work temporarily on elements of subvectors of
aheap-allocatedvector;
•Wewantseveralthreadsworkingonpartsofthesameheap-
allocatedobject.
However,inliberallanguagessuchasC++,unintuitive/wrong
behavior (i.e., bugs) might happen (e.g., double-free, use-after-
free). For double frees, we can use shared pointers in C++ that
usesreferencecounting. Theyusethiscounterwhichisincreased
with every copy and decreased whenever a pointer is destroyed.
Thisisusefulforbuildingcontainersthatlastovertheinvocation
ofafunction:
auto s1 make_shared<String>("Hello");
auto s2 = s1;
Use-after-frees are probably one of the nastier things that we
couldfindinC++andmightappearinseveralways. Thefollowing
C++validsequencehasamemorybug:
std:::vector<int> v { 10, 11 };
int *vptr = &v[1]; /// points *into* v
v.push_back(12);
std:::cout << *vptr; /// boom!
Theproblemwiththisisthatwearecreatingapointertoaninter-
nal region of the vector and the push_back() operation (pushing
anelementattheendofthevector), mightmodifyorde-allocate
the vector memory region (allocating a new one), which means
that the print afterwards could break the program, printing ran-
domstuffinmemory.
145Rustandmemorysafety
Solutionstoproblemwedescribedbeforecouldbethefollowing:
•Trytoenforceasingleownerandmakeitcommittomanage
memoryproperly;
•Whenmultipleownersareneeded(aliasingofpointers),ei-
ther use a reference counter or strictly control the creation
anddestructionofsuchaliases(i.e., borrowing ).
Singleownership
RustusesRAIIbasicallyeverywhere. Forinstance,whencreating
a string as an automatic variable on the stack internally this allo-
catesapointertotheheapwherethestringisactuallyallocated:
fn main() {
let s = String:::from("hello"); /// s is valid from this point forward
/// do stuff with s
} /// here memory is automatically de-allocated
Inthisway,memoryleakscan’thappenanymore.
Wecanproduceexplicitlyanobjectontheheapbycreatinga
”boxed value”, which is effectively a smart pointer (think of it as
unique_ptr inC++):
fn main() {
let b = Box:::new(5);
println!("b = {}", *b);
}
Notethat,whenweexitthescope, b’sdataisdeallocatedfromthe
heap.
Movesemantics
In Rust,move semantics is the default. Variables are in charge of
freeing their own resources. Remember that, in Rust, resources
canonlyhaveoneowner. Inthefollowingexample, s1willnotbe
usableafter s2iscreated,itwillproduceacompiletimeerror:
let s1 = String:from("Hello");
let s2 = s1;
/// .....
146/// s1 can't be used anymore
/// .....
Functioninvocationmovesownershiptothecalledfunction:
/// caller's code
fn func() {
let s = String:::from("Hello");
/// .....
consume(s); /// s looses ownership
/// .....
println!("{}", s); /// compiler error
}
/// callee's code
fn consume(r: String) { /// r acquire ownership
/// implicit drop(r);
}
Multipleownership
In Rust, the equivalent of shared pointers is theArctype (which
standsfor atomicreferencecountedvariable ):
let s1 = Arc:::new("Hello");
let s2 = s1.clone(&s1);
Thisusesanatomicreferencecounterwhichcanbeusedtoshare
safely the pointer across threads. There exist also a simple Rc<T>
trait (not atomic). However, this is a very resource intensive way
of dealing with multiple ownership (remember that a reference
counterisalwayskeptwhenusing Arc). Thisissolvedbyborrow-
ing.
Borrowing
ContrarytoC++,Rusthasawaytodealatcompiletimewithuse-
after-freebugs. Themechanismisbasedonreferences. References
(orborrows)arepointersthatdonotownthevalue. Creatingaref-
erenceiscalledborrowing: givenavariable vwecreateareference
with&v. Aliasing through references is controlled: Rust ensures
thatifthereisaliveborrowingwecan’tmodifytheoriginalvalue.
Let’s see the original (buggy) program in C++ now rewritten
inRust:
147let mut v = vec![10, 11];
let vptr : &'a mut i32 = &mut v[1];
v.push(12);
println!("{}", *vptr); /// error
Inparticular,themutableborrow vptrfreezestheoriginalobject
vuntil it is alive. We use the symbol a'to indicate all the lines
inwhichthevariableisstillalive(i.e.,itslifetime). Atline3inthe
codeabove, visusedwhileanoutstandingliveborrowexistssothe
compilerproducesanerror. Actually,thecompilerseesthatthere
isanoverlapbetweenamodificationofanobject(i.e., v.push(12) )
and an outstanding borrow (i.e., println!("{}", *vptr); ). The
otherimportantthingtonoticeisthatthisisaso-called zerocost
abstraction .
In some sense, borrowing a value is like creating a lock on
an object: whenever we have a pending lock in a reference to an
object, we can’t modify the original object itself. Creating non-
mutableborrowsislikecreatingreadlocks: wecanhavemultiple
non-mutableborrowsoutstanding,butwecan’tmodifytheobject
anyhow.
16 Lecture24-SeminaronSecureBootI
Securebootbasics
UEFI Secure Boot (SB) is a verification mechanism for ensuring
thatcodelaunchedbyacomputer’sUEFIfirmwareistrusted. Itis
designedtoprotectasystemagainstmaliciouscodebeingloaded
and executed early in the boot process, before the operating sys-
tem has been loaded. SB works using cryptographic checksums
and signatures. Each program that is loaded by the firmware in-
cludesasignatureandachecksum,andbeforeallowingexecution
the firmware will verify that the program is trusted by validating
thechecksumandthesignature. WhenSBisenabledonasystem,
anyattempttoexecuteanuntrustedprogramwillnotbeallowed.
This stops unexpected / unauthorised code from running in the
UEFIenvironment.
14817 Lecture25-I/ODevicesandDriversII
Deferringwork
Theunderlyingideabehindworkdeferringistomovenon-critical
management of interrupts to a later time (i.e., doing a minimal
workimmediatelyandletsomeworktobeperformedaftersome
time). Thismightalsobenefitfromaggregation,sincewecollected
some work to be done later80. Originally, the Linux interrupt80In some sense, we would have many small opera-
tionsmergedintoasingleone. managementwasdividedintotwolevels:
•Top-half: executesminimalamountofworkwhichismanda-
torytolaterfinalizethewholeinterruptmanagement. Such
aschemeworksina non-interruptible fashionandsched-
ulessomedeferredwork(ordeferredfunctions);
•Bottom-half : finalizestheworkusingdeferredfunctionsfrom
aqueueandexecutesthem. Theseareinvokedinparticular
reconciliationpoints intime.
In the Linux kernel there are some abstractions, used to per-
form the work deferring. SoftIRQs are basically tasks to be exe-
cuted at a later time (i.e., at the reconciliation points) and can be
categorizedinseveraltypes:
•HI_SOFTIRQ ;
•TIMER_SOFTIRQ ;
•TASKLET_SOFTIRQ ;
•etc.
Unless using a very specific type of SoftIRQs, these actions
won’tbeeverinterruptedonaCPUwhenexecuting,buttheycould
runatthesametimeonadifferentCPU81.Thereisanother(sim-81Thus, some mutual exclusion primitives must be
usedtoavoidconcurrencyproblems. Notethatwewant
toavoidlocksasmuchaspossible.plertouse)abstractioncalled Tasklets,whicharetreatedasaspe-
cific type of SoftIRQs. By scheduling multiple instances of the
same tasklet, we are sure that these instances can’t run in paral-
lel,buttheyareserializedinstead.
149Figure97: Deferringwork
SoftIRQs
Supposethatanhandlerisbeingexecuted. Interruptsofthesame
IRQsaredisabled,butotherinterruptscanarrive. Wheneveran-
otherinterruptarrives,ifithassomeworktodoitmarkstheSoftIRQ
aspending(i.e.,usingthe raise_softirq() ). Thisdeferredwork
will be executed at the next reconciliation point. Note that the
handler being executed originally could itself register some de-
ferred work to be done with the raise_softirq() . When exiting
fromtheinterruptcontext(on irq_exit),thedo_softirq() func-
tion signals a reconciliation point: on return from hardIRQs or
withinksoftirq/<cpu> kernelthreads,someofthedeferredwork
is executed. Note that all interrupts are enabled when executing
softIRQs.
SoftIRQs might be raised at high rates (such as during heavy
network traffic) and they might reactivate themselves either. To
avoidstarvingtheuserspace,thekernel’sstrategyisnottoimme-
diately process re-activated SoftIRQs. Instead, if the number of
SoftIRQsgrowsexcessively,thekernelwakesupafamilyofkernel
threadstohandletheload(i.e., ksoftirqd threads). The ksoftirqd
kernelthreadrepeatedlychecksforpendingSoftIRQsandhandles
thembyalwaysensuringtore-scheduleifahigherprioritythread
comesaround.
SoftIRQsare staticallyallocated atcompiletimeandtheyare
anarrayof NR_SOFTIRQS functionpointers:
150Figure98: SoftIRQsfunctioningintheLinuxkernel
void softirq_handler(struct softirq_action *)
Linux ensures that, when a SoftIRQ is running on a CPU, it can’t
bepreemptedonthatCPU.AnotherCPU,however,couldrunthe
same handler at the same time. This makes them difficult to be
programmedcorrectly.
ThekerneldefinesseveralSoftIRQs. Ingeneral,wewanttouse
onlyoneofthistypecalled TASKLET_SOFTIRQ andHI_SOFTIRQ :
Name Prio Description
HI_SOFTIRQ 0 High-prioritytasklets
TIMER_SOFTIRQ 1 Timers
NET_TX_SOFTIRQ 2 Sendnetworkpackets
NET_RX_SOFTIRQ 3 Receivenetworkpackets
BLOCK_SOFTIRQ 4 Blockdevices
TASKLET_SOFTIRQ 5 Normalprioritytasklets
SCHED_SOFTIRQ 6 Scheduler
HRTIMER_SOFTIRQ 7 High-resolutiontimers
RCU_SOFTIRQ 8 RCUlocking
Tasklets
Tasklets are one of the many SoftIRQs available within the Linux
kernel. Inparticular,theyhaveasimplerinterfaceandtherecan’t
bemorethanoneinstanceofthesametaskletrunningoverallthe
CPUs. This implies no problems with reentrancy82. A tasklet is82Asubroutineiscalledreentrantifmultipleinvoca-
tionscansafelyrunconcurrentlyonmultipleprocessors. basically a function plus some data and it is represented by the
kernelwithalistofstructuresas:
151struct tasklet_struct {
struct tasklet_struct *next;
unsigned long state; //* 0, scheduled or running **/
/// .....
void (*func)(unsigned long);
unsigned long data;
};
/// .....
DECLARE_TASKLET(my_tasklet, my_tasklet_handler, my_data);
/// .....
tasklet_schedule(&my_tasklet);
Inparticular,duringthereconciliationpoints,thekernelgoesthrough
the list and looks for tasklets that are scheduled but not running
on another CPU: it sets them to the running state and runs the
handler (i.e., func). Remember that tasklet_handler can’t sleep
andmust:
•Take care of locking data if they are accessing data shared
withotherprocessors;
•Disableinterrupts iftheysharedatawithaninterrupthan-
dler;
•Avoidtoblock foranyreason.
As shown in the example, we could declare tasklets statically
ordynamicallyinourinterrupthandlers:
/// creates a my_tasklet variable
DECLARE_TASKLET(my_tasklet, my_tasklet_handler, my_data);
Toscheduleataskletforexecution,weinvoke tasklet_schedule(&my_tasklet)
anditwillrunonce. Ifthetaskisre-scheduledbeforerunningthe
firsttime,itwillonlyrunonce.
Workqueues
Itmayhappenthatadeferredactionmustblock. Forinstance,we
couldhaveworkallocatingalotofmemory,obtainingasemaphore
orperformingablockingI/Ooperation. Thus,wewanttouseso-
calledwork queues to do that. A work queue is a schedulable en-
titythatrunsinprocesscontexttoexecuteourbottomhalves. In
particular, this is a general mechanism to submit work to worker
152kernel threads called events/n. To create work for the events/n
threadwecoulduse:
DECLARE_WORK(work, void (*func)(void *), void *data);
Toenqueuetheworkwecoulduse:
schedule_work(&work);
In particular, the worker thread enters an infinite loop and goes
to sleep. When the work is queued, the thread is awakened and
processesthework. Whenthereisnoworklefttoprocess,itgoes
backtosleep.
Timers
Therearetwomaintypesoftimers:
•System timer : programmable piece of hardware that issues
aninterruptonafixedfrequency. Theinterrupthandlerfor
this timer (called timer interrupt ) updates the system time
andperformsperiodicworksuchasupdatingthetimeslice
consumption of a process. Without the system timer, the
entiretimesharingmechanisminLinuxcouldn’twork(and
Linuxcouldn’tworkaswell);
•Dynamic timers : they are used to schedule events that run
onceafteraspecifiedtimeslicehaselapsed83. Forinstance,83Notethatdynamictimersaremultipleones, while
the system timer is just one global timer with fixed tick
rate(e.g.,50to1000Hz).wecouldsetthat,afteracertainperiodofinactivity,adevice
isturnedoff.
Thesystemtimerinvokesaninterrupthandlercalled tick_period()
that updates the jiffiesglobal variable, taking into account the
timeelapsedfromthestartupofthesystem. Notethatthesystem
timeris notthe real-time clock. The real-time clock (RTC), in-
stead, provides a non-volatile device for storing the system time.
The RTC continues to keep track of time even when the system
is off, by using a small battery which is typically included on the
system board. On boot, the kernel reads the RTC and uses it to
initializethewalltime(storedinthe xtimevariable). Onx86,the
primarysystemtimeristheprogrammableinterrupttimer(PIT).
ThePITexistsonallPCsandhasbeendrivinginterruptssincethe
days of DOS. The kernel programs the PIT on boot to drive the
systemtimerinterrupt(interruptzero)attheHzfrequency. How-
ever,itisasimpledevicewithlimitedfunctionality,butitgetsthe
153job done. Other x86 time sources include the local APIC timer
andtheprocessor’stimestampcounter(TSC).
Considerthisdefinitionofadynamictimer:
struct timer_list my_timer;
init_timer(&my_timer);
/// .....
my_timer.expires = jiffies + delay; //* timer expires in delay ticks **/
my_timer.data = 0; //* zero is passed to the timer handler **/
my_timer.function = my_function; //* function to run when timer expires **/
add_timer(&my_timer); //* start the timer **/
Thekernelcodeoftenneedstodelaytheexecutionofsomefunc-
tionuntilalatertime(e.g.,bottom-halves). Timersareconstantly
createdanddestroyedandthereisnolimitinthenumberoftimers.
Thekernelchecksforexpiredtimersattheendofthesystemtimer;
ifanyhasexpired,thekernelraisesa TIMER_SOFTIRQ interrupt.
Linuxdevicemanagement
Linux integrates devices into the file system as special files . In
particular, each device is assigned a path name (usually in /dev).
For example, the printer might be /dev/lp. Devices are divided
intotwocategories:
•Acharacter device is characterized by a character stream.
Writing or reading from the file has direct impact on the
deviceitself. Nobufferingisperformedinthiscase;
•Ablock device is seen as a sequence of numbered blocks.
Eachblockcanbeindividuallyaddressedandaccessedthrough
acache(withrandomaccess).
Each device has a special driverthat handles it and has what
is called a major device number that servers to identify it. If a
driver supports multiple devices, say, two disks of the same type,
eachdiskhasa minordevicenumber thatidentifiesit.
devfs,sysfsandudev
Linuxusedtoexposeentriesunder /devevenfordevicesnotcur-
rently attached84to the system (it used to contain thousands of84Linuxusedtocontainalldevicesthatatsomepoint
intimewouldbeattachedandusedinthesystem. devices). There have been an evolution of such a scenario, going
154under the name of devfs, according to which we had only those
devicescurrentlypluggedintothesystem.
There were still some problems. For instance, it forced a few
constraints(especiallyonthenameofsomedevices)andimplied
to have a big database of names in kernel memory. In particular,
the name given to a device could change depending on how we
connected the device to the system85. Each name corresponded85For instance, changing the port at which the de-
vice was connected implied to change the device name
aswell.to a major and minor number, used by the kernel to determine
which hardware device to talk to. Names assigned to devices, as
we just said, might change if the user changed the topology (e.g.,
plug USB devices in a different way). Another new system has
beenintroducedtosolvesomeproblemsandgoesunderthename
ofudev. This system substituted devfs’s/devdirectory and gives
complete customizability on the naming policy to the user. This
newfilesystemstructureisbasedon sysfsinformation,whichis
anorthogonalandcomplementaryarchitecturetokeeptrackhow
devices are connected to the system itself. The sysfspart of the
file-system(under /sys)showstothefile-systemhowtheoriginal
devices were connected tothe system. Thisintroduces two views
86: oneflattenedone( /dev)andahierarchicalone( /sys).86A metaphor is that /sysprovides access to the
packaging, while /devprovides access to the content of
thebox.
Figure99: devfs,sysfsandudevfunctioning
Note that sysfsexposes how the kernel models the current
stateandstructureofthesystem(takingintoaccountdevicescur-
rentlyaddedtothesystem),intermsof:
155•Howtheyareintermsofpowermanagement;
•Whatbustheyareattachedto;
•What drivers they have, along with the structure of buses,
devicesanddriversinthesystem.
Thekernelprovidesarepresentationofitsmodelinuserspace
throughthe sysfsvirtualfilesystem(mountedunder /sys),while
in/devitallowsprogramstoaccessdevicesthemselves.
Creatinganewcharacterdevice
Supposewewanttocreateanewcharacterdevice. Thismeansthat
we want to follow a specific pattern within the Linux kernel, in-
cludingthecreationofsuchadeviceunder /dev. Ourdevicemust
interactwiththeLinuxsystemtocreatefiles. Thereisastrictcon-
nection between the file itself and the operations to be registered
andthatcanbedonebythedevice. Theoperationsaredefinedus-
ing the file_operations structure, which is an array of function
pointersthatdefinehowthekernelwillhandlevariousoperations
(e.g.,read(),write()andioctl()) on a device. This structure
allows device drivers to register functions that will be called for
each of these operations. By standardizing the interface for de-
vicedrivers,thekernelisabletosupportawidevarietyofdevices
withoutrequiringanyspecialcodeforeachone.
Figure100: Writingacharacterdevicedriver
156Thedifferencebetweencharacterandblockdevices
When creating block devices, instead, we follow a different pat-
tern: we don’t interact directly with the device. However, when
we want to register a block device we instantiate and specify a
structurecalled block_device_operations (alongwitha gendisk
structure),definingoperationsasfunctionsthatworkjustliketheir
char driver equivalents. They are called whenever the device is
opened and closed. A block driver might respond to an open()
call by spinning up the device, locking the door (for removable
media), etc. It should also count how many users are using it to
safely release the device (i.e., spinning down the device). Block
devicescanprovidean ioctl()methodtoperformdevicecontrol
functions(e.g.,returndevice-specificdatasuchasgeometry).
The virtual file-system interacts with block device drivers to
readandwritedatathankstothe gendiskdatastructure: thisstruc-
turecreatestheactualblockdeviceitselfanddefinesawaytoreg-
isterrequeststothedeviceforreadingorwritingblocks.
Figure101: Writingblockdevicedrivers
Managingblockdevices
Supposewehaveaprocessthataccessadiskwith read()andwrite()
operationsinvolvingacertainnumberofbytes. TheVFSisamod-
ulethathandlestwodifferentaspects:
157•Itverifiesthatdataisalreadyinmemory(i.e.,residesinthe
kernel’spagecache);
•If not, it sends the request for data to the mapping layer.
Themappinglayeraccessesthefiledescriptorandpiecesto-
getherthelogical-to-physicalmapping,thereforegetting,at
theend,thepositionoftheactualdiskblocks. Finally,itcre-
ates a request to the block layer through a structure called
bio(i.e.,blockI/O).
Then, the block I/O layer tries to merge the list of biostruc-
turesintotheleastamountofactualrequeststothedriver.
Figure102: Blockdeviceinteractions
Morespecifically,ifthepagecachedoesnotcontainthedata,
the mapping layer identifies the segments of a page that corre-
spondtocontiguoussectorsondisk. Internally,themappinglayer
works with multiple sectors called blocks(for simplicity assume
that1sectoris1block),thenitcollectsrequestsfor segments that
map to contiguous sectors on disk in a structure called bio. A
bioreferences back to the original segments through a bio_vec
pointerandcontainsdatatoiterateoverit.
Once created, one or more biosare sent to the block layer
whichwillcreatetheactual requesttobesenttothedevicedriver.
158Figure103: Blockrequest’smanagement
Before sending it, the block layer tries to merge several biore-
quests into single requests whenever possible. After a while, re-
quests are moved from the staging queue to the actual hardware
queue that will be read by the device driver and, once in a while,
thequeue_rq is called by the block layer and the device can fetch
requestsfromthehardwarequeueandexecutethem. Driver’s queue_rq
isinvokedthroughamechanism,called plugging,thatadjuststhe
rateatwhichrequestsaredispatchedtothedevicedriver. Undera
low load, operations to the driver are delayed, allowing the block
layertoperformmoremerges.
I/Oschedulers
I/O schedulers can have many purposes depending on the goal.
Commonpurposesincludethefollowing:
•To minimize time wasted by hard disk seeks (still relevant
insomecases);
•ToprioritizeI/Orequestscomingfromcertainprocesses;
•Togiveashareofthediskbandwidthtoeachrunningpro-
cess;
•To guarantee that certain requests will be issued before a
particulardeadline.
Since2013,Linuxsupportsfasteststoragedevicesonlargesys-
tems, which have multiple hardware queues. This allows to have
159multiplerequestsflyingconcurrentlyandtohaveout-of-ordercom-
pletions. Thekernelmustsupportefficientrequesttaggingtodis-
tinguish which one has finished. Each CPU has its own software
queuetoavoidcontention.
1.NOOPI/OschedulerThegoaloftheNOOPI/Oscheduler
is to pursue efficiency by doing as little as possible. Global
I/O requests are ordered in a FIFO fashion. The scheduler
justmergesrequeststoadjacentsectorstomaximizethethrough-
put. Thisschedulerissuitableforstoragedevicesnotinclud-
ingmechanicalparts.
2.Budget Fair Queuing I/O scheduler The goal of the Bud-
get Fair Queuing I/O scheduler is to assign a fair amount
ofdiskbandwidth. Inparticular,itassignsanI/Obudgetto
each process (i.e., the number of sectors allowed to trans-
fer). Onceaprocessisselected,ithasexclusiveaccesstothe
storage device until it has transferred its budgeted number
of sectors. BFQ tries to preserve fairness overall, so a pro-
cessgettingasmallerbudgetnowwillgetanotherturnatthe
drivesoonerthanaprocessthatwasgivenalargebudget.
3.Kyber I/O scheduler The goal of the Kyber I/O scheduler
is to maximize the throughput. This is a simple scheduler
that allows for request merging and some simple policies.
It is intended for fast multi-queue devices (flash) and lacks
muchofthecomplexityfoundinBFQ.
4.MQ-deadline I/O scheduler The goal of MQ-deadline I/O
scheduler is to try to do some merges but then prioritize
long starving reads. In particular, it assigns an expiration
time to any incoming I/O request. The MQ-deadline I/O
schedulerhasfourqueues,twoseparateFIFOqueuesREAD
andWRITErequestsandtwosector-wisesortedqueuesfor
READandWRITEformergingrequests.
160